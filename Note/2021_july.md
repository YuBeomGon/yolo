0729
1. Loss가 Nan 또는 int가 나온다. 
   torch.log(input)에서 input이 0일 경우 문제 발생, small value를 더해 줘야 한다. 
   이 때 data type을 고려해야 한다. float16일 경우 small value가 1e-8일 경우 0으로 type casting되어서 계속 inf가 나왔다.
   
2. Loss.backward() 할 때 inplace modification error 
   back propagation을 할 때, temperary값을 다 가지고 있어야 한다. backpropagation시 inplace로 값을 변경할 경우 error 발생한다.
   예를 들면 아래와 같은 경우
   이 계산 부분을 data loader로 옮겨서 해결
   target[target< 0.5] = 0.
   
0730
1. focal loss 구현
2. patch별 label작업을 segmentation map과 patch간의 IOU를 계산하는 것으로 적용
    - Normal cell 및 abnormal cell에 대해 patch별 label이 잘 됨을 확인
    - image에 Noise가 많이 있어서 이 부분 제거할 필요 존재
    
0731
1. imagenet label encoding 후 비교 테스트
   - gpu 한 곳에 할당하는 것 관련 아래 참고
   - https://m.blog.naver.com/ptm0228/222048480521
   import os
   os.environ["CUDA_VISIBLE_DEVICES"]="0"
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   
0802
1. imagenet 비교 테스트
    - sentence2vec으로  각 label을 텐서화한 후에 dense layer fixing하고 training하는 것이 일반적인 방식보다 성능이 더 안 좋다.
    - 다양한 초기화 포인트..
    
2. CNN을 이용하여 patch를 뽑아내고 bert통과시킴, learning rate가 0.001일 때 모든 batch output의 결과가 똑 같아진다. 
    - 적절한 learning rate tuning이 필요.