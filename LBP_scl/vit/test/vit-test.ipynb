{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7666ad1d-529a-49d8-ac2d-511668e99a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5625df-c598-4200-aafc-7c40613ffcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://yhkim4504.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c9d56e-8165-496c-ad58-4dc5c32dc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf8a780b-5780-4649-84d5-c504b80d7e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 224, 224])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(8,3,224,224)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f7c8a4d-316c-43e3-bd00-e36e0cb60f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : torch.Size([8, 3, 224, 224])\n",
      "patches : torch.Size([8, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16 # 16 pixels\n",
    "\n",
    "print('x :', x.shape)\n",
    "patches = rearrange(x, 'b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=patch_size, s2=patch_size)\n",
    "print('patches :', patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed59f77f-8f81-4cc2-8dd8-41eade545619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 768, 14, 14])\n",
      "torch.Size([8, 196, 768])\n",
      "torch.Size([8, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16\n",
    "in_channels = 3\n",
    "emb_size = 768\n",
    "conv1 = nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size)\n",
    "x1 = conv1(x)\n",
    "print(x1.shape)\n",
    "\n",
    "x2 = x1.permute(0,2,3,1).view(8, 14*14, 768)\n",
    "print(x2.shape)\n",
    "\n",
    "x3 = Rearrange('b e (h) (w) -> b (h w) e')(x1)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43600ba7-d7c6-4be7-8de4-c6ae91fc678e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 196, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4 = rearrange(x1, 'b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=1, s2=1)\n",
    "x4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "130447e7-320d-488b-9475-09b2854a94bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1204224)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x2 == x4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc0dd695-ef35-4a93-b17f-5ba098e4f167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1204224)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x2 == x3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "623e391e-770f-44f1-bbd0-2805c525bfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 196, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_size = 16\n",
    "in_channels = 3\n",
    "emb_size = 768\n",
    "\n",
    "projection = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "\n",
    "y = projection(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ccd201-f29d-44c4-922b-9ef6c011ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x2[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ee0d6e4-9e6d-4518-924a-cbbe65a7b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6a22e96-3c52-43de-8b16-2c62c67cce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 768\n",
    "img_size = 224\n",
    "patch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4af882ce-b90f-4ff8-a201-cadd343f9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token = nn.Parameter(torch.randn(1,1,emb_size))\n",
    "cls_token.shape\n",
    "position = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
    "# position = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
    "position.shape\n",
    "\n",
    "cls_tokens = cls_token.repeat(8,1,1)\n",
    "\n",
    "tot_tokens = torch.cat([cls_tokens, x2], dim=1)\n",
    "tot_tokens.shape\n",
    "\n",
    "tot_tokens += position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "af8526f2-996a-4a2a-8c4f-056c74b12364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8504, -0.8504, -0.8504, -0.8504, -0.8504, -0.8504, -0.8504, -0.8504],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_tokens[0][0][0]\n",
    "cls_tokens[1][0][0]\n",
    "cls_tokens[2][0][0]\n",
    "cls_tokens[0:8,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86edb1-8e92-484c-9ffa-c328af20846f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81b73608-4268-44f1-92af-9b005a38deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "Projected X shape : torch.Size([8, 196, 768])\n",
      "Cls Shape : torch.Size([1, 1, 768]) , Pos Shape : torch.Size([197, 768])\n",
      "Repeated Cls shape : torch.Size([8, 1, 768])\n",
      "output :  torch.Size([8, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 패치사이즈로 나누고 flatten\n",
    "print(x.shape)\n",
    "projected_x = projection(x)\n",
    "print('Projected X shape :', projected_x.shape)\n",
    "\n",
    "# cls_token과 pos encoding Parameter 정의\n",
    "cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "positions = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
    "print('Cls Shape :', cls_token.shape, ', Pos Shape :', positions.shape)\n",
    "\n",
    "# cls_token을 반복하여 배치사이즈의 크기와 맞춰줌\n",
    "batch_size = 8\n",
    "cls_tokens = repeat(cls_token, '() n e -> b n e', b=batch_size)\n",
    "print('Repeated Cls shape :', cls_tokens.shape)\n",
    "\n",
    "# cls_token과 projected_x를 concatenate\n",
    "cat_x = torch.cat([cls_tokens, projected_x], dim=1)\n",
    "\n",
    "# position encoding을 더해줌\n",
    "cat_x += positions\n",
    "print('output : ', cat_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b7870a3c-58de-42f9-a56d-f05d2a8f6a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=768, bias=True) Linear(in_features=768, out_features=768, bias=True) Linear(in_features=768, out_features=768, bias=True)\n"
     ]
    }
   ],
   "source": [
    "emb_size = 768\n",
    "num_heads = 8\n",
    "\n",
    "keys = nn.Linear(emb_size, emb_size)\n",
    "queries = nn.Linear(emb_size, emb_size)\n",
    "values = nn.Linear(emb_size, emb_size)\n",
    "print(keys, queries, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9717d7c5-90de-4291-8675-76d2c5f9819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 196, 768])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-2d69154dfa61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqueries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "print(x2.shape)\n",
    "queries(cat_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "26f0b279-0827-4e27-83b5-c73d1dc3e070",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-3b51d08930d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b n (h d) -> b h n d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b n (h d) -> b h n d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalues\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b n (h d) -> b h n d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "queries = rearrange(queries(x2), \"b n (h d) -> b h n d\", h=num_heads)\n",
    "keys = rearrange(keys(x2), \"b n (h d) -> b h n d\", h=num_heads)\n",
    "values  = rearrange(values(x2), \"b n (h d) -> b h n d\", h=num_heads)\n",
    "\n",
    "print('shape :', queries.shape, keys.shape, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75f91db-3c07-4072-9af2-5770f4c4f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(4, 4)\n",
    "a\n",
    "a = torch.tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
    "        [-0.7401, -0.8805, -0.3402, -1.1936],\n",
    "        [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
    "        [-1.6092,  0.5419, -0.2993,  0.3195]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e718e4-4167-4d9e-9dad-22f1d735b2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d0385c-cc54-41cb-b576-e6e6a4828404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 1, 2],\n",
       "        [0, 1, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,4,3)\n",
    "torch.argmax(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cd486-7ab2-430f-867d-ab3d409b4dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
