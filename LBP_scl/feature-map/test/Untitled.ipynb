{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e41802-caed-412b-8cf3-bc0824e8a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0ed3aa-7f53-41ff-93a5-0e521c7e5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_img_size = 512\n",
    "res_stride = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d613acf-90c9-48bc-bfe3-99c2c62263e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = torch.randn(res_img_size,res_img_size)\n",
    "gaussian = torch.randn(1,1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b636eed-cfd8-4960-b6ab-224cbc1b015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 21, 21])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_iou = F.conv2d(torch.tensor(laplacian).reshape(1,1,res_img_size,res_img_size).float(), \n",
    "        gaussian, stride=res_stride)\n",
    "laplacian_iou.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69e372e6-013c-4e27-82a6-988aaefa8d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2048, 2048])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.randint(2,(1,1, 2048,2048))\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a8a8c55-e6a0-4fb3-a9a5-06ccd37faaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.randn(1,1,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ea2fbd4-4b35-491d-a7e2-0116d794f81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 21, 21])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = F.conv2d(mask.float(), kernel, stride=96) / (128 ** 2)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a02b85-e804-4a2b-ab6a-bf6f8062ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "            mask = gray < self.threshold \n",
    "            for box in boxes :\n",
    "                x, y, width, height, class_label = map(int, box)\n",
    "                targets_mask = torch.zeros(1,1,self.image_size,self.image_size)\n",
    "                targets_mask[:,:,y:y+height,x:x+width] = 1\n",
    "            targets_mask = targets_mask * mask\n",
    "            targets = F.conv2d(targets_mask.float(), self.kernel, stride=self.stride) / (self.kernel_size * self.kernel_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
