{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d4d04f-92d5-43b0-9622-3a6f5d0b0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataset import LbpDataset, train_transforms, val_transforms, test_transforms, get_indices\n",
    "from model import LBPModel, CNNModel\n",
    "from loss import LBPloss\n",
    "from visualize import visualize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from resnet import resnet18, resnet12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a538ea-0606-4253-b104-e57914bb119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = nn.AdaptiveAvgPool2d((1,1))\n",
    "# input = torch.randn(1, 64, 8, 9)\n",
    "# output = m(input)\n",
    "# output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7704eea1-bb7c-4c1e-bccc-c3498775f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet12(pretrained=False)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c2c20c-e284-4fc2-acc7-388582530ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1555, 12)\n",
      "1214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_id': 'patch_images/2021.01.08/LBC141-20210105(1)/LBC141-20210105(1)_1001.png',\n",
       " 'boxes': array([[1558., 1603.,   96.,   73.,    0.],\n",
       "        [1452., 1263.,   82.,   94.,    0.]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/df.csv')\n",
    "print(df.shape)\n",
    "df['label_id'] = df.label.apply( lambda x : 0.)\n",
    "df_data = df.groupby('path')\n",
    "def get_data(img_id):\n",
    "    if img_id not in df_data.groups:\n",
    "        return dict(image_id=img_id, boxes=list())\n",
    "    \n",
    "    data  = df_data.get_group(img_id)\n",
    "#     boxes = data['bbox'].values\n",
    "    boxes = data[['xmin', 'ymin', 'w', 'h', 'label_id']].values\n",
    "#     labels = data['label'].values\n",
    "    return dict(image_id = img_id, boxes = boxes)\n",
    "#     return dict(image_id = img_id, boxes = boxes, labels=labels)\n",
    "\n",
    "train_list = [get_data(img_id) for img_id in df.path.unique()]\n",
    "print(len(train_list))\n",
    "# df.head()\n",
    "\n",
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c42995f-59f7-4897-be70-c020aa053aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 'patch_images/2021.01.06/LBC24-20210102(1)/LBC24-20210102(1)_1160.png',\n",
       "  'boxes': []},\n",
       " {'image_id': 'patch_images/2021.01.06/LBC24-20210102(1)/LBC24-20210102(1)_1817.png',\n",
       "  'boxes': []}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/Dataset/scl/patch_images/2021.01.06/LBC24-20210102(1)/'\n",
    "file_list = ['patch_images/2021.01.06/LBC24-20210102(1)/' + d for d in os.listdir(path)]\n",
    "file_list[:2]\n",
    "\n",
    "test_list = [get_data(img_id) for img_id in file_list]\n",
    "test_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959224d0-30b5-4967-9ae3-22d3253bbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_dataset = LbpDataset(\n",
    "    train_list,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "#     pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_dataset = LbpDataset(\n",
    "    test_list,\n",
    "    transform=val_transforms,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    "#     pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53e99f5-c808-41ee-9418-64536b31f454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 2048, 3)\n",
      "torch.Size([3721, 1])\n",
      "torch.Size([3721, 1])\n",
      "torch.Size([8, 2048, 2048, 3])\n",
      "torch.Size([8, 3721, 1])\n",
      "torch.Size([8, 3721, 1])\n"
     ]
    }
   ],
   "source": [
    "image, cell_iou, targets, path = next(iter(train_dataset))\n",
    "print(image.shape)\n",
    "print(cell_iou.shape)\n",
    "print(targets.shape)\n",
    "# train_dataset.anchors\n",
    "image, cell_iou, targets, path = next(iter(train_loader))\n",
    "print(image.shape)\n",
    "print(cell_iou.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba527c40-7bc2-4a1c-8bb0-3a016bc01311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1,5,3,2])\n",
    "# b = np.array([2,1,4,4])\n",
    "# c = np.array([6,3,1,2])\n",
    "# t_list = []\n",
    "# t_list.append(a)\n",
    "# t_list.append(b)\n",
    "# t_list.append(c)\n",
    "# np.max(t_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4babd79-4aa5-4661-88f3-f3f4cde51c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ccf44be-2e55-4cc4-a8ff-0393dc066850",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# model = CNNModel().to(device)\n",
    "model = resnet12(pretrained=False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5 )\n",
    "loss_fn = LBPloss(device).to(device)\n",
    "# scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66cdcbb-25d0-4c5e-9962-024b160540d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # torch.randperm(0)\n",
    "# a = torch.tensor([1,10,3,5,7,11,32,22])\n",
    "# index = [3,5,7]\n",
    "# # for b in a[index]\n",
    "# a[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc43282b-db8b-42c1-b9de-61d6c7dedfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([  13,  202,  388,  426,  687, 1224, 1357, 1403, 1465, 1723, 1737, 1822,\n",
    "#         2121, 3084, 3190, 3207, 3357, 3396, 3518, 3640])\n",
    "# list(a.int())\n",
    "# a.tolist()\n",
    "\n",
    "# torch.Size([2, 1, 128, 128, 3])\n",
    "# a = torch.randn(2,1,8,8,3)\n",
    "# b = torch.randn(2,1,8,8,3)\n",
    "# b1 = torch.randn(2,1,8,8,3)\n",
    "# c = [a, b, b1]\n",
    "# index = [1,2]\n",
    "# c[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532d565-ae60-45b7-8078-af527fbf9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:52<00:00,  2.87it/s, loss=-1.18]\n",
      "100%|██████████| 152/152 [00:52<00:00,  2.89it/s, loss=-3.57]\n",
      " 66%|██████▌   | 100/152 [00:36<00:18,  2.86it/s, loss=-4.12]"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in (range(epochs)) :\n",
    "    batch_losses = []\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    count = 0\n",
    "    for images, iou, targets, path in loop :\n",
    "\n",
    "        batch_size, gride_size, _ = iou.shape\n",
    "        images = images.permute(0,3,1,2).to(device)\n",
    "\n",
    "        indices, iou, targets = get_indices(iou, targets)\n",
    "        labels = torch.cat([iou, targets], dim=-1)\n",
    "#         print(labels.shape)\n",
    "        \n",
    "        outputs = model(images, indices)\n",
    "#         print(outputs.shape)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "#         print(outputs.shape)\n",
    "#         print(labels.shape)\n",
    "        loss, cell_loss = loss_fn(outputs, labels)\n",
    "#         print(loss)\n",
    "#         print(cell_loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        mean_loss = sum(batch_losses) / len(batch_losses)\n",
    "        loop.set_postfix(loss=mean_loss) \n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdae1c-cd59-4979-bfc1-700d1bfa9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_indices = torch.ge(iou, 0.5)\n",
    "# print(positive_indices)\n",
    "print(len(torch.where(iou[0,:,0] > 0.8)[0]))\n",
    "print(len(torch.where((iou[0,:,0] > 0.0) & (iou[0,:,0] < 0.8))[0]))\n",
    "\n",
    "print(len(torch.where(targets[0,:,0] > 0.8)[0]))\n",
    "print(len(torch.where((targets[0,:,0] > 0.0) & (targets[0,:,0] < 0.8))[0]))\n",
    "\n",
    "normal_cell = torch.where(iou[0,:,0] > 0.8)[0]\n",
    "normal_cell_not = torch.where((iou[0,:,0] > 0.0) & (iou[0,:,0] < 0.8))[0]\n",
    "\n",
    "abnormal_cell = torch.where(targets[0,:,0] > 0.8)[0]\n",
    "abnormal_cell_not = torch.where((targets[0,:,0] > 0.0) & (targets[0,:,0] < 0.8))[0]\n",
    "\n",
    "\n",
    "normal_cell_indices = torch.randperm(len(normal_cell))[:10]\n",
    "normal_cell_not_indices = torch.randperm(len(normal_cell_not))[:10]\n",
    "abnormal_cell_indices = torch.randperm(len(abnormal_cell))[:10]\n",
    "abnormal_cell_not_indices = torch.randperm(len(abnormal_cell_not))[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8db4b-10d7-413c-bd07-3543e9a3e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncell = (normal_cell[normal_cell_indices])\n",
    "ncell_not = (normal_cell_not[normal_cell_not_indices])\n",
    "abcell = (abnormal_cell[abnormal_cell_indices])\n",
    "abcell_not = (abnormal_cell_not[abnormal_cell_not_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be8f16-4002-4e25-909c-1d813e7028d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice, _ = torch.sort(torch.cat([ncell, ncell_not, \n",
    "           abcell, abcell_not]), dim=-1)\n",
    "indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83b3a6-95e4-41dc-9921-74e186449332",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d2129-528b-4c79-aac2-a66084d9800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_cell = torch.where(targets[0,:,0] > 0.8)[0]\n",
    "abnormal_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f360a-95ae-4763-bcac-1deca98b72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cell_indices = torch.randperm(len(normal_cell))[:10]\n",
    "normal_cell_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a4cbc-04d4-4159-88ec-a27d51c014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randperm(len([1,2,3,4,5,6,7,8,9,0,11,12,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b222a6-4e79-4ae9-864a-72362284bca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc77070-2098-4b21-8ba0-7aca0d010b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda334f-917d-4047-962a-faf747ed7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2):\n",
    "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "    x_min, y_min, x_max, y_max = list(map(int, bbox))\n",
    "#     print(bbox)\n",
    "#     x_min, y_min, x_max, y_max = list(map(round, bbox))\n",
    "#     print((int(x_min), int(y_min)), (int(x_max), int(y_max)))\n",
    "\n",
    "    img = cv2.rectangle(img, (int(x_min), int(y_min)), (int(x_max), int(y_max)), color=BOX_COLOR, thickness=thickness)\n",
    "    return img\n",
    "\n",
    "def visualize(image, bboxes):\n",
    "    img = image.copy()\n",
    "    print(img.shape)\n",
    "#     img = image.clone().detach()\n",
    "    for bbox in (bboxes):\n",
    "#         print(bbox)\n",
    "        img = visualize_bbox(img, bbox)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042650c-8304-4054-bf22-3169af602da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, _, _ = next(iter(test_loader))\n",
    "images, iou, _ , path = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "images = images.permute(0,3,1,2).to(device)\n",
    "# image = image.to(device)\n",
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda5567-e094-42ed-a581-1be40b256574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs.shape)\n",
    "# iou[0] > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f8a7a-7fcc-40a9-b8e1-b64ca9ba2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (outputs.view(2,15,15,2)[1,:,:,0] >= 0.999).sum()\n",
    "print((outputs.view(BATCH_SIZE,15,15,2)[1,:,:,0] > 0.9).sum() )\n",
    "print((outputs.view(BATCH_SIZE,15,15,2)[1,:,:,1] > 0.9).sum() )\n",
    "print(torch.max(outputs.view(BATCH_SIZE,15,15,2)[0,:,:,1]))\n",
    "print(torch.max(outputs.view(BATCH_SIZE,15,15,2)[1,:,:,1]))\n",
    "print(torch.max(outputs.view(BATCH_SIZE,15,15,2)[2,:,:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e7493-7b5d-4bb6-8b89-ce5570f34f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs.view(2,15,15,2)[1,:,:,0])\n",
    "# print(outputs.view(2,15,15,2)[1,:,:,1])\n",
    "# outputs.view(2,15,15,2)[1,:,:,0] > 0.5\n",
    "# torch.ge(outputs.view(2,15,15,2)[1,:,:,0], 0.5)\n",
    "# positive_indices[positive_indices==True]\n",
    "a, b = (outputs.view(BATCH_SIZE,15,15,2)[0,:,:,0] >= 0.9).cpu().detach().nonzero(as_tuple=True)\n",
    "# a, b = (outputs.view(BATCH_SIZE,15,15,2)[1,:,:,1] >= 0.15).cpu().detach().nonzero(as_tuple=True)\n",
    "# a, b = (iou.view(BATCH_SIZE,15,15)[0,:,:] >= 0.7).cpu().detach().nonzero(as_tuple=True)\n",
    "bboxes = []\n",
    "\n",
    "for x, y in zip(a, b) :\n",
    "#     print(int(x), int(y))\n",
    "    xmin = int(x) * 32\n",
    "    xmax = xmin + 64\n",
    "    ymin = int(y) * 32\n",
    "    ymax = ymin + 64\n",
    "    bboxes.append([xmin, ymin, xmax, ymax])\n",
    "bboxes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179cc44-30cc-4040-b2a4-43f70f1bfbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.view(2,15,15,2)[1,:,:,1] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954b7ae-fba3-47eb-83e6-eb3cdf0db314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fc9c5-f6b2-4908-865a-e6c4c9ff16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(images[1].permute(2,1,0).cpu().detach().numpy(), bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf2b96-30ff-4826-984c-461a311a7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(images[0].permute(2,1,0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bd0d8-2541-418e-b462-fa5f5a410cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
