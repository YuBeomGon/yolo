{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff7a0c4-5dd1-4178-99b6-4e8dc7c4d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is from below, pytorch torchvision github\n",
    "# https://github.com/pytorch/vision/tree/main/torchvision/models/detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fa3dce-1e68-4733-a880-56dc2a3c5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../data/')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch.optim as optim\n",
    "\n",
    "from _utils import warmup_lr_scheduler, reduce_dict\n",
    "from dataset import LbpDataset, train_transforms, val_transforms, test_transforms, collate_fn, get_data\n",
    "# from loss import LBPloss\n",
    "# from engine import train_one_epoch, evaluate\n",
    "from visualize import visualize\n",
    "from model import fasterrcnn_resnet101_fpn, fasterrcnn_resnet152_fpn, fasterrcnn_resnet18_fpn\n",
    "from anchor_utils import *\n",
    "from rpn import *\n",
    "from roi_heads import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e19d64-c86b-412b-8b5f-744218d3db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7593f28-cdaf-4b46-93ae-c10e9cd2dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0396d709-62f9-4f01-8a7f-b4d7f0be6136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(2048,), max_size=2048, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = fasterrcnn_resnet18_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.train()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57b7b7b-89f2-455e-a283-09b30b54c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa933b-79ac-40b0-b584-cf38f26c6708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef54ee2-f2d8-4749-ac10-6754a6b2ad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6736, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/df.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc00e65d-ae40-47ad-a356-868e6440326e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>task</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "      <th>occluded</th>\n",
       "      <th>des</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patch_images/2021.01.12/LBC305-20210108(1)/LBC...</td>\n",
       "      <td>[ASCUS] LBC305</td>\n",
       "      <td>[56, 35, 1980, 1985]</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>1980</td>\n",
       "      <td>1985</td>\n",
       "      <td>판독불가</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patch_images/2021.01.12/LBC305-20210108(1)/LBC...</td>\n",
       "      <td>[ASCUS] LBC305</td>\n",
       "      <td>[56, 30, 1912, 1937]</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>1912</td>\n",
       "      <td>1937</td>\n",
       "      <td>판독불가</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patch_images/2021.01.12/LBC305-20210108(1)/LBC...</td>\n",
       "      <td>[ASCUS] LBC305</td>\n",
       "      <td>[21, 12, 2010, 2027]</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>2027</td>\n",
       "      <td>판독불가</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patch_images/2021.01.06/LBC37-20210102(1)/LBC3...</td>\n",
       "      <td>[ASCUS] LBC37</td>\n",
       "      <td>[1349, 420, 100, 113]</td>\n",
       "      <td>1349</td>\n",
       "      <td>420</td>\n",
       "      <td>100</td>\n",
       "      <td>113</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atypical squamous cells of undetermined signif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patch_images/2021.01.06/LBC37-20210102(1)/LBC3...</td>\n",
       "      <td>[ASCUS] LBC37</td>\n",
       "      <td>[1575, 720, 163, 213]</td>\n",
       "      <td>1575</td>\n",
       "      <td>720</td>\n",
       "      <td>163</td>\n",
       "      <td>213</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atypical squamous cells of undetermined signif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name            task  \\\n",
       "0  patch_images/2021.01.12/LBC305-20210108(1)/LBC...  [ASCUS] LBC305   \n",
       "1  patch_images/2021.01.12/LBC305-20210108(1)/LBC...  [ASCUS] LBC305   \n",
       "2  patch_images/2021.01.12/LBC305-20210108(1)/LBC...  [ASCUS] LBC305   \n",
       "3  patch_images/2021.01.06/LBC37-20210102(1)/LBC3...   [ASCUS] LBC37   \n",
       "4  patch_images/2021.01.06/LBC37-20210102(1)/LBC3...   [ASCUS] LBC37   \n",
       "\n",
       "                    bbox  xmin  ymin     w     h   label  occluded  des  \\\n",
       "0   [56, 35, 1980, 1985]    56    35  1980  1985    판독불가         0  NaN   \n",
       "1   [56, 30, 1912, 1937]    56    30  1912  1937    판독불가         0  NaN   \n",
       "2   [21, 12, 2010, 2027]    21    12  2010  2027    판독불가         0  NaN   \n",
       "3  [1349, 420, 100, 113]  1349   420   100   113  ASC-US         0  NaN   \n",
       "4  [1575, 720, 163, 213]  1575   720   163   213  ASC-US         0  NaN   \n",
       "\n",
       "                                           cell_type  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Atypical squamous cells of undetermined signif...  \n",
       "4  Atypical squamous cells of undetermined signif...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b35505-1bda-41b9-97e5-b8e7dd018db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74fbc8b-43d0-439d-8ef6-48fb81aa535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_id'] = df.label.apply(lambda x : 1 if 'ASC-US' in x or 'ASC-US with HPV infection' in x \n",
    "                                or 'AS' in x else 0.)\n",
    "df = df[df['label_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6109e47d-d1c1-4125-83a9-7009defcfc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AS                           1947\n",
       "ASC-US                       1931\n",
       "ASC-US with HPV infection     724\n",
       "ASC-H                          75\n",
       "ASCUS-SIL                       2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "954ecc50-cdcf-4170-8c9b-a82005f4f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['xmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f7118e-4ae4-4ebf-860f-69692966bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['xdiff'] = df.apply(lambda x : x['xmax'] - x['xmin'], axis=1)\n",
    "df['xmax'] = df.apply(lambda x : x['xmin'] + x['w'], axis=1)\n",
    "df['ymax'] = df.apply(lambda x : x['ymin'] + x['h'], axis=1)\n",
    "df = df[['file_name', 'task', 'bbox', 'xmin', 'ymin', 'xmax', 'ymax', 'w', 'h', 'label',\n",
    "       'occluded', 'des', 'cell_type', 'label_id']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb1975b-6411-45c8-8d74-68c812ed27a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4019 train 3215 test 804\n",
      "3215\n",
      "804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_id': 'patch_images/2021.01.14/LBC426-20210111(1)/LBC426-20210111(1)_1005.png',\n",
       " 'boxes': array([[1728,  231, 1868,  365],\n",
       "        [1948,   85, 2047,  283],\n",
       "        [1354, 1778, 1513, 1951]]),\n",
       " 'labels': array([1., 1., 1.]),\n",
       " 'size': array([[140, 134],\n",
       "        [ 99, 198],\n",
       "        [159, 173]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group = df.groupby('file_name')\n",
    "df_list = df.file_name.unique()\n",
    "train_list, test_list = train_test_split(df_list, test_size=0.2, random_state=42)\n",
    "print('total {} train {} test {}'.format(len(df_list), len(train_list), len(test_list)))\n",
    "\n",
    "train_list = [get_data(img_id, df_group) for img_id in train_list]\n",
    "test_list = [get_data(img_id, df_group) for img_id in test_list]\n",
    "\n",
    "print(len(train_list))\n",
    "print(len(test_list))\n",
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d0a571-2d39-46be-a699-f537a264553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "train_dataset = LbpDataset(\n",
    "    train_list,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "#     pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_dataset = LbpDataset(\n",
    "    test_list,\n",
    "    transform=val_transforms,  \n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "#     pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73a421b5-4bb6-4d80-b46c-d7e1eb0f09f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'boxes': tensor([[1157.,  386., 1442.,  674.]]), 'labels': tensor([1])},\n",
       " {'boxes': tensor([[ 604.0713,    0.0000,  821.0779,  229.3168],\n",
       "          [ 873.2430,  437.4984, 1090.2496,  675.2693]]),\n",
       "  'labels': tensor([1, 1])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, targets, path = next(iter(train_loader))\n",
    "# print(path)\n",
    "print(images[0].shape)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58411dfa-4e18-472f-9ee1-7539ff9fd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in list(targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12f08891-af9d-42d3-b096-30f51f31f7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[1157.,  386., 1442.,  674.]], device='cuda:0'),\n",
       "  'labels': tensor([1], device='cuda:0')},\n",
       " {'boxes': tensor([[ 604.0713,    0.0000,  821.0779,  229.3168],\n",
       "          [ 873.2430,  437.4984, 1090.2496,  675.2693]], device='cuda:0'),\n",
       "  'labels': tensor([1, 1], device='cuda:0')}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c161338d-5ee5-4203-a755-53a9a19786f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = model.transform(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c45c38f-fa34-49e5-9bdd-23057eafc8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<image_list.ImageList at 0x7f5a64b32dd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "885e5f52-3eeb-4f59-a6ed-c5683e9aad36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "features = model.backbone(images.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee72fa69-9029-4528-960c-80a4cb806653",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals, proposal_losses = model.rpn(images, features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "819b2b19-8525-4205-b923-d48580e34226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proposals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61a623d2-3b5b-4ac2-aa3c-1cf76d8c449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals, matched_idxs, labels, regression_targets = model.roi_heads.select_training_samples(proposals, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f36dd472-3a59-4511-bf2d-6b172828a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42002a59-f8ef-45e2-a6ad-bbfbeb917e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_features = model.roi_heads.box_roi_pool(features, proposals, images.image_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7ce470e-5da4-468e-a07e-4070a44d7f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 256, 7, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5997fac-ed5e-4461-9887-10f5f3190414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9ca45-36ff-493d-993d-6f6c2f46474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7056ab8-11a4-4d0e-a5ec-911794e25368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378528b-d9d6-4e11-9157-bf79d49f996c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034282c8-3ee3-4cb2-9e14-7171a07983e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57938fbf-dc29-43ad-9022-754bfc30d3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfa883-eb43-4dcc-8509-eaf3b245ebbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3c60fea-d078-4a38-a76a-14bf3b5c3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections, detector_losses = model.roi_heads(features, proposals, images.image_sizes, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe8941c6-e57a-428e-b3b8-f60a55c21c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78026b7e-fca1-4daa-86e9-fa03e99db2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987dc7d9-c3c4-40a6-bea6-2442d34366b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d5d17-7673-4bd6-80dc-074674acd6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5abb7-4bf2-4988-9c74-e965cc4648c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f977bdd-a07b-4913-b037-ffbae823921c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32c598-1758-49db-8b94-f148c5ec1129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79e7bc-ca2b-4218-9f0f-94f5e77cb081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f78317a-079c-4d13-8232-7b10cdedc009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 64, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['3'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf7da948-7529-4849-b449-7b93822ca4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(features.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9eaf618-a051-44f2-ad3f-e5cb5b88b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPNHead(\n",
       "  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rpn.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db6bd4cb-2ab8-4019-9dbc-bc6d24112e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features.values())\n",
    "objectness, pred_bbox_deltas = model.rpn.head(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d464a926-b9d6-45c9-8049-3a0a761b8ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(objectness[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b769826a-b91e-49c6-8e95-503963a8c7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 32, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox_deltas[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "174eb55b-b14c-4dad-8de3-3ede134a30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = model.rpn.anchor_generator(images, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41132ffa-2ce3-4e23-ad1a-bc7c527c43f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1047552"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anchors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bae8842e-e2fc-4f93-9920-3186f9e8737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(anchors)\n",
    "num_anchors_per_level_shape_tensors = [o[0].shape for o in objectness]\n",
    "num_anchors_per_level = [s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors]\n",
    "objectness, pred_bbox_deltas = \\\n",
    "    concat_box_prediction_layers(objectness, pred_bbox_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a22283a3-c451-4e21-9584-41840c5f96fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[786432, 196608, 49152, 12288, 3072]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73271a57-a639-48e6-a68e-71f5940b770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = model.rpn.box_coder.decode(pred_bbox_deltas.detach(), anchors)\n",
    "proposals = proposals.view(num_images, -1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aeb3258-f8fb-4477-9def-1114c8f3b11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1047552, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(proposals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43dc557d-ba7c-493e-95c3-ab08857ca189",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, scores = model.rpn.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e577dae8-1350-497b-bedf-f7267bcf3119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e45c840-f4a3-49c6-bf1e-ac15650f2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, matched_gt_boxes = model.rpn.assign_targets_to_anchors(anchors, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0720728-b295-4310-aad7-0368c3527067",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_targets = model.rpn.box_coder.encode(matched_gt_boxes, anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10722220-7fa8-4d03-bc76-e1a3945b72c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1047552, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6d75d9e-ebfd-4771-9596-c82fb70c9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pos_inds, sampled_neg_inds = model.rpn.fg_bg_sampler(labels)\n",
    "sampled_pos_inds = torch.where(torch.cat(sampled_pos_inds, dim=0))[0]\n",
    "sampled_neg_inds = torch.where(torch.cat(sampled_neg_inds, dim=0))[0]\n",
    "sampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81b5d4bb-fe86-4d08-bb4f-908b5c477cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d9c7-d4d4-4ba5-a968-c21e1b48fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_objectness, loss_rpn_box_reg = self.compute_loss(objectness, pred_bbox_deltas, labels, regression_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b57ef24d-a537-47f5-845d-4bda45853f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1205,  0.0254, -0.0594,  0.0458],\n",
       "        [-0.1216,  0.0255, -0.0607,  0.0448],\n",
       "        [-0.1218,  0.0254, -0.0602,  0.0453],\n",
       "        [-0.1208,  0.0260, -0.0599,  0.0454],\n",
       "        [-0.1016, -0.0714, -0.0263,  0.0643],\n",
       "        [-0.1007, -0.0704, -0.0283,  0.0640],\n",
       "        [-0.1002, -0.0727, -0.0257,  0.0639],\n",
       "        [-0.0990, -0.0717, -0.0274,  0.0627]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox_deltas[sampled_pos_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c79c7-34aa-40e9-8f32-d959e8ffa3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60f6dc1d-2856-4e9d-998a-c1d9de2ee34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff78d33e-b6fe-4f43-b75a-9a2e210c461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals, proposal_losses = model.rpn(images, features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "246a68e2-a366-42f3-adff-f799b8e610b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proposals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9babd80-6860-4cdf-91ea-11ca8427bebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_objectness': tensor(0.6975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " 'loss_rpn_box_reg': tensor(0.0091, device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a56e4a96-884f-4289-83b5-fef67db491a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections, detector_losses = model.roi_heads(features, proposals, images.image_sizes, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e81f80f-5689-423b-bd71-0c29d8754cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "605d9e41-eeda-4623-9687-242f35d5772c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(0.7143, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       " 'loss_box_reg': tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b0496-cc8d-42e0-9989-beb646fe92ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95b3dd-29d6-4267-9e41-51bfde16b0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c57b148-616d-4e08-9879-0e55181374e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from faster_rcnn import FastRCNNPredictor\n",
    "# from mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    \n",
    "#     model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model = fasterrcnn_resnet152_fpn(pretrained=True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "#     # now get the number of input features for the mask classifier\n",
    "#     in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "#     hidden_layer = 256\n",
    "#     # and replace the mask predictor with a new one\n",
    "#     model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "#                                                        hidden_layer,\n",
    "#                                                        num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee4d17c-d42f-4f1a-bc9e-7aea11714e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# # For Training\n",
    "# images,targets, path = next(iter(train_loader))\n",
    "# # print(image[0].shape)\n",
    "# images = list(image for image in images)\n",
    "# targets = [{k: v for k, v in t.items()} for t in list(targets)]\n",
    "# output = model(images,targets)   # Returns losses and detections\n",
    "# # For inference\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfcf04b8-361c-4752-966f-7cd9fd7143b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "701244ef-ab1b-4f9a-a431-e3330e0b9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_epochs = 80\n",
    "saved_model = '../trained_models/resnet_2048/'\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.1,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4 )\n",
    "\n",
    "# # and a learning rate scheduler\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "#                                                step_size=3,\n",
    "#                                                gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d5a1331-8311-49e1-9085-cb81ff712c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f45474e-2ca4-4596-86a5-08b1356faa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235c354e-801a-4803-9fc2-93229c16cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1757 [00:00<?, ?it/s]/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 1757/1757 [27:23<00:00,  1.07it/s, epoch_loss=0.418, loss=0.126, lr=0.1] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.18, loss=0.081, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.162, loss=0.295, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.172, loss=0.244, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.181, loss=0.142, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.189, loss=0.191, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.06it/s, epoch_loss=0.189, loss=0.172, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.192, loss=0.145, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.197, loss=0.117, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.196, loss=0.152, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.195, loss=0.169, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.197, loss=0.281, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.197, loss=0.223, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.196, loss=0.116, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.196, loss=0.141, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.201, loss=0.132, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.198, loss=0.177, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.06it/s, epoch_loss=0.201, loss=0.257, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.2, loss=0.15, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.2, loss=0.204, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.199, loss=0.1, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.201, loss=0.284, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.201, loss=0.311, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:33<00:00,  1.06it/s, epoch_loss=0.197, loss=0.0988, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:35<00:00,  1.06it/s, epoch_loss=0.201, loss=0.162, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:36<00:00,  1.06it/s, epoch_loss=0.204, loss=0.857, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:36<00:00,  1.06it/s, epoch_loss=0.199, loss=0.126, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.197, loss=0.178, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:24<00:00,  1.07it/s, epoch_loss=0.199, loss=0.151, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:23<00:00,  1.07it/s, epoch_loss=0.198, loss=0.127, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:22<00:00,  1.07it/s, epoch_loss=0.2, loss=0.172, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:25<00:00,  1.07it/s, epoch_loss=0.199, loss=0.166, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:25<00:00,  1.07it/s, epoch_loss=0.202, loss=0.149, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:25<00:00,  1.07it/s, epoch_loss=0.204, loss=0.173, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.202, loss=0.198, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.197, loss=0.939, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.201, loss=0.0963, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.204, loss=0.208, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.201, loss=0.111, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.2, loss=0.103, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.196, loss=0.255, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.202, loss=0.153, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:22<00:00,  1.07it/s, epoch_loss=0.199, loss=0.169, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:20<00:00,  1.07it/s, epoch_loss=0.195, loss=0.129, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:19<00:00,  1.07it/s, epoch_loss=0.198, loss=0.22, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:19<00:00,  1.07it/s, epoch_loss=0.198, loss=0.161, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:21<00:00,  1.07it/s, epoch_loss=0.201, loss=0.247, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.197, loss=0.148, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.202, loss=0.134, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.198, loss=0.132, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.196, loss=0.227, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.195, loss=0.0257, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.199, loss=0.187, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.199, loss=0.155, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.199, loss=0.274, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.198, loss=0.114, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.197, loss=0.165, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.202, loss=0.127, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.198, loss=0.139, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.201, loss=0.0238, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.2, loss=0.217, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.2, loss=0.472, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.197, loss=0.322, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.196, loss=0.103, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.198, loss=0.0955, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.202, loss=0.211, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.199, loss=0.0758, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.2, loss=0.306, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.198, loss=0.255, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.197, loss=0.0767, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.201, loss=0.069, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.2, loss=0.508, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.2, loss=0.818, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.202, loss=0.287, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.199, loss=0.0913, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.199, loss=0.0237, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.198, loss=0.202, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.196, loss=0.154, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.198, loss=0.216, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:34<00:00,  1.06it/s, epoch_loss=0.198, loss=0.195, lr=0.0002] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "    EPOCH_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(train_loader) - 1)\n",
    "\n",
    "        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "        \n",
    "    batch_losses = []\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for images, targets, path in loop :\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in list(targets)]\n",
    "#         print(targets[0]['labels'])\n",
    "#         images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        loss_dict = model(images,targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        batch_losses.append(losses.item())\n",
    "        loop.set_postfix(epoch_loss=sum(batch_losses) / len(batch_losses), \n",
    "                         loss=losses.item(), lr=EPOCH_lr) \n",
    "        \n",
    "    if epoch % 10 == 9 : \n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }        \n",
    "        torch.save(state, saved_model + 'epoch_' + str(epoch) +'_model.pt')        \n",
    "        \n",
    "#     evaluate(model, test_loader, device=device)\n",
    "\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7b2afc-22d5-44c1-82d2-0cba3ec358b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = {\n",
    "#     'epoch': epoch,\n",
    "#     'state_dict': model.state_dict(),\n",
    "#     'optimizer': optimizer.state_dict(),\n",
    "# }        \n",
    "# torch.save(state, saved_model + 'epoch_' + str(epoch) +'_model.pt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf3b91ae-ebf9-488c-ae29-15fd40d4c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd\n"
     ]
    }
   ],
   "source": [
    "# saved_model = '../trained_models/'\n",
    "# device = torch.device('cpu')\n",
    "state = torch.load(saved_model  + 'epoch_' + str(59) + '_model.pt')\n",
    "model.load_state_dict(state['state_dict'])\n",
    "# model.load_state_dict(state['optimizer'])\n",
    "model.eval()\n",
    "print('dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f320158-973d-4463-9f78-e6e3b2801373",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, paths = next(iter(test_loader))\n",
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in list(targets)]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfcfc3f1-405a-4312-b1e7-0610ddab0107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0115ecd61432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "NUM = 0\n",
    "threshold = 0.3\n",
    "image = images[NUM].permute(1,2,0).cpu().numpy() * 255.\n",
    "pred_scores = predictions[NUM]['scores'].detach().cpu().numpy()\n",
    "pred_bbox = predictions[NUM]['boxes'][:].detach().cpu().numpy()\n",
    "# print(pred_bbox)\n",
    "boxes = []\n",
    "print('highest score', pred_scores[0:2])\n",
    "for i, s in enumerate(pred_scores) :\n",
    "    if s > threshold :\n",
    "        boxes.append(pred_bbox[i])\n",
    "    else :\n",
    "        break\n",
    "\n",
    "visualize(image , bboxes=boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e94250f-ff5b-4675-b8fc-23c9358d2a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d3256cefc938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mabs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/Dataset/scl/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "img_path = paths[NUM]\n",
    "abs_path = '/home/Dataset/scl/'\n",
    "\n",
    "train_image = cv2.imread(abs_path + img_path)\n",
    "train_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2RGB)\n",
    "boxes = get_data(img_path, df_group)['boxes']\n",
    "# boxes = targets[NUM]['boxes'].cpu().numpy()\n",
    "print(boxes)\n",
    "# boxes[:,2] = boxes[:,0] + boxes[:,2]\n",
    "# boxes[:,3] = boxes[:,1] + boxes[:,3]\n",
    "\n",
    "visualize(train_image, boxes[:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9712ad7-3bb0-452d-b91c-2ed996a93529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97ce89-2148-4635-ac63-adfd74263438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e953e-dc23-4f8d-a391-569fec08f089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
