{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff7a0c4-5dd1-4178-99b6-4e8dc7c4d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is from below, pytorch torchvision github\n",
    "# https://github.com/pytorch/vision/tree/main/torchvision/models/detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fa3dce-1e68-4733-a880-56dc2a3c5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../data/')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch.optim as optim\n",
    "\n",
    "from _utils import warmup_lr_scheduler, reduce_dict\n",
    "from dataset import LbpDataset, train_transforms, val_transforms, test_transforms, collate_fn, get_data\n",
    "# from loss import LBPloss\n",
    "# from engine import train_one_epoch, evaluate\n",
    "from visualize import visualize\n",
    "from model import fasterrcnn_resnet101_fpn, fasterrcnn_resnet152_fpn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e19d64-c86b-412b-8b5f-744218d3db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0396d709-62f9-4f01-8a7f-b4d7f0be6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "model = fasterrcnn_resnet152_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57b7b7b-89f2-455e-a283-09b30b54c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa933b-79ac-40b0-b584-cf38f26c6708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef54ee2-f2d8-4749-ac10-6754a6b2ad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4211, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/df.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc00e65d-ae40-47ad-a356-868e6440326e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>task</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "      <th>occluded</th>\n",
       "      <th>des</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patch_images/2021.01.12/LBC305-20210108(1)/LBC...</td>\n",
       "      <td>[ASCUS] LBC305</td>\n",
       "      <td>[56, 35, 1980, 1985]</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>1980</td>\n",
       "      <td>1985</td>\n",
       "      <td>판독불가</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patch_images/2021.01.12/LBC305-20210108(1)/LBC...</td>\n",
       "      <td>[ASCUS] LBC305</td>\n",
       "      <td>[56, 30, 1912, 1937]</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>1912</td>\n",
       "      <td>1937</td>\n",
       "      <td>판독불가</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patch_images/2021.01.12/LBC305-20210108(1)/LBC...</td>\n",
       "      <td>[ASCUS] LBC305</td>\n",
       "      <td>[21, 12, 2010, 2027]</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>2027</td>\n",
       "      <td>판독불가</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patch_images/2021.01.06/LBC37-20210102(1)/LBC3...</td>\n",
       "      <td>[ASCUS] LBC37</td>\n",
       "      <td>[1349, 420, 100, 113]</td>\n",
       "      <td>1349</td>\n",
       "      <td>420</td>\n",
       "      <td>100</td>\n",
       "      <td>113</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atypical squamous cells of undetermined signif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patch_images/2021.01.06/LBC37-20210102(1)/LBC3...</td>\n",
       "      <td>[ASCUS] LBC37</td>\n",
       "      <td>[1575, 720, 163, 213]</td>\n",
       "      <td>1575</td>\n",
       "      <td>720</td>\n",
       "      <td>163</td>\n",
       "      <td>213</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atypical squamous cells of undetermined signif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name            task  \\\n",
       "0  patch_images/2021.01.12/LBC305-20210108(1)/LBC...  [ASCUS] LBC305   \n",
       "1  patch_images/2021.01.12/LBC305-20210108(1)/LBC...  [ASCUS] LBC305   \n",
       "2  patch_images/2021.01.12/LBC305-20210108(1)/LBC...  [ASCUS] LBC305   \n",
       "3  patch_images/2021.01.06/LBC37-20210102(1)/LBC3...   [ASCUS] LBC37   \n",
       "4  patch_images/2021.01.06/LBC37-20210102(1)/LBC3...   [ASCUS] LBC37   \n",
       "\n",
       "                    bbox  xmin  ymin     w     h   label  occluded  des  \\\n",
       "0   [56, 35, 1980, 1985]    56    35  1980  1985    판독불가         0  NaN   \n",
       "1   [56, 30, 1912, 1937]    56    30  1912  1937    판독불가         0  NaN   \n",
       "2   [21, 12, 2010, 2027]    21    12  2010  2027    판독불가         0  NaN   \n",
       "3  [1349, 420, 100, 113]  1349   420   100   113  ASC-US         0  NaN   \n",
       "4  [1575, 720, 163, 213]  1575   720   163   213  ASC-US         0  NaN   \n",
       "\n",
       "                                           cell_type  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Atypical squamous cells of undetermined signif...  \n",
       "4  Atypical squamous cells of undetermined signif...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b35505-1bda-41b9-97e5-b8e7dd018db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f74fbc8b-43d0-439d-8ef6-48fb81aa535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_id'] = df.label.apply(lambda x : 1 if 'ASC-US' in x or 'ASC-US with HPV infection' in x \n",
    "                                or 'AS' in x else 0.)\n",
    "df = df[df['label_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6109e47d-d1c1-4125-83a9-7009defcfc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASC-US                       1502\n",
       "ASC-US with HPV infection     656\n",
       "AS                            461\n",
       "ASC-H                          74\n",
       "ASCUS-SIL                       2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "954ecc50-cdcf-4170-8c9b-a82005f4f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['xmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f7118e-4ae4-4ebf-860f-69692966bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['xdiff'] = df.apply(lambda x : x['xmax'] - x['xmin'], axis=1)\n",
    "df['xmax'] = df.apply(lambda x : x['xmin'] + x['w'], axis=1)\n",
    "df['ymax'] = df.apply(lambda x : x['ymin'] + x['h'], axis=1)\n",
    "df = df[['file_name', 'task', 'bbox', 'xmin', 'ymin', 'xmax', 'ymax', 'w', 'h', 'label',\n",
    "       'occluded', 'des', 'cell_type', 'label_id']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb1975b-6411-45c8-8d74-68c812ed27a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2197 train 1757 test 440\n",
      "1757\n",
      "440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_id': 'patch_images/2021.01.06/LBC40-20210102(1)/LBC40-20210102(1)_1712.png',\n",
       " 'boxes': array([[1146,  238, 1384,  544]]),\n",
       " 'labels': array([1.]),\n",
       " 'size': array([[238, 306]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group = df.groupby('file_name')\n",
    "df_list = df.file_name.unique()\n",
    "train_list, test_list = train_test_split(df_list, test_size=0.2, random_state=42)\n",
    "print('total {} train {} test {}'.format(len(df_list), len(train_list), len(test_list)))\n",
    "\n",
    "train_list = [get_data(img_id, df_group) for img_id in train_list]\n",
    "test_list = [get_data(img_id, df_group) for img_id in test_list]\n",
    "\n",
    "print(len(train_list))\n",
    "print(len(test_list))\n",
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d0a571-2d39-46be-a699-f537a264553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "train_dataset = LbpDataset(\n",
    "    train_list,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "#     pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_dataset = LbpDataset(\n",
    "    test_list,\n",
    "    transform=val_transforms,  \n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "#     pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a421b5-4bb6-4d80-b46c-d7e1eb0f09f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'boxes': tensor([[1063.4437,  795.5042, 1192.5322,  946.7064]]),\n",
       "  'labels': tensor([1])},)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, targets, path = next(iter(train_loader))\n",
    "# print(path)\n",
    "print(images[0].shape)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c57b148-616d-4e08-9879-0e55181374e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from faster_rcnn import FastRCNNPredictor\n",
    "# from mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    \n",
    "#     model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model = fasterrcnn_resnet152_fpn(pretrained=True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "#     # now get the number of input features for the mask classifier\n",
    "#     in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "#     hidden_layer = 256\n",
    "#     # and replace the mask predictor with a new one\n",
    "#     model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "#                                                        hidden_layer,\n",
    "#                                                        num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee4d17c-d42f-4f1a-bc9e-7aea11714e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# # For Training\n",
    "# images,targets, path = next(iter(train_loader))\n",
    "# # print(image[0].shape)\n",
    "# images = list(image for image in images)\n",
    "# targets = [{k: v for k, v in t.items()} for t in list(targets)]\n",
    "# output = model(images,targets)   # Returns losses and detections\n",
    "# # For inference\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfcf04b8-361c-4752-966f-7cd9fd7143b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "701244ef-ab1b-4f9a-a431-e3330e0b9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_epochs = 80\n",
    "saved_model = '../trained_models/resnet_2048/'\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.1,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4 )\n",
    "\n",
    "# # and a learning rate scheduler\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "#                                                step_size=3,\n",
    "#                                                gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d5a1331-8311-49e1-9085-cb81ff712c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f45474e-2ca4-4596-86a5-08b1356faa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235c354e-801a-4803-9fc2-93229c16cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1757 [00:00<?, ?it/s]/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 1757/1757 [27:23<00:00,  1.07it/s, epoch_loss=0.418, loss=0.126, lr=0.1] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.18, loss=0.081, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.162, loss=0.295, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.172, loss=0.244, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.181, loss=0.142, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.189, loss=0.191, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.06it/s, epoch_loss=0.189, loss=0.172, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.192, loss=0.145, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.197, loss=0.117, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.196, loss=0.152, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.195, loss=0.169, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.197, loss=0.281, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.197, loss=0.223, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.196, loss=0.116, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.196, loss=0.141, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.201, loss=0.132, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.198, loss=0.177, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.06it/s, epoch_loss=0.201, loss=0.257, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.2, loss=0.15, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.2, loss=0.204, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.199, loss=0.1, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.201, loss=0.284, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.201, loss=0.311, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:33<00:00,  1.06it/s, epoch_loss=0.197, loss=0.0988, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:35<00:00,  1.06it/s, epoch_loss=0.201, loss=0.162, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:36<00:00,  1.06it/s, epoch_loss=0.204, loss=0.857, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:36<00:00,  1.06it/s, epoch_loss=0.199, loss=0.126, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.197, loss=0.178, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:24<00:00,  1.07it/s, epoch_loss=0.199, loss=0.151, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:23<00:00,  1.07it/s, epoch_loss=0.198, loss=0.127, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:22<00:00,  1.07it/s, epoch_loss=0.2, loss=0.172, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:25<00:00,  1.07it/s, epoch_loss=0.199, loss=0.166, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:25<00:00,  1.07it/s, epoch_loss=0.202, loss=0.149, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:25<00:00,  1.07it/s, epoch_loss=0.204, loss=0.173, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.202, loss=0.198, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.197, loss=0.939, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.201, loss=0.0963, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.204, loss=0.208, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.201, loss=0.111, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.2, loss=0.103, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.196, loss=0.255, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.202, loss=0.153, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:22<00:00,  1.07it/s, epoch_loss=0.199, loss=0.169, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:20<00:00,  1.07it/s, epoch_loss=0.195, loss=0.129, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:19<00:00,  1.07it/s, epoch_loss=0.198, loss=0.22, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:19<00:00,  1.07it/s, epoch_loss=0.198, loss=0.161, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:21<00:00,  1.07it/s, epoch_loss=0.201, loss=0.247, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.197, loss=0.148, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.202, loss=0.134, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.198, loss=0.132, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.196, loss=0.227, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.195, loss=0.0257, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.199, loss=0.187, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.199, loss=0.155, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.199, loss=0.274, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.198, loss=0.114, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.197, loss=0.165, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:31<00:00,  1.06it/s, epoch_loss=0.202, loss=0.127, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.198, loss=0.139, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.201, loss=0.0238, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.2, loss=0.217, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.2, loss=0.472, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:29<00:00,  1.07it/s, epoch_loss=0.197, loss=0.322, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.196, loss=0.103, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.198, loss=0.0955, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.202, loss=0.211, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.199, loss=0.0758, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:28<00:00,  1.07it/s, epoch_loss=0.2, loss=0.306, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.198, loss=0.255, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.197, loss=0.0767, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.201, loss=0.069, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:26<00:00,  1.07it/s, epoch_loss=0.2, loss=0.508, lr=0.0002]    \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.2, loss=0.818, lr=0.0002]   \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.202, loss=0.287, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:27<00:00,  1.07it/s, epoch_loss=0.199, loss=0.0913, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:30<00:00,  1.06it/s, epoch_loss=0.199, loss=0.0237, lr=0.0002]\n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.198, loss=0.202, lr=0.0002] \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.196, loss=0.154, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:32<00:00,  1.06it/s, epoch_loss=0.198, loss=0.216, lr=0.0002]  \n",
      "100%|██████████| 1757/1757 [27:34<00:00,  1.06it/s, epoch_loss=0.198, loss=0.195, lr=0.0002] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "    EPOCH_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(train_loader) - 1)\n",
    "\n",
    "        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "        \n",
    "    batch_losses = []\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for images, targets, path in loop :\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in list(targets)]\n",
    "#         print(targets[0]['labels'])\n",
    "#         images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        loss_dict = model(images,targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        batch_losses.append(losses.item())\n",
    "        loop.set_postfix(epoch_loss=sum(batch_losses) / len(batch_losses), \n",
    "                         loss=losses.item(), lr=EPOCH_lr) \n",
    "        \n",
    "    if epoch % 10 == 9 : \n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }        \n",
    "        torch.save(state, saved_model + 'epoch_' + str(epoch) +'_model.pt')        \n",
    "        \n",
    "#     evaluate(model, test_loader, device=device)\n",
    "\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7b2afc-22d5-44c1-82d2-0cba3ec358b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = {\n",
    "#     'epoch': epoch,\n",
    "#     'state_dict': model.state_dict(),\n",
    "#     'optimizer': optimizer.state_dict(),\n",
    "# }        \n",
    "# torch.save(state, saved_model + 'epoch_' + str(epoch) +'_model.pt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf3b91ae-ebf9-488c-ae29-15fd40d4c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd\n"
     ]
    }
   ],
   "source": [
    "# saved_model = '../trained_models/'\n",
    "# device = torch.device('cpu')\n",
    "state = torch.load(saved_model  + 'epoch_' + str(59) + '_model.pt')\n",
    "model.load_state_dict(state['state_dict'])\n",
    "# model.load_state_dict(state['optimizer'])\n",
    "model.eval()\n",
    "print('dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f320158-973d-4463-9f78-e6e3b2801373",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, paths = next(iter(test_loader))\n",
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in list(targets)]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfcfc3f1-405a-4312-b1e7-0610ddab0107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0115ecd61432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "NUM = 0\n",
    "threshold = 0.3\n",
    "image = images[NUM].permute(1,2,0).cpu().numpy() * 255.\n",
    "pred_scores = predictions[NUM]['scores'].detach().cpu().numpy()\n",
    "pred_bbox = predictions[NUM]['boxes'][:].detach().cpu().numpy()\n",
    "# print(pred_bbox)\n",
    "boxes = []\n",
    "print('highest score', pred_scores[0:2])\n",
    "for i, s in enumerate(pred_scores) :\n",
    "    if s > threshold :\n",
    "        boxes.append(pred_bbox[i])\n",
    "    else :\n",
    "        break\n",
    "\n",
    "visualize(image , bboxes=boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e94250f-ff5b-4675-b8fc-23c9358d2a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d3256cefc938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mabs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/Dataset/scl/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "img_path = paths[NUM]\n",
    "abs_path = '/home/Dataset/scl/'\n",
    "\n",
    "train_image = cv2.imread(abs_path + img_path)\n",
    "train_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2RGB)\n",
    "boxes = get_data(img_path, df_group)['boxes']\n",
    "# boxes = targets[NUM]['boxes'].cpu().numpy()\n",
    "print(boxes)\n",
    "# boxes[:,2] = boxes[:,0] + boxes[:,2]\n",
    "# boxes[:,3] = boxes[:,1] + boxes[:,3]\n",
    "\n",
    "visualize(train_image, boxes[:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9712ad7-3bb0-452d-b91c-2ed996a93529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97ce89-2148-4635-ac63-adfd74263438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e953e-dc23-4f8d-a391-569fec08f089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
