{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ab6313-698a-46cc-9ab4-770b35f86211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from resnet import *\n",
    "\n",
    "from main import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56508d67-5301-4e1e-9454-1fe41b5f3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args(args=[])\n",
    "# args = parser.parse_args()\n",
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch-size\": 256, \n",
    "                          \"epochs\": 100, \n",
    "                          \"data\": 0, \n",
    "                          'arch':'resnet18',\n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':90,\n",
    "                         'gpu':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea598abf-d5fe-4f70-8cbf-78ad6038e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "device = 'cpu'\n",
    "#device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e9ebbf-4193-412c-b416-9faccf6aac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "print(\"=> using pre-trained model '{}'\".format('resnet18'))\n",
    "# model = models.__dict__['resnet18'](pretrained=True)\n",
    "# model = models.resnet18(pretrained=True)\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8910807d-3862-4446-a811-530857664cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "torch.Size([64, 3, 7, 7])\n",
      "bn1.weight\n",
      "torch.Size([64])\n",
      "bn1.bias\n",
      "torch.Size([64])\n",
      "bn1.running_mean\n",
      "torch.Size([64])\n",
      "bn1.running_var\n",
      "torch.Size([64])\n",
      "bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer1.0.conv1.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn1.weight\n",
      "torch.Size([64])\n",
      "layer1.0.bn1.bias\n",
      "torch.Size([64])\n",
      "layer1.0.bn1.running_mean\n",
      "torch.Size([64])\n",
      "layer1.0.bn1.running_var\n",
      "torch.Size([64])\n",
      "layer1.0.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer1.0.conv2.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight\n",
      "torch.Size([64])\n",
      "layer1.0.bn2.bias\n",
      "torch.Size([64])\n",
      "layer1.0.bn2.running_mean\n",
      "torch.Size([64])\n",
      "layer1.0.bn2.running_var\n",
      "torch.Size([64])\n",
      "layer1.0.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer1.1.conv1.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn1.weight\n",
      "torch.Size([64])\n",
      "layer1.1.bn1.bias\n",
      "torch.Size([64])\n",
      "layer1.1.bn1.running_mean\n",
      "torch.Size([64])\n",
      "layer1.1.bn1.running_var\n",
      "torch.Size([64])\n",
      "layer1.1.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer1.1.conv2.weight\n",
      "torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight\n",
      "torch.Size([64])\n",
      "layer1.1.bn2.bias\n",
      "torch.Size([64])\n",
      "layer1.1.bn2.running_mean\n",
      "torch.Size([64])\n",
      "layer1.1.bn2.running_var\n",
      "torch.Size([64])\n",
      "layer1.1.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer2.0.conv1.weight\n",
      "torch.Size([128, 64, 3, 3])\n",
      "layer2.0.bn1.weight\n",
      "torch.Size([128])\n",
      "layer2.0.bn1.bias\n",
      "torch.Size([128])\n",
      "layer2.0.bn1.running_mean\n",
      "torch.Size([128])\n",
      "layer2.0.bn1.running_var\n",
      "torch.Size([128])\n",
      "layer2.0.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer2.0.conv2.weight\n",
      "torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight\n",
      "torch.Size([128])\n",
      "layer2.0.bn2.bias\n",
      "torch.Size([128])\n",
      "layer2.0.bn2.running_mean\n",
      "torch.Size([128])\n",
      "layer2.0.bn2.running_var\n",
      "torch.Size([128])\n",
      "layer2.0.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer2.0.downsample.0.weight\n",
      "torch.Size([128, 64, 1, 1])\n",
      "layer2.0.downsample.1.weight\n",
      "torch.Size([128])\n",
      "layer2.0.downsample.1.bias\n",
      "torch.Size([128])\n",
      "layer2.0.downsample.1.running_mean\n",
      "torch.Size([128])\n",
      "layer2.0.downsample.1.running_var\n",
      "torch.Size([128])\n",
      "layer2.0.downsample.1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer2.1.conv1.weight\n",
      "torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn1.weight\n",
      "torch.Size([128])\n",
      "layer2.1.bn1.bias\n",
      "torch.Size([128])\n",
      "layer2.1.bn1.running_mean\n",
      "torch.Size([128])\n",
      "layer2.1.bn1.running_var\n",
      "torch.Size([128])\n",
      "layer2.1.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer2.1.conv2.weight\n",
      "torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight\n",
      "torch.Size([128])\n",
      "layer2.1.bn2.bias\n",
      "torch.Size([128])\n",
      "layer2.1.bn2.running_mean\n",
      "torch.Size([128])\n",
      "layer2.1.bn2.running_var\n",
      "torch.Size([128])\n",
      "layer2.1.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer3.0.conv1.weight\n",
      "torch.Size([256, 128, 3, 3])\n",
      "layer3.0.bn1.weight\n",
      "torch.Size([256])\n",
      "layer3.0.bn1.bias\n",
      "torch.Size([256])\n",
      "layer3.0.bn1.running_mean\n",
      "torch.Size([256])\n",
      "layer3.0.bn1.running_var\n",
      "torch.Size([256])\n",
      "layer3.0.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer3.0.conv2.weight\n",
      "torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight\n",
      "torch.Size([256])\n",
      "layer3.0.bn2.bias\n",
      "torch.Size([256])\n",
      "layer3.0.bn2.running_mean\n",
      "torch.Size([256])\n",
      "layer3.0.bn2.running_var\n",
      "torch.Size([256])\n",
      "layer3.0.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer3.0.downsample.0.weight\n",
      "torch.Size([256, 128, 1, 1])\n",
      "layer3.0.downsample.1.weight\n",
      "torch.Size([256])\n",
      "layer3.0.downsample.1.bias\n",
      "torch.Size([256])\n",
      "layer3.0.downsample.1.running_mean\n",
      "torch.Size([256])\n",
      "layer3.0.downsample.1.running_var\n",
      "torch.Size([256])\n",
      "layer3.0.downsample.1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer3.1.conv1.weight\n",
      "torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn1.weight\n",
      "torch.Size([256])\n",
      "layer3.1.bn1.bias\n",
      "torch.Size([256])\n",
      "layer3.1.bn1.running_mean\n",
      "torch.Size([256])\n",
      "layer3.1.bn1.running_var\n",
      "torch.Size([256])\n",
      "layer3.1.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer3.1.conv2.weight\n",
      "torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight\n",
      "torch.Size([256])\n",
      "layer3.1.bn2.bias\n",
      "torch.Size([256])\n",
      "layer3.1.bn2.running_mean\n",
      "torch.Size([256])\n",
      "layer3.1.bn2.running_var\n",
      "torch.Size([256])\n",
      "layer3.1.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer4.0.conv1.weight\n",
      "torch.Size([512, 256, 3, 3])\n",
      "layer4.0.bn1.weight\n",
      "torch.Size([512])\n",
      "layer4.0.bn1.bias\n",
      "torch.Size([512])\n",
      "layer4.0.bn1.running_mean\n",
      "torch.Size([512])\n",
      "layer4.0.bn1.running_var\n",
      "torch.Size([512])\n",
      "layer4.0.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer4.0.conv2.weight\n",
      "torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight\n",
      "torch.Size([512])\n",
      "layer4.0.bn2.bias\n",
      "torch.Size([512])\n",
      "layer4.0.bn2.running_mean\n",
      "torch.Size([512])\n",
      "layer4.0.bn2.running_var\n",
      "torch.Size([512])\n",
      "layer4.0.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer4.0.downsample.0.weight\n",
      "torch.Size([512, 256, 1, 1])\n",
      "layer4.0.downsample.1.weight\n",
      "torch.Size([512])\n",
      "layer4.0.downsample.1.bias\n",
      "torch.Size([512])\n",
      "layer4.0.downsample.1.running_mean\n",
      "torch.Size([512])\n",
      "layer4.0.downsample.1.running_var\n",
      "torch.Size([512])\n",
      "layer4.0.downsample.1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer4.1.conv1.weight\n",
      "torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn1.weight\n",
      "torch.Size([512])\n",
      "layer4.1.bn1.bias\n",
      "torch.Size([512])\n",
      "layer4.1.bn1.running_mean\n",
      "torch.Size([512])\n",
      "layer4.1.bn1.running_var\n",
      "torch.Size([512])\n",
      "layer4.1.bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "layer4.1.conv2.weight\n",
      "torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight\n",
      "torch.Size([512])\n",
      "layer4.1.bn2.bias\n",
      "torch.Size([512])\n",
      "layer4.1.bn2.running_mean\n",
      "torch.Size([512])\n",
      "layer4.1.bn2.running_var\n",
      "torch.Size([512])\n",
      "layer4.1.bn2.num_batches_tracked\n",
      "torch.Size([])\n",
      "fc.weight\n",
      "torch.Size([1000, 512])\n",
      "fc.bias\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "model_dict = model.state_dict() \n",
    "for k in model_dict :\n",
    "    print(k)\n",
    "    print(model_dict[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5493c8ea-4540-4067-8954-9e7a73cb10da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cd832a-5720-4925-9d50-36b16480132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "data_dir = '../ILSVRC/Data/CLS-LOC/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb79f3f-e8a8-4e0d-9a55-f7dbf5c08236",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4460bdaa-261a-4858-a94c-c70aebd6fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beece8cc-7ac9-4e30-8cca-0ca4adbd58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=(train_sampler is None),\n",
    "    num_workers=8, pin_memory=True, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53171b34-4e2f-4b1b-ae3f-d8d2db58b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25092250-abbb-482c-bb3a-3c279e593859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/5005]\tTime  2.857 ( 2.857)\tData  2.362 ( 2.362)\tLoss 1.3540e+00 (1.3540e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  86.72 ( 86.72)\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "acc1 = 0\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    # train for one epoch\n",
    "    epoch_loss = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, args)  \n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    val_acc.append(acc1)\n",
    "    print('************train_loss {} val_acc {}*************'.format(epoch_loss, acc1))\n",
    "    \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "#     if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "#             and args.rank % ngpus_per_node == 0):\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6de6a0-a209-4b66-b52d-322f333aacae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48e851-7663-40f7-b4d8-417cc3498927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
