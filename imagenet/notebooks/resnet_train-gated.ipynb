{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ab6313-698a-46cc-9ab4-770b35f86211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "# from resnet import *\n",
    "\n",
    "from main import *\n",
    "from gated import *\n",
    "from resnet_gated import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56508d67-5301-4e1e-9454-1fe41b5f3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args(args=[])\n",
    "# args = parser.parse_args()\n",
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch-size\": 256, \n",
    "                          \"epochs\": 100, \n",
    "                          \"data\": 0, \n",
    "                          'arch':'resnet18',\n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea598abf-d5fe-4f70-8cbf-78ad6038e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "# device = 'cpu'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e9ebbf-4193-412c-b416-9faccf6aac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilation [False, False, False]\n",
      "stride 1\n",
      "downsample\n",
      "stride 2\n",
      "downsample\n",
      "stride 2\n",
      "downsample\n",
      "stride 2\n"
     ]
    }
   ],
   "source": [
    "# print(\"=> using pre-trained model '{}'\".format('resnet18'))\n",
    "# model = models.__dict__['resnet18'](pretrained=True)\n",
    "# model = models.resnet18(pretrained=True)\n",
    "model = resnet18(pretrained=False)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8910807d-3862-4446-a811-530857664cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = model.state_dict() \n",
    "# for k in model_dict :\n",
    "#     print(k)\n",
    "#     print(model_dict[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5493c8ea-4540-4067-8954-9e7a73cb10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cd832a-5720-4925-9d50-36b16480132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "data_dir = '../ILSVRC/Data/CLS-LOC/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb79f3f-e8a8-4e0d-9a55-f7dbf5c08236",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4460bdaa-261a-4858-a94c-c70aebd6fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beece8cc-7ac9-4e30-8cca-0ca4adbd58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=96, \n",
    "    shuffle=(train_sampler is None),\n",
    "    num_workers=12, \n",
    "#     pin_memory=True, \n",
    "    sampler=train_sampler)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    num_workers=12, )\n",
    "#     pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53171b34-4e2f-4b1b-ae3f-d8d2db58b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25092250-abbb-482c-bb3a-3c279e593859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][    0/13346]\tTime  1.547 ( 1.547)\tData  1.191 ( 1.191)\tLoss 7.0724e+00 (7.0724e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 16.246 Acc@5 36.214\n",
      "************train_loss 5.311251977296421 val_acc 16.246179580688477*************\n",
      "Epoch: [1][    0/13346]\tTime  1.467 ( 1.467)\tData  1.397 ( 1.397)\tLoss 4.3883e+00 (4.3883e+00)\tAcc@1  15.62 ( 15.62)\tAcc@5  34.38 ( 34.38)\n",
      " * Acc@1 25.315 Acc@5 49.208\n",
      "************train_loss 4.132702326910366 val_acc 25.31511688232422*************\n",
      "Epoch: [2][    0/13346]\tTime  1.447 ( 1.447)\tData  1.364 ( 1.364)\tLoss 3.5355e+00 (3.5355e+00)\tAcc@1  26.04 ( 26.04)\tAcc@5  58.33 ( 58.33)\n",
      " * Acc@1 27.604 Acc@5 52.104\n",
      "************train_loss 3.765541959609225 val_acc 27.604324340820312*************\n",
      "Epoch: [3][    0/13346]\tTime  1.356 ( 1.356)\tData  1.241 ( 1.241)\tLoss 3.1416e+00 (3.1416e+00)\tAcc@1  35.42 ( 35.42)\tAcc@5  57.29 ( 57.29)\n",
      " * Acc@1 30.139 Acc@5 55.784\n",
      "************train_loss 3.592500311117488 val_acc 30.139230728149414*************\n",
      "Epoch: [4][    0/13346]\tTime  1.355 ( 1.355)\tData  1.266 ( 1.266)\tLoss 3.5464e+00 (3.5464e+00)\tAcc@1  29.17 ( 29.17)\tAcc@5  57.29 ( 57.29)\n",
      " * Acc@1 31.464 Acc@5 56.759\n",
      "************train_loss 3.498935971198617 val_acc 31.46361541748047*************\n",
      "Epoch: [5][    0/13346]\tTime  1.382 ( 1.382)\tData  1.304 ( 1.304)\tLoss 3.5036e+00 (3.5036e+00)\tAcc@1  26.04 ( 26.04)\tAcc@5  47.92 ( 47.92)\n",
      " * Acc@1 32.486 Acc@5 58.607\n",
      "************train_loss 3.443399604892831 val_acc 32.486366271972656*************\n",
      "Epoch: [6][    0/13346]\tTime  1.360 ( 1.360)\tData  1.279 ( 1.279)\tLoss 3.4246e+00 (3.4246e+00)\tAcc@1  35.42 ( 35.42)\tAcc@5  57.29 ( 57.29)\n",
      " * Acc@1 31.977 Acc@5 57.502\n",
      "************train_loss 3.39614669211565 val_acc 31.97698974609375*************\n",
      "Epoch: [7][    0/13346]\tTime  1.287 ( 1.287)\tData  1.213 ( 1.213)\tLoss 3.6250e+00 (3.6250e+00)\tAcc@1  26.04 ( 26.04)\tAcc@5  48.96 ( 48.96)\n",
      " * Acc@1 33.743 Acc@5 59.589\n",
      "************train_loss 3.3659379192687005 val_acc 33.742835998535156*************\n",
      "Epoch: [8][    0/13346]\tTime  1.319 ( 1.319)\tData  1.214 ( 1.214)\tLoss 2.9809e+00 (2.9809e+00)\tAcc@1  35.42 ( 35.42)\tAcc@5  65.62 ( 65.62)\n",
      " * Acc@1 34.310 Acc@5 60.486\n",
      "************train_loss 3.3413476716198343 val_acc 34.310142517089844*************\n",
      "Epoch: [9][    0/13346]\tTime  1.278 ( 1.278)\tData  1.184 ( 1.184)\tLoss 3.1992e+00 (3.1992e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  56.25 ( 56.25)\n",
      " * Acc@1 34.792 Acc@5 60.980\n",
      "************train_loss 3.3196938153455124 val_acc 34.79155731201172*************\n",
      "Epoch: [10][    0/13346]\tTime  1.285 ( 1.285)\tData  1.187 ( 1.187)\tLoss 3.1525e+00 (3.1525e+00)\tAcc@1  30.21 ( 30.21)\tAcc@5  60.42 ( 60.42)\n",
      " * Acc@1 31.573 Acc@5 57.150\n",
      "************train_loss 3.3020510838768855 val_acc 31.5734806060791*************\n",
      "Epoch: [11][    0/13346]\tTime  1.306 ( 1.306)\tData  1.224 ( 1.224)\tLoss 3.4232e+00 (3.4232e+00)\tAcc@1  30.21 ( 30.21)\tAcc@5  48.96 ( 48.96)\n",
      " * Acc@1 35.724 Acc@5 61.952\n",
      "************train_loss 3.289153099328025 val_acc 35.72441864013672*************\n",
      "Epoch: [12][    0/13346]\tTime  1.278 ( 1.278)\tData  1.198 ( 1.198)\tLoss 3.4471e+00 (3.4471e+00)\tAcc@1  25.00 ( 25.00)\tAcc@5  52.08 ( 52.08)\n",
      " * Acc@1 33.002 Acc@5 58.712\n",
      "************train_loss 3.2812222467447065 val_acc 33.001739501953125*************\n",
      "Epoch: [13][    0/13346]\tTime  1.366 ( 1.366)\tData  1.283 ( 1.283)\tLoss 3.3281e+00 (3.3281e+00)\tAcc@1  33.33 ( 33.33)\tAcc@5  54.17 ( 54.17)\n",
      " * Acc@1 35.249 Acc@5 61.655\n",
      "************train_loss 3.2667598603780386 val_acc 35.24899673461914*************\n",
      "Epoch: [14][    0/13346]\tTime  1.387 ( 1.387)\tData  1.311 ( 1.311)\tLoss 2.8308e+00 (2.8308e+00)\tAcc@1  38.54 ( 38.54)\tAcc@5  61.46 ( 61.46)\n",
      " * Acc@1 35.944 Acc@5 62.308\n",
      "************train_loss 3.2639183540421413 val_acc 35.944149017333984*************\n",
      "Epoch: [15][    0/13346]\tTime  1.341 ( 1.341)\tData  1.249 ( 1.249)\tLoss 3.1427e+00 (3.1427e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  60.42 ( 60.42)\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "acc1 = 0\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    # train for one epoch\n",
    "    epoch_loss = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, args)  \n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    val_acc.append(acc1)\n",
    "    \n",
    "    print('************train_loss {} val_acc {}*************'.format(epoch_loss, acc1))\n",
    "    \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "#     if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "#             and args.rank % ngpus_per_node == 0):\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6de6a0-a209-4b66-b52d-322f333aacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48e851-7663-40f7-b4d8-417cc3498927",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../trained_model/gated/checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c59498-eb7d-4622-9de6-8a5e5848da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "epoch = checkpoint['epoch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b927e1d-636b-4c33-a6ee-632c4c7f4a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
