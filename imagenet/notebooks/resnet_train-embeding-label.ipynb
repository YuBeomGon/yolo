{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ab6313-698a-46cc-9ab4-770b35f86211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "# import torchvision.models as models\n",
    "from resnet import *\n",
    "\n",
    "from main import *\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56508d67-5301-4e1e-9454-1fe41b5f3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args(args=[])\n",
    "# args = parser.parse_args()\n",
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch-size\": 256, \n",
    "                          \"epochs\": 50, \n",
    "                          \"data\": 0, \n",
    "                          'arch':'resnet18',\n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea598abf-d5fe-4f70-8cbf-78ad6038e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "# device = 'cpu'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b5c549-7611-40a8-a5cd-54451c41e793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "imagenet_embeding = np.load('../data/imagenet_embeding.npy')\n",
    "imagenet_embeding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5e59a2-80d4-49f7-8998-7b78846b333f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_embeding = torch.tensor(imagenet_embeding)\n",
    "imagenet_embeding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e9ebbf-4193-412c-b416-9faccf6aac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "print(\"=> using pre-trained model '{}'\".format('resnet18'))\n",
    "# model = models.__dict__['resnet18'](pretrained=True)\n",
    "# model = models.resnet18(pretrained=False)\n",
    "model = resnet18(pretrained=False)\n",
    "# model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf479d7-0b16-4399-8f59-fd72bec730d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0136, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8e115d-c36b-4e00-8f16-9473415528af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), '../trained_model/init.pt')\n",
    "model.load_state_dict(torch.load('../trained_model/init.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75cef50-6d29-411a-a565-898a4468242d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0301, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8910807d-3862-4446-a811-530857664cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n",
      "tensor([[-0.0301,  0.0198, -0.0104,  ..., -0.0012, -0.0136,  0.0011],\n",
      "        [-0.0023, -0.0009, -0.0329,  ..., -0.0281, -0.0132,  0.0052],\n",
      "        [ 0.0036, -0.0155, -0.0112,  ..., -0.0055,  0.0028,  0.0204],\n",
      "        ...,\n",
      "        [-0.0349, -0.0049, -0.0264,  ..., -0.0168, -0.0148,  0.0045],\n",
      "        [ 0.0063, -0.0293, -0.0185,  ..., -0.0337, -0.0108,  0.0270],\n",
      "        [-0.0275, -0.0346,  0.0034,  ..., -0.0311,  0.0181,  0.0030]])\n",
      "tensor([[ 0.5611,  0.2227,  0.2527,  ..., -0.1777,  0.2208,  0.6253],\n",
      "        [ 0.0625, -0.3026, -0.2862,  ..., -0.0785, -0.1146, -0.1183],\n",
      "        [ 0.1750,  0.1851, -0.3477,  ..., -0.3395, -0.0346, -0.3034],\n",
      "        ...,\n",
      "        [-0.3333,  0.0872, -0.0674,  ...,  0.2487, -0.1052,  0.0210],\n",
      "        [-0.0106,  0.0222,  0.2349,  ..., -0.4712, -0.5066,  0.3787],\n",
      "        [ 0.6112,  0.1495, -0.0799,  ..., -0.2983, -0.5161,  0.1615]])\n"
     ]
    }
   ],
   "source": [
    "model_dict = model.state_dict() \n",
    "for k in model_dict :\n",
    "    if 'fc.weight' in k :\n",
    "        print(model_dict[k].shape)\n",
    "        print(model_dict[k])\n",
    "        model_dict[k] = imagenet_embeding\n",
    "#     if 'fc.bias' in k :\n",
    "#         print(model_dict[k])        \n",
    "#     print(model_dict[k].shape)\n",
    "model.load_state_dict(model_dict)\n",
    "model_dict = model.state_dict() \n",
    "for k in model_dict :\n",
    "    if 'fc.weight' in k :\n",
    "#         print(model_dict[k].shape)\n",
    "        print(model_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66335ead-2157-4014-8671-62dbab63a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77598382-abf2-459f-9457-f8bdd1cf8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.parameters() :\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5493c8ea-4540-4067-8954-9e7a73cb10da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6cd832a-5720-4925-9d50-36b16480132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "data_dir = '../ILSVRC/Data/CLS-LOC/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb79f3f-e8a8-4e0d-9a55-f7dbf5c08236",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3d9c94c-b533-4147-96f0-57afbf42624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4460bdaa-261a-4858-a94c-c70aebd6fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beece8cc-7ac9-4e30-8cca-0ca4adbd58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=(train_sampler is None),\n",
    "    num_workers=8, pin_memory=True, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53171b34-4e2f-4b1b-ae3f-d8d2db58b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afed6352-ebb9-4fcf-ade1-12354b4e7755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25092250-abbb-482c-bb3a-3c279e593859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/5005]\tTime  2.852 ( 2.852)\tData  2.473 ( 2.473)\tLoss 9.6591e+00 (9.6591e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Epoch: [0][1001/5005]\tTime  0.390 ( 0.387)\tData  0.000 ( 0.003)\tLoss 6.9821e+00 (7.0464e+00)\tAcc@1   0.39 (  0.35)\tAcc@5   1.56 (  1.55)\n",
      "Epoch: [0][2002/5005]\tTime  0.390 ( 0.388)\tData  0.000 ( 0.002)\tLoss 6.5474e+00 (6.8368e+00)\tAcc@1   0.00 (  0.57)\tAcc@5   3.52 (  2.36)\n",
      "Epoch: [0][3003/5005]\tTime  0.391 ( 0.388)\tData  0.000 ( 0.001)\tLoss 6.3105e+00 (6.6725e+00)\tAcc@1   2.73 (  0.86)\tAcc@5   7.42 (  3.40)\n",
      "Epoch: [0][4004/5005]\tTime  0.390 ( 0.389)\tData  0.000 ( 0.001)\tLoss 6.0042e+00 (6.5211e+00)\tAcc@1   3.12 (  1.27)\tAcc@5  10.16 (  4.68)\n",
      " * Acc@1 3.727 Acc@5 11.476\n",
      "************train_loss 6.388201045132541 val_acc 3.7274527549743652*************\n",
      "Epoch: [1][   0/5005]\tTime  2.266 ( 2.266)\tData  2.124 ( 2.124)\tLoss 5.9463e+00 (5.9463e+00)\tAcc@1   3.91 (  3.91)\tAcc@5  10.55 ( 10.55)\n",
      "Epoch: [1][1001/5005]\tTime  0.405 ( 0.392)\tData  0.000 ( 0.003)\tLoss 5.7594e+00 (5.6648e+00)\tAcc@1   4.30 (  5.07)\tAcc@5  14.06 ( 14.60)\n",
      "Epoch: [1][2002/5005]\tTime  0.376 ( 0.390)\tData  0.000 ( 0.001)\tLoss 5.5883e+00 (5.5743e+00)\tAcc@1   8.59 (  5.76)\tAcc@5  17.19 ( 16.06)\n",
      "Epoch: [1][3003/5005]\tTime  0.378 ( 0.390)\tData  0.000 ( 0.001)\tLoss 5.2312e+00 (5.4811e+00)\tAcc@1   9.38 (  6.55)\tAcc@5  23.83 ( 17.65)\n",
      "Epoch: [1][4004/5005]\tTime  0.389 ( 0.390)\tData  0.000 ( 0.001)\tLoss 4.9051e+00 (5.3804e+00)\tAcc@1  14.84 (  7.50)\tAcc@5  30.08 ( 19.42)\n",
      " * Acc@1 12.467 Acc@5 29.238\n",
      "************train_loss 5.280509019826914 val_acc 12.466791152954102*************\n",
      "Epoch: [2][   0/5005]\tTime  2.458 ( 2.458)\tData  2.313 ( 2.313)\tLoss 4.8310e+00 (4.8310e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  28.52 ( 28.52)\n",
      "Epoch: [2][1001/5005]\tTime  0.389 ( 0.392)\tData  0.000 ( 0.003)\tLoss 4.4780e+00 (4.6691e+00)\tAcc@1  16.80 ( 14.58)\tAcc@5  33.98 ( 32.19)\n",
      "Epoch: [2][2002/5005]\tTime  0.388 ( 0.391)\tData  0.000 ( 0.002)\tLoss 4.6987e+00 (4.5824e+00)\tAcc@1  16.02 ( 15.66)\tAcc@5  35.55 ( 33.86)\n",
      "Epoch: [2][3003/5005]\tTime  0.387 ( 0.390)\tData  0.000 ( 0.001)\tLoss 4.3456e+00 (4.5042e+00)\tAcc@1  18.36 ( 16.62)\tAcc@5  40.23 ( 35.29)\n",
      "Epoch: [2][4004/5005]\tTime  0.391 ( 0.390)\tData  0.000 ( 0.001)\tLoss 4.3190e+00 (4.4297e+00)\tAcc@1  18.36 ( 17.57)\tAcc@5  38.67 ( 36.68)\n",
      " * Acc@1 24.262 Acc@5 47.300\n",
      "************train_loss 4.363346622659491 val_acc 24.262401580810547*************\n",
      "Epoch: [3][   0/5005]\tTime  2.074 ( 2.074)\tData  1.916 ( 1.916)\tLoss 3.7201e+00 (3.7201e+00)\tAcc@1  25.78 ( 25.78)\tAcc@5  48.05 ( 48.05)\n",
      "Epoch: [3][1001/5005]\tTime  0.392 ( 0.392)\tData  0.000 ( 0.002)\tLoss 4.0346e+00 (3.9593e+00)\tAcc@1  22.27 ( 23.51)\tAcc@5  42.58 ( 45.30)\n",
      "Epoch: [3][2002/5005]\tTime  0.385 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.8928e+00 (3.9201e+00)\tAcc@1  23.44 ( 24.20)\tAcc@5  48.83 ( 46.09)\n",
      "Epoch: [3][3003/5005]\tTime  0.390 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.6000e+00 (3.8807e+00)\tAcc@1  26.56 ( 24.78)\tAcc@5  53.91 ( 46.80)\n",
      "Epoch: [3][4004/5005]\tTime  0.389 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.8493e+00 (3.8418e+00)\tAcc@1  24.61 ( 25.37)\tAcc@5  49.22 ( 47.52)\n",
      " * Acc@1 27.682 Acc@5 51.337\n",
      "************train_loss 3.806273166664116 val_acc 27.682228088378906*************\n",
      "Epoch: [4][   0/5005]\tTime  2.359 ( 2.359)\tData  2.207 ( 2.207)\tLoss 3.5635e+00 (3.5635e+00)\tAcc@1  32.42 ( 32.42)\tAcc@5  50.78 ( 50.78)\n",
      "Epoch: [4][1001/5005]\tTime  0.392 ( 0.392)\tData  0.000 ( 0.003)\tLoss 3.4403e+00 (3.5672e+00)\tAcc@1  31.64 ( 29.31)\tAcc@5  53.12 ( 52.45)\n",
      "Epoch: [4][2002/5005]\tTime  0.388 ( 0.391)\tData  0.000 ( 0.002)\tLoss 3.5774e+00 (3.5489e+00)\tAcc@1  30.08 ( 29.63)\tAcc@5  52.34 ( 52.76)\n",
      "Epoch: [4][3003/5005]\tTime  0.391 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.4451e+00 (3.5295e+00)\tAcc@1  30.86 ( 29.94)\tAcc@5  57.03 ( 53.11)\n",
      "Epoch: [4][4004/5005]\tTime  0.391 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.6272e+00 (3.5107e+00)\tAcc@1  30.86 ( 30.22)\tAcc@5  50.78 ( 53.45)\n",
      " * Acc@1 33.669 Acc@5 58.241\n",
      "************train_loss 3.4883547952006033 val_acc 33.66892623901367*************\n",
      "Epoch: [5][   0/5005]\tTime  2.147 ( 2.147)\tData  2.002 ( 2.002)\tLoss 3.1337e+00 (3.1337e+00)\tAcc@1  37.89 ( 37.89)\tAcc@5  58.20 ( 58.20)\n",
      "Epoch: [5][1001/5005]\tTime  0.393 ( 0.392)\tData  0.000 ( 0.002)\tLoss 3.1749e+00 (3.3339e+00)\tAcc@1  33.59 ( 32.83)\tAcc@5  59.77 ( 56.56)\n",
      "Epoch: [5][2002/5005]\tTime  0.385 ( 0.391)\tData  0.000 ( 0.001)\tLoss 3.6076e+00 (3.3260e+00)\tAcc@1  26.17 ( 32.96)\tAcc@5  50.00 ( 56.70)\n",
      "Epoch: [5][3003/5005]\tTime  0.388 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.3676e+00 (3.3155e+00)\tAcc@1  32.42 ( 33.15)\tAcc@5  56.64 ( 56.92)\n",
      "Epoch: [5][4004/5005]\tTime  0.386 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.1069e+00 (3.3043e+00)\tAcc@1  37.50 ( 33.35)\tAcc@5  60.16 ( 57.13)\n",
      " * Acc@1 32.730 Acc@5 57.406\n",
      "************train_loss 3.2932225483638065 val_acc 32.730072021484375*************\n",
      "Epoch: [6][   0/5005]\tTime  2.248 ( 2.248)\tData  2.107 ( 2.107)\tLoss 3.0862e+00 (3.0862e+00)\tAcc@1  36.33 ( 36.33)\tAcc@5  63.67 ( 63.67)\n",
      "Epoch: [6][1001/5005]\tTime  0.390 ( 0.392)\tData  0.000 ( 0.003)\tLoss 3.1230e+00 (3.1800e+00)\tAcc@1  40.62 ( 35.35)\tAcc@5  61.33 ( 59.19)\n",
      "Epoch: [6][2002/5005]\tTime  0.388 ( 0.391)\tData  0.000 ( 0.002)\tLoss 3.1589e+00 (3.1843e+00)\tAcc@1  33.20 ( 35.22)\tAcc@5  59.38 ( 59.16)\n",
      "Epoch: [6][3003/5005]\tTime  0.390 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.1210e+00 (3.1765e+00)\tAcc@1  41.02 ( 35.34)\tAcc@5  62.50 ( 59.29)\n",
      "Epoch: [6][4004/5005]\tTime  0.381 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.9502e+00 (3.1695e+00)\tAcc@1  40.23 ( 35.46)\tAcc@5  60.94 ( 59.43)\n",
      " * Acc@1 37.277 Acc@5 62.442\n",
      "************train_loss 3.1620732058297385 val_acc 37.27652359008789*************\n",
      "Epoch: [7][   0/5005]\tTime  2.183 ( 2.183)\tData  2.033 ( 2.033)\tLoss 3.1044e+00 (3.1044e+00)\tAcc@1  33.59 ( 33.59)\tAcc@5  59.38 ( 59.38)\n",
      "Epoch: [7][1001/5005]\tTime  0.388 ( 0.392)\tData  0.000 ( 0.002)\tLoss 3.2810e+00 (3.0744e+00)\tAcc@1  33.98 ( 36.93)\tAcc@5  58.59 ( 61.04)\n",
      "Epoch: [7][2002/5005]\tTime  0.390 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.9639e+00 (3.0825e+00)\tAcc@1  40.62 ( 36.86)\tAcc@5  62.50 ( 60.93)\n",
      "Epoch: [7][3003/5005]\tTime  0.392 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.0327e+00 (3.0793e+00)\tAcc@1  33.98 ( 36.93)\tAcc@5  64.45 ( 60.99)\n",
      "Epoch: [7][4004/5005]\tTime  0.388 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7959e+00 (3.0732e+00)\tAcc@1  39.45 ( 37.01)\tAcc@5  67.58 ( 61.09)\n",
      " * Acc@1 35.934 Acc@5 61.301\n",
      "************train_loss 3.069625977869634 val_acc 35.93416213989258*************\n",
      "Epoch: [8][   0/5005]\tTime  2.491 ( 2.491)\tData  2.335 ( 2.335)\tLoss 2.9617e+00 (2.9617e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  64.06 ( 64.06)\n",
      "Epoch: [8][1001/5005]\tTime  0.392 ( 0.393)\tData  0.000 ( 0.003)\tLoss 3.0188e+00 (2.9971e+00)\tAcc@1  37.11 ( 38.22)\tAcc@5  61.33 ( 62.29)\n",
      "Epoch: [8][2002/5005]\tTime  0.388 ( 0.391)\tData  0.000 ( 0.002)\tLoss 3.1090e+00 (3.0007e+00)\tAcc@1  36.72 ( 38.21)\tAcc@5  59.77 ( 62.24)\n",
      "Epoch: [8][3003/5005]\tTime  0.389 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7963e+00 (3.0020e+00)\tAcc@1  42.58 ( 38.20)\tAcc@5  64.06 ( 62.28)\n",
      "Epoch: [8][4004/5005]\tTime  0.385 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.1963e+00 (2.9996e+00)\tAcc@1  34.77 ( 38.24)\tAcc@5  57.81 ( 62.35)\n",
      " * Acc@1 38.199 Acc@5 63.710\n",
      "************train_loss 2.9995626851157113 val_acc 38.199398040771484*************\n",
      "Epoch: [9][   0/5005]\tTime  2.349 ( 2.349)\tData  2.202 ( 2.202)\tLoss 3.1932e+00 (3.1932e+00)\tAcc@1  38.67 ( 38.67)\tAcc@5  59.38 ( 59.38)\n",
      "Epoch: [9][1001/5005]\tTime  0.391 ( 0.392)\tData  0.000 ( 0.003)\tLoss 2.7958e+00 (2.9371e+00)\tAcc@1  39.06 ( 39.25)\tAcc@5  66.41 ( 63.38)\n",
      "Epoch: [9][2002/5005]\tTime  0.391 ( 0.391)\tData  0.000 ( 0.002)\tLoss 3.1401e+00 (2.9411e+00)\tAcc@1  33.20 ( 39.14)\tAcc@5  62.50 ( 63.33)\n",
      "Epoch: [9][3003/5005]\tTime  0.383 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.6548e+00 (2.9443e+00)\tAcc@1  42.97 ( 39.10)\tAcc@5  70.31 ( 63.25)\n",
      "Epoch: [9][4004/5005]\tTime  0.388 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.1693e+00 (2.9451e+00)\tAcc@1  30.08 ( 39.10)\tAcc@5  56.64 ( 63.27)\n",
      " * Acc@1 40.710 Acc@5 66.387\n",
      "************train_loss 2.9433994672872448 val_acc 40.71033477783203*************\n",
      "Epoch: [10][   0/5005]\tTime  2.456 ( 2.456)\tData  2.313 ( 2.313)\tLoss 2.7446e+00 (2.7446e+00)\tAcc@1  38.67 ( 38.67)\tAcc@5  64.84 ( 64.84)\n",
      "Epoch: [10][1001/5005]\tTime  0.389 ( 0.393)\tData  0.000 ( 0.003)\tLoss 3.1715e+00 (2.8978e+00)\tAcc@1  32.42 ( 39.88)\tAcc@5  59.38 ( 64.07)\n",
      "Epoch: [10][2002/5005]\tTime  0.393 ( 0.391)\tData  0.000 ( 0.002)\tLoss 2.6961e+00 (2.9020e+00)\tAcc@1  45.31 ( 39.81)\tAcc@5  69.53 ( 64.00)\n",
      "Epoch: [10][3003/5005]\tTime  0.380 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.8841e+00 (2.9049e+00)\tAcc@1  37.89 ( 39.78)\tAcc@5  61.33 ( 63.96)\n",
      "Epoch: [10][4004/5005]\tTime  0.390 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7234e+00 (2.9057e+00)\tAcc@1  45.70 ( 39.79)\tAcc@5  64.84 ( 63.95)\n",
      " * Acc@1 40.223 Acc@5 66.177\n",
      "************train_loss 2.904777197737794 val_acc 40.222930908203125*************\n",
      "Epoch: [11][   0/5005]\tTime  2.370 ( 2.370)\tData  2.228 ( 2.228)\tLoss 2.9135e+00 (2.9135e+00)\tAcc@1  39.45 ( 39.45)\tAcc@5  61.72 ( 61.72)\n",
      "Epoch: [11][1001/5005]\tTime  0.386 ( 0.393)\tData  0.000 ( 0.003)\tLoss 3.1687e+00 (2.8531e+00)\tAcc@1  36.72 ( 40.63)\tAcc@5  59.77 ( 64.72)\n",
      "Epoch: [11][2002/5005]\tTime  0.389 ( 0.391)\tData  0.000 ( 0.002)\tLoss 2.9606e+00 (2.8608e+00)\tAcc@1  39.06 ( 40.52)\tAcc@5  64.84 ( 64.64)\n",
      "Epoch: [11][3003/5005]\tTime  0.392 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7583e+00 (2.8635e+00)\tAcc@1  41.41 ( 40.53)\tAcc@5  65.62 ( 64.61)\n",
      "Epoch: [11][4004/5005]\tTime  0.387 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7128e+00 (2.8662e+00)\tAcc@1  41.41 ( 40.48)\tAcc@5  66.02 ( 64.57)\n",
      " * Acc@1 39.905 Acc@5 64.955\n",
      "************train_loss 2.8678498216204114 val_acc 39.90531539916992*************\n",
      "Epoch: [12][   0/5005]\tTime  2.429 ( 2.429)\tData  2.286 ( 2.286)\tLoss 2.9089e+00 (2.9089e+00)\tAcc@1  39.45 ( 39.45)\tAcc@5  64.06 ( 64.06)\n",
      "Epoch: [12][1001/5005]\tTime  0.392 ( 0.393)\tData  0.000 ( 0.003)\tLoss 2.7177e+00 (2.8291e+00)\tAcc@1  44.53 ( 40.92)\tAcc@5  66.41 ( 65.17)\n",
      "Epoch: [12][2002/5005]\tTime  0.390 ( 0.391)\tData  0.000 ( 0.002)\tLoss 2.9108e+00 (2.8334e+00)\tAcc@1  42.58 ( 40.84)\tAcc@5  63.28 ( 65.12)\n",
      "Epoch: [12][3003/5005]\tTime  0.388 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7448e+00 (2.8341e+00)\tAcc@1  39.45 ( 40.93)\tAcc@5  67.58 ( 65.13)\n",
      "Epoch: [12][4004/5005]\tTime  0.388 ( 0.390)\tData  0.000 ( 0.001)\tLoss 3.0507e+00 (2.8375e+00)\tAcc@1  37.11 ( 40.91)\tAcc@5  65.23 ( 65.10)\n",
      " * Acc@1 43.257 Acc@5 68.768\n",
      "************train_loss 2.840689935503187 val_acc 43.25722885131836*************\n",
      "Epoch: [13][   0/5005]\tTime  2.375 ( 2.375)\tData  2.232 ( 2.232)\tLoss 2.6651e+00 (2.6651e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5  67.97 ( 67.97)\n",
      "Epoch: [13][1001/5005]\tTime  0.391 ( 0.393)\tData  0.000 ( 0.003)\tLoss 2.8015e+00 (2.7994e+00)\tAcc@1  38.67 ( 41.63)\tAcc@5  64.45 ( 65.66)\n",
      "Epoch: [13][2002/5005]\tTime  0.391 ( 0.391)\tData  0.000 ( 0.002)\tLoss 2.6687e+00 (2.8054e+00)\tAcc@1  43.75 ( 41.50)\tAcc@5  65.23 ( 65.60)\n",
      "Epoch: [13][3003/5005]\tTime  0.390 ( 0.391)\tData  0.000 ( 0.001)\tLoss 3.0328e+00 (2.8097e+00)\tAcc@1  38.28 ( 41.40)\tAcc@5  64.45 ( 65.54)\n",
      "Epoch: [13][4004/5005]\tTime  0.394 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.9035e+00 (2.8116e+00)\tAcc@1  42.19 ( 41.35)\tAcc@5  64.45 ( 65.51)\n",
      " * Acc@1 43.990 Acc@5 69.807\n",
      "************train_loss 2.8150607459671373 val_acc 43.990333557128906*************\n",
      "Epoch: [14][   0/5005]\tTime  2.293 ( 2.293)\tData  2.148 ( 2.148)\tLoss 2.6566e+00 (2.6566e+00)\tAcc@1  41.41 ( 41.41)\tAcc@5  66.80 ( 66.80)\n",
      "Epoch: [14][1001/5005]\tTime  0.381 ( 0.393)\tData  0.000 ( 0.003)\tLoss 2.8721e+00 (2.7821e+00)\tAcc@1  41.02 ( 41.83)\tAcc@5  64.45 ( 66.06)\n",
      "Epoch: [14][2002/5005]\tTime  0.381 ( 0.391)\tData  0.000 ( 0.002)\tLoss 2.4850e+00 (2.7875e+00)\tAcc@1  47.27 ( 41.75)\tAcc@5  69.92 ( 65.96)\n",
      "Epoch: [14][3003/5005]\tTime  0.381 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.7198e+00 (2.7915e+00)\tAcc@1  46.09 ( 41.71)\tAcc@5  68.75 ( 65.91)\n",
      "Epoch: [14][4004/5005]\tTime  0.392 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7089e+00 (2.7928e+00)\tAcc@1  41.41 ( 41.69)\tAcc@5  65.62 ( 65.87)\n",
      " * Acc@1 43.575 Acc@5 69.134\n",
      "************train_loss 2.7945123260433262 val_acc 43.5748405456543*************\n",
      "Epoch: [15][   0/5005]\tTime  2.206 ( 2.206)\tData  2.045 ( 2.045)\tLoss 2.7389e+00 (2.7389e+00)\tAcc@1  42.58 ( 42.58)\tAcc@5  66.80 ( 66.80)\n",
      "Epoch: [15][1001/5005]\tTime  0.388 ( 0.393)\tData  0.000 ( 0.002)\tLoss 2.7663e+00 (2.7531e+00)\tAcc@1  42.19 ( 42.28)\tAcc@5  64.45 ( 66.37)\n",
      "Epoch: [15][2002/5005]\tTime  0.379 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.5411e+00 (2.7649e+00)\tAcc@1  45.31 ( 42.12)\tAcc@5  70.31 ( 66.23)\n",
      "Epoch: [15][3003/5005]\tTime  0.390 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.7360e+00 (2.7731e+00)\tAcc@1  41.02 ( 42.00)\tAcc@5  65.23 ( 66.10)\n",
      "Epoch: [15][4004/5005]\tTime  0.391 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.5622e+00 (2.7753e+00)\tAcc@1  50.78 ( 41.98)\tAcc@5  68.36 ( 66.07)\n",
      " * Acc@1 44.392 Acc@5 70.158\n",
      "************train_loss 2.776426762753314 val_acc 44.391841888427734*************\n",
      "Epoch: [16][   0/5005]\tTime  2.275 ( 2.275)\tData  2.124 ( 2.124)\tLoss 2.9462e+00 (2.9462e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  63.28 ( 63.28)\n",
      "Epoch: [16][1001/5005]\tTime  0.391 ( 0.393)\tData  0.000 ( 0.003)\tLoss 2.6412e+00 (2.7500e+00)\tAcc@1  44.53 ( 42.26)\tAcc@5  67.19 ( 66.49)\n",
      "Epoch: [16][2002/5005]\tTime  0.391 ( 0.391)\tData  0.000 ( 0.002)\tLoss 2.6237e+00 (2.7544e+00)\tAcc@1  41.80 ( 42.19)\tAcc@5  67.19 ( 66.44)\n",
      "Epoch: [16][3003/5005]\tTime  0.388 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.7703e+00 (2.7589e+00)\tAcc@1  39.06 ( 42.16)\tAcc@5  63.28 ( 66.35)\n",
      "Epoch: [16][4004/5005]\tTime  0.389 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.7259e+00 (2.7604e+00)\tAcc@1  41.02 ( 42.15)\tAcc@5  65.62 ( 66.35)\n",
      " * Acc@1 41.967 Acc@5 67.673\n",
      "************train_loss 2.7621834119478543 val_acc 41.966800689697266*************\n",
      "Epoch: [17][   0/5005]\tTime  2.435 ( 2.435)\tData  2.274 ( 2.274)\tLoss 2.5442e+00 (2.5442e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  67.97 ( 67.97)\n",
      "Epoch: [17][1001/5005]\tTime  0.391 ( 0.393)\tData  0.000 ( 0.003)\tLoss 2.7816e+00 (2.7289e+00)\tAcc@1  36.72 ( 42.72)\tAcc@5  69.14 ( 66.82)\n",
      "Epoch: [17][2002/5005]\tTime  0.392 ( 0.391)\tData  0.000 ( 0.002)\tLoss 2.9421e+00 (2.7375e+00)\tAcc@1  36.72 ( 42.52)\tAcc@5  62.89 ( 66.70)\n",
      "Epoch: [17][3003/5005]\tTime  0.387 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.7277e+00 (2.7439e+00)\tAcc@1  41.80 ( 42.48)\tAcc@5  63.67 ( 66.64)\n",
      "Epoch: [17][4004/5005]\tTime  0.391 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.9409e+00 (2.7461e+00)\tAcc@1  43.75 ( 42.43)\tAcc@5  68.36 ( 66.63)\n",
      " * Acc@1 43.853 Acc@5 69.439\n",
      "************train_loss 2.7505254923642335 val_acc 43.852500915527344*************\n",
      "Epoch: [18][   0/5005]\tTime  1.852 ( 1.852)\tData  1.712 ( 1.712)\tLoss 2.4570e+00 (2.4570e+00)\tAcc@1  45.70 ( 45.70)\tAcc@5  69.14 ( 69.14)\n",
      "Epoch: [18][1001/5005]\tTime  0.391 ( 0.392)\tData  0.000 ( 0.002)\tLoss 2.9419e+00 (2.7230e+00)\tAcc@1  43.75 ( 42.84)\tAcc@5  64.84 ( 66.98)\n",
      "Epoch: [18][2002/5005]\tTime  0.390 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.5550e+00 (2.7236e+00)\tAcc@1  44.53 ( 42.84)\tAcc@5  67.19 ( 66.98)\n",
      "Epoch: [18][3003/5005]\tTime  0.378 ( 0.391)\tData  0.000 ( 0.001)\tLoss 3.0773e+00 (2.7289e+00)\tAcc@1  36.72 ( 42.71)\tAcc@5  62.11 ( 66.94)\n",
      "Epoch: [18][4004/5005]\tTime  0.392 ( 0.390)\tData  0.000 ( 0.001)\tLoss 2.8800e+00 (2.7350e+00)\tAcc@1  42.58 ( 42.62)\tAcc@5  65.62 ( 66.83)\n",
      " * Acc@1 45.015 Acc@5 70.778\n",
      "************train_loss 2.7366016838576765 val_acc 45.01508331298828*************\n",
      "Epoch: [19][   0/5005]\tTime  2.465 ( 2.465)\tData  2.322 ( 2.322)\tLoss 2.7905e+00 (2.7905e+00)\tAcc@1  41.80 ( 41.80)\tAcc@5  67.97 ( 67.97)\n",
      "Epoch: [19][1001/5005]\tTime  0.392 ( 0.393)\tData  0.000 ( 0.003)\tLoss 2.6204e+00 (2.7075e+00)\tAcc@1  46.09 ( 42.96)\tAcc@5  70.31 ( 67.29)\n",
      "Epoch: [19][2002/5005]\tTime  0.389 ( 0.392)\tData  0.000 ( 0.002)\tLoss 3.0561e+00 (2.7116e+00)\tAcc@1  37.11 ( 42.94)\tAcc@5  62.89 ( 67.20)\n",
      "Epoch: [19][3003/5005]\tTime  0.392 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.7688e+00 (2.7190e+00)\tAcc@1  42.97 ( 42.88)\tAcc@5  63.67 ( 67.06)\n",
      "Epoch: [19][4004/5005]\tTime  0.389 ( 0.391)\tData  0.000 ( 0.001)\tLoss 2.8512e+00 (2.7224e+00)\tAcc@1  40.62 ( 42.85)\tAcc@5  67.58 ( 67.03)\n",
      " * Acc@1 45.413 Acc@5 71.097\n",
      "************train_loss 2.726197893064577 val_acc 45.41259765625*************\n",
      "Epoch: [20][   0/5005]\tTime  2.338 ( 2.338)\tData  2.190 ( 2.190)\tLoss 2.8017e+00 (2.8017e+00)\tAcc@1  39.45 ( 39.45)\tAcc@5  66.41 ( 66.41)\n",
      "Epoch: [20][1001/5005]\tTime  0.389 ( 0.394)\tData  0.000 ( 0.003)\tLoss 2.8116e+00 (2.6965e+00)\tAcc@1  44.92 ( 43.27)\tAcc@5  66.02 ( 67.49)\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "acc1 = 0\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    # train for one epoch\n",
    "    epoch_loss = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, args)  \n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    val_acc.append(acc1)\n",
    "    print('************train_loss {} val_acc {}*************'.format(epoch_loss, acc1))\n",
    "    \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "#     if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "#             and args.rank % ngpus_per_node == 0):\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6de6a0-a209-4b66-b52d-322f333aacae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48e851-7663-40f7-b4d8-417cc3498927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
