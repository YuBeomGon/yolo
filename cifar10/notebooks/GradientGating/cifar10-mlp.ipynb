{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd9cb2c-0c4d-49c9-af05-5ecb49436e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d740fac4-f4ce-4d53-bcd0-b38ad27434a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherit from Function\n",
    "class LinearFunction(torch.autograd.Function):\n",
    "\n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "#         ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        ctx.save_for_backward(input, weight, bias, output)\n",
    "        return output\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # This is a pattern that is very convenient - at the top of backward\n",
    "        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n",
    "        # None. Thanks to the fact that additional trailing Nones are\n",
    "        # ignored, the return statement is simple even when the function has\n",
    "        # optional inputs.\n",
    "        input, weight, bias, output = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        # These needs_input_grad checks are optional and there only to\n",
    "        # improve efficiency. If you want to make your code simpler, you can\n",
    "        # skip them. Returning gradients for inputs that don't require it is\n",
    "        # not an error.\n",
    "#         print(grad_output.shape)\n",
    "#         print((grad_output * (torch.sigmoid(output)-0.5)*2).shape)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "#             grad_input = (grad_output * (torch.sigmoid(output)-0.5)*2).mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "#             grad_weight = (grad_output * (torch.sigmoid(output)-0.5)*2).t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca51e08-55ef-4b74-ac3a-68c43da50597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherit from Function\n",
    "class LinearGated(torch.autograd.Function):\n",
    "\n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "#         ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        ctx.save_for_backward(input, weight, bias, output)\n",
    "        return output\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # This is a pattern that is very convenient - at the top of backward\n",
    "        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n",
    "        # None. Thanks to the fact that additional trailing Nones are\n",
    "        # ignored, the return statement is simple even when the function has\n",
    "        # optional inputs.\n",
    "        input, weight, bias, output = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        # These needs_input_grad checks are optional and there only to\n",
    "        # improve efficiency. If you want to make your code simpler, you can\n",
    "        # skip them. Returning gradients for inputs that don't require it is\n",
    "        # not an error.\n",
    "#         print(grad_output.shape)\n",
    "#         print((grad_output * (torch.sigmoid(output)-0.5)*2).shape)\n",
    "#         grad_output = (grad_output * (torch.sigmoid(output)-0.5)*2)\n",
    "#         (torch.nn.Softmax(dim=1)(torch.sigmoid(x)))\n",
    "        grad_output = grad_output * torch.nn.Softmax(dim=1)(torch.sigmoid(grad_output))\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "#             grad_input = (grad_output * torch.nn.Softmax(dim=1)(torch.sigmoid(grad_output))).mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "#             grad_weight = (grad_output * (torch.sigmoid(output)-0.5)*2).t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1feec6-e112-481c-847d-fc695524f558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6aca96e-8081-411d-8e0b-f24fe84bf525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck\n",
    "linear = LinearFunction.apply\n",
    "linearGated = LinearGated.apply\n",
    "# gradcheck takes a tuple of tensors as input, check if your gradient\n",
    "# evaluated with these tensors are close enough to numerical\n",
    "# approximations and returns True if they all verify this condition.\n",
    "# input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))\n",
    "# test = gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "# print(test)\n",
    "\n",
    "# input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))\n",
    "# test = gradcheck(linearGated, input, eps=1e-2, atol=1e-2)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f420dc-38a5-4afe-a4e2-642ec388bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2540ff08-1f10-41b2-ac5d-14f2e2db8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # N is batch size; D_in is input dimension;\n",
    "# # H is hidden dimension; D_out is output dimension.\n",
    "# N, D_in, H, D_out = 4, 1000, 100, 10\n",
    "\n",
    "# # # Create random Tensors to hold input and outputs.\n",
    "# # x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "# # y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# # Create random Tensors for weights.\n",
    "# w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "# w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea60670-a503-418e-aa4a-0abeead36085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239e607fb9ed45e3b83d9753705d692f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a67fd8-407c-443d-812b-ac9027c21a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = batch_size, 32*32*3, 100, 10\n",
    "# Create random Tensors for weights.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "# w3 = w1.clone()\n",
    "# w4 = w2.clone()\n",
    "# print(w3)\n",
    "w3 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w4 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a91806-4fa1-4b0a-a86e-d43ce15f3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dense1 = LinearFunction.apply\n",
    "        self.dense2 = LinearFunction.apply\n",
    "#         self.w1 = w1\n",
    "#         self.w2 = w2\n",
    "\n",
    "    def forward(self, x, w1, w2):\n",
    "#         x = self.pool(F.relu(self.convZ(x)))\n",
    "#         x = x.view(-1, 1 * 1 * 1)\n",
    "#         x = self.fc1(x)\n",
    "        x = self.dense2(F.relu(self.dense1(x, w1.t())), w2.t())\n",
    "        return x\n",
    "    \n",
    "class NetG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetG, self).__init__()\n",
    "        self.dense1 = LinearGated.apply\n",
    "        self.dense2 = LinearGated.apply\n",
    "#         self.w1 = w1\n",
    "#         self.w2 = w2\n",
    "\n",
    "    def forward(self, x, w3, w4):\n",
    "#         x = self.pool(F.relu(self.convZ(x)))\n",
    "#         x = x.view(-1, 1 * 1 * 1)\n",
    "#         x = self.fc1(x)\n",
    "        x = (self.dense2(F.relu(self.dense1(x, w3.t())), w4.t()))\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f5ac85c-56cd-4a27-a79c-9dc4af6d7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(4,3)\n",
    "# print(x)\n",
    "# print(torch.sigmoid(x))\n",
    "# print(torch.nn.Softmax(dim=1)(torch.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e755e35c-87a7-490c-b48f-1caa69621155",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "netg = NetG()\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3936e5a6-c758-44f1-aa20-177f584c2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (model, w1, w2) :\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = torch.flatten(inputs,1)  \n",
    "\n",
    "            # zero the parameter gradients\n",
    "        #     optimizer.zero_grad()   \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs, w1, w2)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cdaf25e-b9b0-4dab-87c0-f49e183b8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   101] loss: 14.467\n",
      "[1,  2101] loss: 219.724\n",
      "[1,  4101] loss: 170.735\n",
      "[1,  6101] loss: 155.532\n",
      "Accuracy of the network on the 10000 test images: 14 %\n",
      "[2,   101] loss: 7.353\n",
      "[2,  2101] loss: 140.239\n",
      "[2,  4101] loss: 135.327\n",
      "[2,  6101] loss: 128.152\n",
      "Accuracy of the network on the 10000 test images: 16 %\n",
      "[3,   101] loss: 6.011\n",
      "[3,  2101] loss: 120.839\n",
      "[3,  4101] loss: 116.535\n",
      "[3,  6101] loss: 109.979\n",
      "Accuracy of the network on the 10000 test images: 17 %\n",
      "[4,   101] loss: 5.228\n",
      "[4,  2101] loss: 106.396\n",
      "[4,  4101] loss: 102.468\n",
      "[4,  6101] loss: 98.861\n",
      "Accuracy of the network on the 10000 test images: 18 %\n",
      "[5,   101] loss: 4.679\n",
      "[5,  2101] loss: 94.413\n",
      "[5,  4101] loss: 91.893\n",
      "[5,  6101] loss: 90.437\n",
      "Accuracy of the network on the 10000 test images: 19 %\n",
      "[6,   101] loss: 4.689\n",
      "[6,  2101] loss: 85.829\n",
      "[6,  4101] loss: 83.042\n",
      "[6,  6101] loss: 81.169\n",
      "Accuracy of the network on the 10000 test images: 20 %\n",
      "[7,   101] loss: 4.053\n",
      "[7,  2101] loss: 77.795\n",
      "[7,  4101] loss: 76.565\n",
      "[7,  6101] loss: 73.852\n",
      "Accuracy of the network on the 10000 test images: 21 %\n",
      "[8,   101] loss: 3.617\n",
      "[8,  2101] loss: 71.626\n",
      "[8,  4101] loss: 69.104\n",
      "[8,  6101] loss: 67.464\n",
      "Accuracy of the network on the 10000 test images: 21 %\n",
      "[9,   101] loss: 3.383\n",
      "[9,  2101] loss: 65.498\n",
      "[9,  4101] loss: 64.071\n",
      "[9,  6101] loss: 60.557\n",
      "Accuracy of the network on the 10000 test images: 22 %\n",
      "[10,   101] loss: 3.153\n",
      "[10,  2101] loss: 59.335\n",
      "[10,  4101] loss: 58.586\n",
      "[10,  6101] loss: 55.698\n",
      "Accuracy of the network on the 10000 test images: 22 %\n",
      "[11,   101] loss: 2.768\n",
      "[11,  2101] loss: 54.906\n",
      "[11,  4101] loss: 52.244\n",
      "[11,  6101] loss: 51.573\n",
      "Accuracy of the network on the 10000 test images: 22 %\n",
      "[12,   101] loss: 2.601\n",
      "[12,  2101] loss: 49.409\n",
      "[12,  4101] loss: 48.145\n",
      "[12,  6101] loss: 46.813\n",
      "Accuracy of the network on the 10000 test images: 23 %\n",
      "[13,   101] loss: 2.178\n",
      "[13,  2101] loss: 44.934\n",
      "[13,  4101] loss: 43.876\n",
      "[13,  6101] loss: 42.791\n",
      "Accuracy of the network on the 10000 test images: 23 %\n",
      "[14,   101] loss: 2.071\n",
      "[14,  2101] loss: 40.824\n",
      "[14,  4101] loss: 39.932\n",
      "[14,  6101] loss: 38.412\n",
      "Accuracy of the network on the 10000 test images: 23 %\n",
      "[15,   101] loss: 1.895\n",
      "[15,  2101] loss: 37.118\n",
      "[15,  4101] loss: 35.983\n",
      "[15,  6101] loss: 34.452\n",
      "Accuracy of the network on the 10000 test images: 23 %\n",
      "[16,   101] loss: 1.835\n",
      "[16,  2101] loss: 33.152\n",
      "[16,  4101] loss: 32.318\n",
      "[16,  6101] loss: 31.199\n",
      "Accuracy of the network on the 10000 test images: 24 %\n",
      "[17,   101] loss: 1.518\n",
      "[17,  2101] loss: 29.820\n",
      "[17,  4101] loss: 28.993\n",
      "[17,  6101] loss: 27.706\n",
      "Accuracy of the network on the 10000 test images: 24 %\n",
      "[18,   101] loss: 1.289\n",
      "[18,  2101] loss: 26.642\n",
      "[18,  4101] loss: 25.713\n",
      "[18,  6101] loss: 24.315\n",
      "Accuracy of the network on the 10000 test images: 24 %\n",
      "[19,   101] loss: 1.279\n",
      "[19,  2101] loss: 23.579\n",
      "[19,  4101] loss: 22.446\n",
      "[19,  6101] loss: 21.399\n",
      "Accuracy of the network on the 10000 test images: 24 %\n",
      "[20,   101] loss: 1.103\n",
      "[20,  2101] loss: 20.547\n",
      "[20,  4101] loss: 19.727\n",
      "[20,  6101] loss: 18.463\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "[21,   101] loss: 0.859\n",
      "[21,  2101] loss: 17.650\n",
      "[21,  4101] loss: 16.879\n",
      "[21,  6101] loss: 16.035\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "[22,   101] loss: 0.780\n",
      "[22,  2101] loss: 15.071\n",
      "[22,  4101] loss: 14.233\n",
      "[22,  6101] loss: 13.511\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "[23,   101] loss: 0.639\n",
      "[23,  2101] loss: 12.646\n",
      "[23,  4101] loss: 11.965\n",
      "[23,  6101] loss: 11.050\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "[24,   101] loss: 0.496\n",
      "[24,  2101] loss: 10.452\n",
      "[24,  4101] loss: 9.668\n",
      "[24,  6101] loss: 8.948\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "[25,   101] loss: 0.472\n",
      "[25,  2101] loss: 8.157\n",
      "[25,  4101] loss: 7.680\n",
      "[25,  6101] loss: 7.102\n",
      "Accuracy of the network on the 10000 test images: 25 %\n",
      "[26,   101] loss: 0.343\n",
      "[26,  2101] loss: 6.367\n",
      "[26,  4101] loss: 5.977\n",
      "[26,  6101] loss: 5.457\n",
      "Accuracy of the network on the 10000 test images: 26 %\n",
      "[27,   101] loss: 0.272\n",
      "[27,  2101] loss: 4.892\n",
      "[27,  4101] loss: 4.546\n",
      "[27,  6101] loss: 4.110\n",
      "Accuracy of the network on the 10000 test images: 27 %\n",
      "[28,   101] loss: 0.192\n",
      "[28,  2101] loss: 3.740\n",
      "[28,  4101] loss: 3.465\n",
      "[28,  6101] loss: 3.166\n",
      "Accuracy of the network on the 10000 test images: 28 %\n",
      "[29,   101] loss: 0.152\n",
      "[29,  2101] loss: 2.926\n",
      "[29,  4101] loss: 2.707\n",
      "[29,  6101] loss: 2.540\n",
      "Accuracy of the network on the 10000 test images: 30 %\n",
      "[30,   101] loss: 0.122\n",
      "[30,  2101] loss: 2.356\n",
      "[30,  4101] loss: 2.246\n",
      "[30,  6101] loss: 2.168\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[31,   101] loss: 0.102\n",
      "[31,  2101] loss: 2.045\n",
      "[31,  4101] loss: 2.006\n",
      "[31,  6101] loss: 1.952\n",
      "Accuracy of the network on the 10000 test images: 32 %\n",
      "[32,   101] loss: 0.095\n",
      "[32,  2101] loss: 1.906\n",
      "[32,  4101] loss: 1.897\n",
      "[32,  6101] loss: 1.879\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[33,   101] loss: 0.093\n",
      "[33,  2101] loss: 1.871\n",
      "[33,  4101] loss: 1.869\n",
      "[33,  6101] loss: 1.853\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[34,   101] loss: 0.092\n",
      "[34,  2101] loss: 1.855\n",
      "[34,  4101] loss: 1.854\n",
      "[34,  6101] loss: 1.858\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[35,   101] loss: 0.094\n",
      "[35,  2101] loss: 1.851\n",
      "[35,  4101] loss: 1.864\n",
      "[35,  6101] loss: 1.851\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[36,   101] loss: 0.093\n",
      "[36,  2101] loss: 1.853\n",
      "[36,  4101] loss: 1.856\n",
      "[36,  6101] loss: 1.859\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[37,   101] loss: 0.095\n",
      "[37,  2101] loss: 1.848\n",
      "[37,  4101] loss: 1.865\n",
      "[37,  6101] loss: 1.848\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[38,   101] loss: 0.095\n",
      "[38,  2101] loss: 1.848\n",
      "[38,  4101] loss: 1.861\n",
      "[38,  6101] loss: 1.855\n",
      "Accuracy of the network on the 10000 test images: 34 %\n",
      "[39,   101] loss: 0.092\n",
      "[39,  2101] loss: 1.857\n",
      "[39,  4101] loss: 1.852\n",
      "[39,  6101] loss: 1.856\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[40,   101] loss: 0.092\n",
      "[40,  2101] loss: 1.846\n",
      "[40,  4101] loss: 1.860\n",
      "[40,  6101] loss: 1.860\n",
      "Accuracy of the network on the 10000 test images: 34 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0005\n",
    "for epoch in range(40) :    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = torch.flatten(inputs,1)  \n",
    "\n",
    "        # zero the parameter gradients\n",
    "    #     optimizer.zero_grad()   \n",
    "        # forward + backward + optimize\n",
    "        outputs = netg(inputs, w3, w4)\n",
    "    #     print(outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "    #     optimizer.step()   \n",
    "#         print(w3.grad)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 100:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0 \n",
    "        with torch.no_grad():\n",
    "            # Update weights using gradient descent\n",
    "            w3 -= learning_rate * w3.grad\n",
    "            w4 -= learning_rate * w4.grad\n",
    "\n",
    "            # Manually zero the gradients after running the backward pass\n",
    "            w3.grad.zero_()\n",
    "            w4.grad.zero_()   \n",
    "    test(netg, w3, w4)\n",
    "            \n",
    "# correct = 0\n",
    "# total = 0\n",
    "# # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         inputs, labels = data\n",
    "#         inputs = torch.flatten(inputs,1)  \n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#     #     optimizer.zero_grad()   \n",
    "#         # forward + backward + optimize\n",
    "#         outputs = netg(inputs, w3, w4)\n",
    "#         # the class with the highest energy is what we choose as prediction\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4fd9411-ff6a-4b19-802d-9ea55bd859f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   101] loss: 13.337\n",
      "[1,  2101] loss: 156.951\n",
      "[1,  4101] loss: 116.333\n",
      "[1,  6101] loss: 99.324\n",
      "Accuracy of the network on the 10000 test images: 22 %\n",
      "[2,   101] loss: 4.338\n",
      "[2,  2101] loss: 83.050\n",
      "[2,  4101] loss: 75.765\n",
      "[2,  6101] loss: 69.156\n",
      "Accuracy of the network on the 10000 test images: 24 %\n",
      "[3,   101] loss: 3.179\n",
      "[3,  2101] loss: 60.795\n",
      "[3,  4101] loss: 55.546\n",
      "[3,  6101] loss: 50.304\n",
      "Accuracy of the network on the 10000 test images: 26 %\n",
      "[4,   101] loss: 2.451\n",
      "[4,  2101] loss: 45.347\n",
      "[4,  4101] loss: 41.644\n",
      "[4,  6101] loss: 38.821\n",
      "Accuracy of the network on the 10000 test images: 27 %\n",
      "[5,   101] loss: 1.773\n",
      "[5,  2101] loss: 34.686\n",
      "[5,  4101] loss: 31.533\n",
      "[5,  6101] loss: 29.228\n",
      "Accuracy of the network on the 10000 test images: 27 %\n",
      "[6,   101] loss: 1.345\n",
      "[6,  2101] loss: 26.164\n",
      "[6,  4101] loss: 23.363\n",
      "[6,  6101] loss: 21.471\n",
      "Accuracy of the network on the 10000 test images: 28 %\n",
      "[7,   101] loss: 1.101\n",
      "[7,  2101] loss: 18.897\n",
      "[7,  4101] loss: 16.932\n",
      "[7,  6101] loss: 15.060\n",
      "Accuracy of the network on the 10000 test images: 28 %\n",
      "[8,   101] loss: 0.727\n",
      "[8,  2101] loss: 13.033\n",
      "[8,  4101] loss: 11.457\n",
      "[8,  6101] loss: 9.848\n",
      "Accuracy of the network on the 10000 test images: 28 %\n",
      "[9,   101] loss: 0.458\n",
      "[9,  2101] loss: 8.389\n",
      "[9,  4101] loss: 7.107\n",
      "[9,  6101] loss: 6.103\n",
      "Accuracy of the network on the 10000 test images: 29 %\n",
      "[10,   101] loss: 0.274\n",
      "[10,  2101] loss: 4.982\n",
      "[10,  4101] loss: 4.222\n",
      "[10,  6101] loss: 3.669\n",
      "Accuracy of the network on the 10000 test images: 29 %\n",
      "[11,   101] loss: 0.177\n",
      "[11,  2101] loss: 3.058\n",
      "[11,  4101] loss: 2.735\n",
      "[11,  6101] loss: 2.452\n",
      "Accuracy of the network on the 10000 test images: 29 %\n",
      "[12,   101] loss: 0.122\n",
      "[12,  2101] loss: 2.244\n",
      "[12,  4101] loss: 2.141\n",
      "[12,  6101] loss: 2.071\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[13,   101] loss: 0.098\n",
      "[13,  2101] loss: 2.036\n",
      "[13,  4101] loss: 1.989\n",
      "[13,  6101] loss: 1.964\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[14,   101] loss: 0.102\n",
      "[14,  2101] loss: 1.949\n",
      "[14,  4101] loss: 1.943\n",
      "[14,  6101] loss: 1.944\n",
      "Accuracy of the network on the 10000 test images: 32 %\n",
      "[15,   101] loss: 0.097\n",
      "[15,  2101] loss: 1.935\n",
      "[15,  4101] loss: 1.935\n",
      "[15,  6101] loss: 1.923\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[16,   101] loss: 0.097\n",
      "[16,  2101] loss: 1.936\n",
      "[16,  4101] loss: 1.934\n",
      "[16,  6101] loss: 1.923\n",
      "Accuracy of the network on the 10000 test images: 33 %\n",
      "[17,   101] loss: 0.100\n",
      "[17,  2101] loss: 1.936\n",
      "[17,  4101] loss: 1.926\n",
      "[17,  6101] loss: 1.932\n",
      "Accuracy of the network on the 10000 test images: 32 %\n",
      "[18,   101] loss: 0.095\n",
      "[18,  2101] loss: 1.914\n",
      "[18,  4101] loss: 1.940\n",
      "[18,  6101] loss: 1.931\n",
      "Accuracy of the network on the 10000 test images: 34 %\n",
      "[19,   101] loss: 0.096\n",
      "[19,  2101] loss: 1.937\n",
      "[19,  4101] loss: 1.914\n",
      "[19,  6101] loss: 1.938\n",
      "Accuracy of the network on the 10000 test images: 32 %\n",
      "[20,   101] loss: 0.095\n",
      "[20,  2101] loss: 1.914\n",
      "[20,  4101] loss: 1.944\n",
      "[20,  6101] loss: 1.930\n",
      "Accuracy of the network on the 10000 test images: 33 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0002\n",
    "for epoch in range(20) :    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = torch.flatten(inputs,1)  \n",
    "\n",
    "        # zero the parameter gradients\n",
    "    #     optimizer.zero_grad()   \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs, w1, w2)\n",
    "    #     print(outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "    #     optimizer.step()   \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 100:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0 \n",
    "        with torch.no_grad():\n",
    "            # Update weights using gradient descent\n",
    "            w1 -= learning_rate * w1.grad\n",
    "            w2 -= learning_rate * w2.grad\n",
    "\n",
    "            # Manually zero the gradients after running the backward pass\n",
    "            w1.grad.zero_()\n",
    "            w2.grad.zero_()    \n",
    "    test(net, w1, w2)\n",
    "            \n",
    "# correct = 0\n",
    "# total = 0\n",
    "# # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         inputs, labels = data\n",
    "#         inputs = torch.flatten(inputs,1)  \n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#     #     optimizer.zero_grad()   \n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs, w1, w2)\n",
    "#         # the class with the highest energy is what we choose as prediction\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff0e81-0eb0-4a98-8a45-f88d914dab1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aec723-910a-4ab3-8ac5-e13d150e8771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5c546-053f-4643-a2cd-9d94d317c7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
