{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e953aaff-5e25-46ee-a200-7043b49bf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/call-backward-on-function-inside-a-backpropagation-step/3793\n",
    "# https://discuss.pytorch.org/t/implementing-a-custom-convolution-using-conv2d-input-and-conv2d-weight/18556\n",
    "# https://discuss.pytorch.org/t/implementing-a-custom-convolution-using-conv2d-input-and-conv2d-weight/18556/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d81d1b7-de30-4c36-a039-14389f064908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3e9003-9102-4e71-98f6-bab909d4376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gated gradient\n",
    "class Conv2dFunctionG(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None, stride=1, padding=1, dilation=1, groups=1):\n",
    "        # Save arguments to context to use on backward\n",
    "        # WARNING : if stride, padding, dilation etc is array, this will not work properly!!!!\n",
    "#         print('stride', stride)\n",
    "        if weight.shape[2] == 1 :\n",
    "            padding = 0\n",
    "        elif weight.shape[2] == 5 :\n",
    "            padding = 2\n",
    "        elif weight.shape[2] == 7 :\n",
    "            padding = 3\n",
    "        confs = torch.from_numpy(np.array([stride, padding, dilation, groups]))\n",
    "        out = F.conv2d(input, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
    "        ctx.save_for_backward(input, out, weight, bias, confs)\n",
    "\n",
    "        # Compute Convolution\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Load saved tensors\n",
    "        input, out, weight, bias, confs = ctx.saved_variables\n",
    "        confs = confs.numpy()\n",
    "        stride, padding, dilation, groups= confs[0], confs[1], confs[2], confs[3]\n",
    "\n",
    "        # Calculate Gradient\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "#         gradient is gated according to the feature map of each layer\n",
    "        grad_output = grad_output * 2*torch.sigmoid(out)*2 *torch.sigmoid(out)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.nn.grad.conv2d_input(input.shape, weight, grad_output, stride, padding, dilation, groups)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.nn.grad.conv2d_weight(input, weight.shape, grad_output, stride, padding, dilation, groups)\n",
    "                \n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "\n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None:\n",
    "            return grad_input, grad_weight, grad_bias, None, None, None, None\n",
    "        else:\n",
    "            return grad_input, grad_weight, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335decb8-b3ae-49d9-b7f3-2c60ae3f931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal case, stoachastic gradient \n",
    "class Conv2dFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None, stride=1, padding=1, dilation=1, groups=1):\n",
    "        # Save arguments to context to use on backward\n",
    "        # WARNING : if stride, padding, dilation etc is array, this will not work properly!!!!\n",
    "#         print('stride', stride)\n",
    "        if weight.shape[2] == 1 :\n",
    "            padding = 0\n",
    "        elif weight.shape[2] == 5 :\n",
    "            padding = 2\n",
    "        elif weight.shape[2] == 7 :\n",
    "            padding = 3\n",
    "        confs = torch.from_numpy(np.array([stride, padding, dilation, groups]))\n",
    "        out = F.conv2d(input, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
    "        ctx.save_for_backward(input, out, weight, bias, confs)\n",
    "\n",
    "        # Compute Convolution\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Load saved tensors\n",
    "        input, out, weight, bias, confs = ctx.saved_variables\n",
    "        confs = confs.numpy()\n",
    "        stride, padding, dilation, groups= confs[0], confs[1], confs[2], confs[3]\n",
    "\n",
    "        # Calculate Gradient\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "#         grad_output = grad_output * 2*torch.sigmoid(out)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.nn.grad.conv2d_input(input.shape, weight, grad_output, stride, padding, dilation, groups)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.nn.grad.conv2d_weight(input, weight.shape, grad_output, stride, padding, dilation, groups)\n",
    "                \n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "\n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None:\n",
    "            return grad_input, grad_weight, grad_bias, None, None, None, None\n",
    "        else:\n",
    "            return grad_input, grad_weight, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd706d30-a744-47e1-b4e7-b000f8dd4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import gradcheck\n",
    "# conv = Conv2dFunction.apply\n",
    "# gradcheck takes a tuple of tensors as input, check if your gradient\n",
    "# evaluated with these tensors are close enough to numerical\n",
    "# approximations and returns True if they all verify this condition.\n",
    "# input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))\n",
    "# test = gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "# print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbec456-07f5-48e8-ac80-64201f5d4e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=8)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0714c16b-d4d3-4993-9880-6ac5862e56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# N, C_in, C_out, K_size = batch_size, 3, 12, 3\n",
    "# Create random Tensors for weights.\n",
    "conw1 = torch.randn(8,3,5,5, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2 = torch.randn(32,8,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3 = torch.randn(128,32,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4 = torch.randn(128,128,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5 = torch.randn(10,128,1,1, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# weight for normal\n",
    "conw1 = torch.nn.init.xavier_uniform_(conw1, gain=1.0)\n",
    "conw2 = torch.nn.init.xavier_uniform_(conw2, gain=1.0)\n",
    "conw3 = torch.nn.init.xavier_uniform_(conw3, gain=1.0)\n",
    "conw4 = torch.nn.init.xavier_uniform_(conw4, gain=1.0)\n",
    "conw5 = torch.nn.init.xavier_uniform_(conw5, gain=1.0)\n",
    "\n",
    "# weight for gated\n",
    "# conw1g = conw1.clone().detatch(requires_grad=True)\n",
    "conw1g = torch.tensor(conw1, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2g = torch.tensor(conw2, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3g = torch.tensor(conw3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4g = torch.tensor(conw4, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5g = torch.tensor(conw5, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# weight for adam \n",
    "conw1a = torch.tensor(conw1, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2a = torch.tensor(conw2, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3a = torch.tensor(conw3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4a = torch.tensor(conw4, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5a = torch.tensor(conw5, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# print(conw1[0][0])\n",
    "# print(torch.nn.init.xavier_uniform_(conw1, gain=1.0)[0][0])\n",
    "# print(conw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac85c29-61e9-4b91-aa7e-c2077b9ffc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conw1 is conw1g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cdcc33-4b9d-4116-9403-15e1fc416f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(conw1[0][0][0])\n",
    "print(conw1g[0][0][0])\n",
    "print(conw1a[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67ad14c-9a63-4152-aee0-5ea1d976d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conw1g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d83544-adbf-49f9-bf2e-de7891fa75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = Conv2dFunction.apply\n",
    "        self.conv2 = Conv2dFunction.apply\n",
    "        self.conv3 = Conv2dFunction.apply\n",
    "        self.conv4 = Conv2dFunction.apply\n",
    "        self.conv5 = Conv2dFunction.apply\n",
    "        self.avgpool = torch.nn.AvgPool2d((2,2) ,stride=(2,2))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, w1, w2, w3, w4, w5):\n",
    "        x = self.act(self.conv1(x, w1))\n",
    "        x = torch.nn.BatchNorm2d(8).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv2(x, w2))\n",
    "        x = torch.nn.BatchNorm2d(32).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv3(x, w3))\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv4(x, w4))\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x, w5)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# gated model    \n",
    "class NetG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetG, self).__init__()\n",
    "        self.conv1 = Conv2dFunctionG.apply\n",
    "        self.conv2 = Conv2dFunctionG.apply\n",
    "        self.conv3 = Conv2dFunctionG.apply\n",
    "        self.conv4 = Conv2dFunctionG.apply\n",
    "        self.conv5 = Conv2dFunctionG.apply\n",
    "        self.avgpool = torch.nn.AvgPool2d((2,2) ,stride=(2,2))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, w1, w2, w3, w4, w5):\n",
    "        x = self.act(self.conv1(x, w1))\n",
    "        x = torch.nn.BatchNorm2d(8).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv2(x, w2))\n",
    "        x = torch.nn.BatchNorm2d(32).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv3(x, w3))\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv4(x, w4))\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x, w5)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x    \n",
    "\n",
    "#     adam model\n",
    "class NetA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetA, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,8,kernel_size=(5,5),padding=2,bias=False)\n",
    "        self.conv2 = nn.Conv2d(8,32,kernel_size=(3,3),padding=1,bias=False)\n",
    "        self.conv3 = nn.Conv2d(32,128,kernel_size=(3,3),padding=1,bias=False)\n",
    "        self.conv4 = nn.Conv2d(128,128,kernel_size=(3,3),padding=1,bias=False)\n",
    "        self.conv5 = nn.Conv2d(128,10,kernel_size=(1,1),padding=0,bias=False)\n",
    "        self.avgpool = torch.nn.AvgPool2d((2,2) ,stride=(2,2))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "#         self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = torch.nn.BatchNorm2d(8).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = torch.nn.BatchNorm2d(32).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f00a2e-56f8-400a-8f67-c2566254a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "netg = NetG().to(device)\n",
    "neta = NetA().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f330ad0-bb90-47df-acae-e51e49f0ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in neta.state_dict() :\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a5c621-d1ae-4e31-a55c-403b5ba31886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in neta.parameters() :\n",
    "#     print(p[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e125c3c4-b8bc-41b3-9bae-894a6e1b8c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for param in neta.parameters() :\n",
    "#     print(param.shape)\n",
    "\n",
    "# parameter for adam should be same with other model\n",
    "neta_dict = neta.state_dict()\n",
    "for p in neta_dict :\n",
    "    if 'conv1' in p :\n",
    "        neta_dict[p] = conw1a\n",
    "    elif 'conv2' in p :\n",
    "        neta_dict[p] = conw2a\n",
    "    elif 'conv3' in p :\n",
    "        neta_dict[p] = conw3a\n",
    "    elif 'conv4' in p :\n",
    "        neta_dict[p] = conw4a\n",
    "    elif 'conv5' in p :\n",
    "        neta_dict[p] = conw5a        \n",
    "#     print(p)\n",
    "#     print(neta.state_dict()[p].shape)\n",
    "#     print()\n",
    "neta.load_state_dict(neta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f3efdec-9d54-4b5a-bde2-7f5d01347aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in neta.parameters() :\n",
    "#     print(p[0][0][0])\n",
    "# print(conw1a[0][0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610eb50f-2961-4154-81a9-fce75b43ad93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bb5f59f-6c53-4939-904a-c0bc8dcbec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "image, label = iter(trainloader).next()\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7b5f1-5973-4a1a-81e6-b9604c18860e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f2c4fbe-b6f4-412b-bfcd-30d6182cb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "image, labels = iter(trainloader).next()\n",
    "outputs = net(image.to(device), conw1, conw2, conw3, conw4, conw5).to(device)\n",
    "print(outputs.shape)\n",
    "# print(outputs.sum(dim=1))\n",
    "# print(outputs)\n",
    "loss = criterion(outputs, labels.to(device))\n",
    "# loss.backward()\n",
    "# print(torch.nn.Softmax(dim=1)(outputs).sum(dim=1))\n",
    "# outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf08457c-bdf5-454d-b152-91959d5d4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conw5.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a08cb68-a7a9-4163-b096-420b0da1e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (model, w1=None, w2=None, w3=None, w4=None, w5=None) :\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            if w1 == None :\n",
    "                outputs = model(inputs.to(device))\n",
    "            else :\n",
    "                outputs = model(inputs.to(device), w1, w2, w3, w4, w5)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613cb2b6-cf53-4c7f-a917-28a38f0934b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8cf486-5b31-4932-be7a-65eda393e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2309ec7d-2cba-4900-ab93-c2515453ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************normal case with adam****************\n",
      "[1,   200] loss: 2.107\n",
      "[1,   400] loss: 2.041\n",
      "[1,   600] loss: 2.001\n",
      "Accuracy of the network on the 10000 test images: 57 %\n",
      "[2,   200] loss: 1.849\n",
      "[2,   400] loss: 1.841\n",
      "[2,   600] loss: 1.836\n",
      "Accuracy of the network on the 10000 test images: 65 %\n"
     ]
    }
   ],
   "source": [
    "print('******************normal case with adam****************')\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(neta.parameters(), lr=learning_rate)\n",
    "adam_loss = []\n",
    "adam_accuracy = []\n",
    "for epoch in range(NUM_EPOCH) :    \n",
    "    running_loss = 0.0\n",
    "    neta.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = neta(inputs.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "    \n",
    "    neta.eval()\n",
    "    test_acc = test(neta)\n",
    "    adam_loss.append(running_loss/len(trainloader))\n",
    "    adam_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f894a66e-6353-4f2f-84bc-6ab87ed265dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(conw1[0][0][0])\n",
    "print(conw1g[0][0][0])\n",
    "print(conw1a[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3243969-2c2d-4aa5-bc74-66d5c6432826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdfeb2d1-947e-48c5-8b39-1f7d32063239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************grad gated****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.188\n",
      "[1,   400] loss: 2.153\n",
      "[1,   600] loss: 2.125\n",
      "Accuracy of the network on the 10000 test images: 41 %\n",
      "[2,   200] loss: 1.981\n",
      "[2,   400] loss: 1.960\n",
      "[2,   600] loss: 1.948\n",
      "Accuracy of the network on the 10000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.1, 0.1, 0.05, 0.05, 0.05, 0.02, 0.02, \n",
    "           0.02, 0.01, 0.01, 0.01, 0.005,\n",
    "           0.005, 0.002, 0.001]\n",
    "print('******************grad gated****************')\n",
    "# lr_list = [0.05] * NUM_EPOCH\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "gated_loss = []\n",
    "gated_accuracy = []\n",
    "for epoch in range(NUM_EPOCH) :    \n",
    "    running_loss = 0.0\n",
    "    learning_rate = lr_list[epoch]\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = netg(inputs.to(device), conw1g, conw2g, conw3g, conw4g, conw5g)\n",
    "#         print(outputs.shape)\n",
    "#         print(labels.shape)\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "#         print(loss)\n",
    "        loss.backward()    \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Update weights using gradient descent\n",
    "            conw1g -= learning_rate * conw1g.grad\n",
    "            conw2g -= learning_rate * conw2g.grad\n",
    "            conw3g -= learning_rate * conw3g.grad\n",
    "            conw4g -= learning_rate * conw4g.grad\n",
    "            conw5g -= learning_rate * conw5g.grad\n",
    "\n",
    "            # Manually zero the gradients after running the backward pass\n",
    "            conw1g.grad.zero_()\n",
    "            conw2g.grad.zero_()\n",
    "            conw3g.grad.zero_()\n",
    "            conw4g.grad.zero_()\n",
    "            conw5g.grad.zero_()\n",
    "            \n",
    "    test_acc = test(netg, conw1g, conw2g, conw3g, conw4g, conw5g)\n",
    "    gated_loss.append(running_loss/len(trainloader))\n",
    "    gated_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8108ddf5-e838-4a60-89fe-1f6c16cea97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([-0.4308,  1.8749,  2.3224,  0.2159, -2.3417], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(conw1[0][0][0])\n",
    "print(conw1g[0][0][0])\n",
    "print(conw1a[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3be209fc-1dc9-4503-8cac-cb289ca17d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************normal case****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.144\n",
      "[1,   400] loss: 2.102\n",
      "[1,   600] loss: 2.066\n",
      "Accuracy of the network on the 10000 test images: 49 %\n",
      "[2,   200] loss: 1.935\n",
      "[2,   400] loss: 1.926\n",
      "[2,   600] loss: 1.919\n",
      "Accuracy of the network on the 10000 test images: 57 %\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.1, 0.1, 0.05, 0.05, 0.05, 0.02, 0.02, \n",
    "           0.02, 0.01, 0.01, 0.01, 0.005,\n",
    "           0.005, 0.002, 0.001]\n",
    "print('******************normal case****************')\n",
    "# lr_list = [0.05] * NUM_EPOCH\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "normal_loss = []\n",
    "normal_accuracy = []\n",
    "for epoch in range(NUM_EPOCH) :    \n",
    "    running_loss = 0.0\n",
    "    learning_rate = lr_list[epoch]\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = net(inputs.to(device), conw1, conw2, conw3, conw4, conw5)\n",
    "#         print(outputs.shape)\n",
    "#         print(labels.shape)\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "#         print(loss)\n",
    "        loss.backward()    \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Update weights using gradient descent\n",
    "            conw1 -= learning_rate * conw1.grad\n",
    "            conw2 -= learning_rate * conw2.grad\n",
    "            conw3 -= learning_rate * conw3.grad\n",
    "            conw4 -= learning_rate * conw4.grad\n",
    "            conw5 -= learning_rate * conw5.grad\n",
    "\n",
    "            # Manually zero the gradients after running the backward pass\n",
    "            conw1.grad.zero_()\n",
    "            conw2.grad.zero_()   \n",
    "            conw3.grad.zero_()\n",
    "            conw4.grad.zero_()       \n",
    "            conw5.grad.zero_()                   \n",
    "            \n",
    "    test_acc = test(net, conw1, conw2, conw3, conw4, conw5)\n",
    "    normal_loss.append(running_loss/len(trainloader))\n",
    "    normal_accuracy.append(test_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "305b240b-b140-4b43-b416-f29fe3fe23e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0530, -0.0751, -0.1955,  0.1179,  0.0591], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([-0.4308,  1.8749,  2.3224,  0.2159, -2.3417], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0080,  0.0216, -0.1431,  0.1397,  0.1133], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(conw1[0][0][0])\n",
    "print(conw1g[0][0][0])\n",
    "print(conw1a[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dc86290-8dcf-4ba5-b081-a68e0f0b5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_loss\n",
    "# normal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13d25a3b-a193-4654-9754-c1d9ebb73575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gated_loss\n",
    "# gated_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "718b9f1d-1159-47e7-a3be-1a5afd747d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam_loss\n",
    "# adam_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d2eb9d7-947b-4bda-9cbf-a41913ad6f9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (15,) and (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1c9803de9a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_loss\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgated_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2988\u001b[0m     return gca().plot(\n\u001b[1;32m   2989\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2990\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (15,) and (2,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.arange(0,15,1)\n",
    "plt.plot(X, adam_loss,  color='red')\n",
    "plt.plot(X, gated_loss, color='blue')\n",
    "plt.plot(X, normal_loss, color='green')\n",
    "plt.legend(['adam', 'gated', 'normal'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b0e00-0d6b-45e7-b5ed-acb133063d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.arange(0,15,1)\n",
    "plt.plot(X, adam_accuracy,  color='red')\n",
    "plt.plot(X, gated_accuracy, color='blue')\n",
    "plt.plot(X, normal_accuracy, color='green')\n",
    "plt.legend(['adam', 'gated', 'normal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710eb41-7640-4ae6-86b4-bb68aba4907e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
