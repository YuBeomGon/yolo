{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e953aaff-5e25-46ee-a200-7043b49bf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/call-backward-on-function-inside-a-backpropagation-step/3793\n",
    "# https://discuss.pytorch.org/t/implementing-a-custom-convolution-using-conv2d-input-and-conv2d-weight/18556\n",
    "# https://discuss.pytorch.org/t/implementing-a-custom-convolution-using-conv2d-input-and-conv2d-weight/18556/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d81d1b7-de30-4c36-a039-14389f064908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3e9003-9102-4e71-98f6-bab909d4376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gated gradient\n",
    "class Conv2dFunctionG(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None, stride=1, padding=1, dilation=1, groups=1):\n",
    "        # Save arguments to context to use on backward\n",
    "        # WARNING : if stride, padding, dilation etc is array, this will not work properly!!!!\n",
    "#         print('stride', stride)\n",
    "        if weight.shape[2] == 1 :\n",
    "            padding = 0\n",
    "        elif weight.shape[2] == 5 :\n",
    "            padding = 2\n",
    "        elif weight.shape[2] == 7 :\n",
    "            padding = 3\n",
    "        confs = torch.from_numpy(np.array([stride, padding, dilation, groups]))\n",
    "        out = F.conv2d(input, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
    "        ctx.save_for_backward(input, out, weight, bias, confs)\n",
    "\n",
    "        # Compute Convolution\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Load saved tensors\n",
    "        input, out, weight, bias, confs = ctx.saved_variables\n",
    "        confs = confs.numpy()\n",
    "        stride, padding, dilation, groups= confs[0], confs[1], confs[2], confs[3]\n",
    "\n",
    "        # Calculate Gradient\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "#         gradient is gated according to the feature map of each layer\n",
    "        grad_output = grad_output * 2*torch.sigmoid(out)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.nn.grad.conv2d_input(input.shape, weight, grad_output, stride, padding, dilation, groups)\n",
    "#             grad_input = 2*torch.sigmoid(input)*torch.nn.grad.conv2d_input(input.shape, weight, grad_output, stride, padding, dilation, groups)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.nn.grad.conv2d_weight(input, weight.shape, grad_output, stride, padding, dilation, groups)\n",
    "                \n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "\n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None:\n",
    "            return grad_input, grad_weight, grad_bias, None, None, None, None\n",
    "        else:\n",
    "            return grad_input, grad_weight, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335decb8-b3ae-49d9-b7f3-2c60ae3f931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal case, stoachastic gradient \n",
    "class Conv2dFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None, stride=1, padding=1, dilation=1, groups=1):\n",
    "        # Save arguments to context to use on backward\n",
    "        # WARNING : if stride, padding, dilation etc is array, this will not work properly!!!!\n",
    "#         print('stride', stride)\n",
    "        if weight.shape[2] == 1 :\n",
    "            padding = 0\n",
    "        elif weight.shape[2] == 5 :\n",
    "            padding = 2\n",
    "        elif weight.shape[2] == 7 :\n",
    "            padding = 3\n",
    "        confs = torch.from_numpy(np.array([stride, padding, dilation, groups]))\n",
    "        out = F.conv2d(input, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
    "        ctx.save_for_backward(input, out, weight, bias, confs)\n",
    "\n",
    "        # Compute Convolution\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Load saved tensors\n",
    "        input, out, weight, bias, confs = ctx.saved_variables\n",
    "        confs = confs.numpy()\n",
    "        stride, padding, dilation, groups= confs[0], confs[1], confs[2], confs[3]\n",
    "\n",
    "        # Calculate Gradient\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "#         grad_output = grad_output * 2*torch.sigmoid(out)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.nn.grad.conv2d_input(input.shape, weight, grad_output, stride, padding, dilation, groups)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.nn.grad.conv2d_weight(input, weight.shape, grad_output, stride, padding, dilation, groups)\n",
    "                \n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "\n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None:\n",
    "            return grad_input, grad_weight, grad_bias, None, None, None, None\n",
    "        else:\n",
    "            return grad_input, grad_weight, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd706d30-a744-47e1-b4e7-b000f8dd4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import gradcheck\n",
    "# conv = Conv2dFunction.apply\n",
    "# gradcheck takes a tuple of tensors as input, check if your gradient\n",
    "# evaluated with these tensors are close enough to numerical\n",
    "# approximations and returns True if they all verify this condition.\n",
    "# input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))\n",
    "# test = gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "# print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbec456-07f5-48e8-ac80-64201f5d4e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=8)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0714c16b-d4d3-4993-9880-6ac5862e56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# N, C_in, C_out, K_size = batch_size, 3, 12, 3\n",
    "# Create random Tensors for weights.\n",
    "conw1 = torch.randn(8,3,5,5, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2 = torch.randn(32,8,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3 = torch.randn(128,32,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4 = torch.randn(128,128,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5 = torch.randn(10,128,1,1, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# weight for normal\n",
    "conw1 = torch.nn.init.xavier_uniform_(conw1, gain=1.0)\n",
    "conw2 = torch.nn.init.xavier_uniform_(conw2, gain=1.0)\n",
    "conw3 = torch.nn.init.xavier_uniform_(conw3, gain=1.0)\n",
    "conw4 = torch.nn.init.xavier_uniform_(conw4, gain=1.0)\n",
    "conw5 = torch.nn.init.xavier_uniform_(conw5, gain=1.0)\n",
    "\n",
    "# weight for gated\n",
    "# conw1g = conw1.clone().detatch(requires_grad=True)\n",
    "conw1g = torch.tensor(conw1, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2g = torch.tensor(conw2, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3g = torch.tensor(conw3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4g = torch.tensor(conw4, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5g = torch.tensor(conw5, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# weight for adam \n",
    "conw1a = torch.tensor(conw1, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2a = torch.tensor(conw2, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3a = torch.tensor(conw3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4a = torch.tensor(conw4, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5a = torch.tensor(conw5, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# print(conw1[0][0])\n",
    "# print(torch.nn.init.xavier_uniform_(conw1, gain=1.0)[0][0])\n",
    "# print(conw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac85c29-61e9-4b91-aa7e-c2077b9ffc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conw1 is conw1g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cdcc33-4b9d-4116-9403-15e1fc416f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67ad14c-9a63-4152-aee0-5ea1d976d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conw1g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d83544-adbf-49f9-bf2e-de7891fa75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = Conv2dFunction.apply\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = Conv2dFunction.apply\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = Conv2dFunction.apply\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = Conv2dFunction.apply\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = Conv2dFunction.apply\n",
    "        self.avgpool = torch.nn.AvgPool2d((2,2) ,stride=(2,2))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, w1, w2, w3, w4, w5):\n",
    "        x = self.act(self.conv1(x, w1))\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv2(x, w2))\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv3(x, w3))\n",
    "        x = self.bn3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv4(x, w4))\n",
    "        x = self.bn4(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x, w5)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# gated model    \n",
    "class NetG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetG, self).__init__()\n",
    "        self.conv1 = Conv2dFunctionG.apply\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = Conv2dFunctionG.apply\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = Conv2dFunctionG.apply\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = Conv2dFunctionG.apply\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = Conv2dFunctionG.apply\n",
    "        self.avgpool = torch.nn.AvgPool2d((2,2) ,stride=(2,2))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, w1, w2, w3, w4, w5):\n",
    "        x = self.act(self.conv1(x, w1))\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv2(x, w2))\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv3(x, w3))\n",
    "        x = self.bn3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv4(x, w4))\n",
    "        x = self.bn4(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x, w5)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x    \n",
    "\n",
    "#     adam model\n",
    "class NetA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetA, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,8,kernel_size=(5,5),padding=2,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8,32,kernel_size=(3,3),padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,128,kernel_size=(3,3),padding=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128,128,kernel_size=(3,3),padding=1,bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128,10,kernel_size=(1,1),padding=0,bias=False)\n",
    "        self.avgpool = torch.nn.AvgPool2d((2,2) ,stride=(2,2))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "#         self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn4(self.conv4(x))\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f00a2e-56f8-400a-8f67-c2566254a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "netg = NetG().to(device)\n",
    "neta = NetA().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f330ad0-bb90-47df-acae-e51e49f0ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_mean\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_var\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.num_batches_tracked\n",
      "tensor(0, device='cuda:0')\n",
      "bn1.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_mean\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_var\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.num_batches_tracked\n",
      "tensor(0, device='cuda:0')\n",
      "bn1.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_mean\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_var\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.num_batches_tracked\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for k in neta.state_dict() :\n",
    "    if 'bn1' in k :\n",
    "        print(k)\n",
    "        print(neta.state_dict()[k])\n",
    "        \n",
    "for k in netg.state_dict() :\n",
    "    if 'bn1' in k :\n",
    "        print(k)\n",
    "        print(netg.state_dict()[k])   \n",
    "for k in net.state_dict() :\n",
    "    if 'bn1' in k :\n",
    "        print(k)\n",
    "        print(net.state_dict()[k])              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a5c621-d1ae-4e31-a55c-403b5ba31886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in neta.parameters() :\n",
    "#     print(p[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e125c3c4-b8bc-41b3-9bae-894a6e1b8c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for param in neta.parameters() :\n",
    "#     print(param.shape)\n",
    "\n",
    "# parameter for adam should be same with other model\n",
    "neta_dict = neta.state_dict()\n",
    "for p in neta_dict :\n",
    "    if 'conv1' in p :\n",
    "        neta_dict[p] = conw1a\n",
    "    elif 'conv2' in p :\n",
    "        neta_dict[p] = conw2a\n",
    "    elif 'conv3' in p :\n",
    "        neta_dict[p] = conw3a\n",
    "    elif 'conv4' in p :\n",
    "        neta_dict[p] = conw4a\n",
    "    elif 'conv5' in p :\n",
    "        neta_dict[p] = conw5a        \n",
    "#     print(p)\n",
    "#     print(neta.state_dict()[p].shape)\n",
    "#     print()\n",
    "neta.load_state_dict(neta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f3efdec-9d54-4b5a-bde2-7f5d01347aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in neta.parameters() :\n",
    "#     print(p[0][0][0])\n",
    "# print(conw1a[0][0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610eb50f-2961-4154-81a9-fce75b43ad93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bb5f59f-6c53-4939-904a-c0bc8dcbec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "image, label = iter(trainloader).next()\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7b5f1-5973-4a1a-81e6-b9604c18860e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f2c4fbe-b6f4-412b-bfcd-30d6182cb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "image, labels = iter(trainloader).next()\n",
    "outputs = net(image.to(device), conw1, conw2, conw3, conw4, conw5).to(device)\n",
    "print(outputs.shape)\n",
    "# print(outputs.sum(dim=1))\n",
    "# print(outputs)\n",
    "loss = criterion(outputs, labels.to(device))\n",
    "# loss.backward()\n",
    "# print(torch.nn.Softmax(dim=1)(outputs).sum(dim=1))\n",
    "# outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf08457c-bdf5-454d-b152-91959d5d4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conw5.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a08cb68-a7a9-4163-b096-420b0da1e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (model, w1=None, w2=None, w3=None, w4=None, w5=None) :\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            if w1 == None :\n",
    "                outputs = model(inputs.to(device))\n",
    "            else :\n",
    "                outputs = model(inputs.to(device), w1, w2, w3, w4, w5)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8cf486-5b31-4932-be7a-65eda393e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2309ec7d-2cba-4900-ab93-c2515453ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************normal case with adam****************\n",
      "[1,   200] loss: 2.103\n",
      "[1,   400] loss: 2.047\n",
      "[1,   600] loss: 2.015\n",
      "Accuracy of the network on the 10000 test images: 45 %\n",
      "[2,   200] loss: 1.898\n",
      "[2,   400] loss: 1.891\n",
      "[2,   600] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "[3,   200] loss: 1.840\n",
      "[3,   400] loss: 1.838\n",
      "[3,   600] loss: 1.837\n",
      "Accuracy of the network on the 10000 test images: 58 %\n",
      "[4,   200] loss: 1.814\n",
      "[4,   400] loss: 1.809\n",
      "[4,   600] loss: 1.798\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[5,   200] loss: 1.734\n",
      "[5,   400] loss: 1.738\n",
      "[5,   600] loss: 1.738\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[6,   200] loss: 1.707\n",
      "[6,   400] loss: 1.713\n",
      "[6,   600] loss: 1.716\n",
      "Accuracy of the network on the 10000 test images: 69 %\n",
      "[7,   200] loss: 1.693\n",
      "[7,   400] loss: 1.695\n",
      "[7,   600] loss: 1.696\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[8,   200] loss: 1.679\n",
      "[8,   400] loss: 1.676\n",
      "[8,   600] loss: 1.678\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[9,   200] loss: 1.653\n",
      "[9,   400] loss: 1.657\n",
      "[9,   600] loss: 1.662\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[10,   200] loss: 1.643\n",
      "[10,   400] loss: 1.646\n",
      "[10,   600] loss: 1.649\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[11,   200] loss: 1.633\n",
      "[11,   400] loss: 1.638\n",
      "[11,   600] loss: 1.639\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[12,   200] loss: 1.622\n",
      "[12,   400] loss: 1.625\n",
      "[12,   600] loss: 1.628\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[13,   200] loss: 1.616\n",
      "[13,   400] loss: 1.613\n",
      "[13,   600] loss: 1.617\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[14,   200] loss: 1.609\n",
      "[14,   400] loss: 1.607\n",
      "[14,   600] loss: 1.608\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[15,   200] loss: 1.598\n",
      "[15,   400] loss: 1.600\n",
      "[15,   600] loss: 1.600\n",
      "Accuracy of the network on the 10000 test images: 74 %\n"
     ]
    }
   ],
   "source": [
    "print('******************normal case with adam****************')\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(neta.parameters(), lr=learning_rate)\n",
    "adam_loss = []\n",
    "adam_accuracy = []\n",
    "for epoch in range(NUM_EPOCH) :    \n",
    "    running_loss = 0.0\n",
    "    neta.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = neta(inputs.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "    \n",
    "    neta.eval()\n",
    "    test_acc = test(neta)\n",
    "    adam_loss.append(running_loss/len(trainloader))\n",
    "    adam_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3243969-2c2d-4aa5-bc74-66d5c6432826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdfeb2d1-947e-48c5-8b39-1f7d32063239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************grad gated****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.130\n",
      "[1,   400] loss: 2.089\n",
      "[1,   600] loss: 2.059\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "[2,   200] loss: 1.936\n",
      "[2,   400] loss: 1.919\n",
      "[2,   600] loss: 1.901\n",
      "Accuracy of the network on the 10000 test images: 58 %\n",
      "[3,   200] loss: 1.792\n",
      "[3,   400] loss: 1.787\n",
      "[3,   600] loss: 1.784\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[4,   200] loss: 1.739\n",
      "[4,   400] loss: 1.743\n",
      "[4,   600] loss: 1.743\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "[5,   200] loss: 1.717\n",
      "[5,   400] loss: 1.716\n",
      "[5,   600] loss: 1.715\n",
      "Accuracy of the network on the 10000 test images: 69 %\n",
      "[6,   200] loss: 1.673\n",
      "[6,   400] loss: 1.671\n",
      "[6,   600] loss: 1.674\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[7,   200] loss: 1.655\n",
      "[7,   400] loss: 1.656\n",
      "[7,   600] loss: 1.655\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[8,   200] loss: 1.639\n",
      "[8,   400] loss: 1.640\n",
      "[8,   600] loss: 1.643\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[9,   200] loss: 1.624\n",
      "[9,   400] loss: 1.623\n",
      "[9,   600] loss: 1.622\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[10,   200] loss: 1.609\n",
      "[10,   400] loss: 1.610\n",
      "[10,   600] loss: 1.611\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[11,   200] loss: 1.605\n",
      "[11,   400] loss: 1.607\n",
      "[11,   600] loss: 1.606\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[12,   200] loss: 1.594\n",
      "[12,   400] loss: 1.597\n",
      "[12,   600] loss: 1.597\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[13,   200] loss: 1.594\n",
      "[13,   400] loss: 1.595\n",
      "[13,   600] loss: 1.595\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[14,   200] loss: 1.591\n",
      "[14,   400] loss: 1.591\n",
      "[14,   600] loss: 1.591\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[15,   200] loss: 1.587\n",
      "[15,   400] loss: 1.586\n",
      "[15,   600] loss: 1.587\n",
      "Accuracy of the network on the 10000 test images: 73 %\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.1, 0.1, 0.05, 0.05, 0.05, 0.02, 0.02, \n",
    "           0.02, 0.01, 0.01, 0.01, 0.005,\n",
    "           0.005, 0.002, 0.001]\n",
    "print('******************grad gated****************')\n",
    "# lr_list = [0.05] * NUM_EPOCH\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(neta.parameters(), lr=0.001)\n",
    "gated_loss = []\n",
    "gated_accuracy = []\n",
    "for epoch in range(NUM_EPOCH) :    \n",
    "    running_loss = 0.0\n",
    "    learning_rate = lr_list[epoch]\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = netg(inputs.to(device), conw1g, conw2g, conw3g, conw4g, conw5g)\n",
    "#         print(outputs.shape)\n",
    "#         print(labels.shape)\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Update weights using gradient descent\n",
    "            conw1g -= learning_rate * conw1g.grad\n",
    "            conw2g -= learning_rate * conw2g.grad\n",
    "            conw3g -= learning_rate * conw3g.grad\n",
    "            conw4g -= learning_rate * conw4g.grad\n",
    "            conw5g -= learning_rate * conw5g.grad\n",
    "\n",
    "            # Manually zero the gradients after running the backward pass\n",
    "            conw1g.grad.zero_()\n",
    "            conw2g.grad.zero_()\n",
    "            conw3g.grad.zero_()\n",
    "            conw4g.grad.zero_()\n",
    "            conw5g.grad.zero_()\n",
    "            \n",
    "    test_acc = test(netg, conw1g, conw2g, conw3g, conw4g, conw5g)\n",
    "    gated_loss.append(running_loss/len(trainloader))\n",
    "    gated_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7113b4c5-d1ad-4b7b-85f6-5541842f8423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_mean\n",
      "tensor([0.6654, 0.4821, 0.8774, 0.8833, 0.5473, 0.6303, 0.7708, 0.5034],\n",
      "       device='cuda:0')\n",
      "bn1.running_var\n",
      "tensor([1.7426, 0.6840, 2.2765, 1.7998, 0.8122, 1.0671, 1.3729, 0.8521],\n",
      "       device='cuda:0')\n",
      "bn1.num_batches_tracked\n",
      "tensor(14085, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for k in netg.state_dict() :\n",
    "    if 'bn1' in k :\n",
    "        print(k)\n",
    "        print(netg.state_dict()[k])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3be209fc-1dc9-4503-8cac-cb289ca17d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************normal case****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.119\n",
      "[1,   400] loss: 2.072\n",
      "[1,   600] loss: 2.043\n",
      "Accuracy of the network on the 10000 test images: 52 %\n",
      "[2,   200] loss: 1.919\n",
      "[2,   400] loss: 1.904\n",
      "[2,   600] loss: 1.894\n",
      "Accuracy of the network on the 10000 test images: 60 %\n",
      "[3,   200] loss: 1.805\n",
      "[3,   400] loss: 1.804\n",
      "[3,   600] loss: 1.801\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[4,   200] loss: 1.769\n",
      "[4,   400] loss: 1.767\n",
      "[4,   600] loss: 1.768\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "[5,   200] loss: 1.738\n",
      "[5,   400] loss: 1.740\n",
      "[5,   600] loss: 1.740\n",
      "Accuracy of the network on the 10000 test images: 68 %\n",
      "[6,   200] loss: 1.701\n",
      "[6,   400] loss: 1.700\n",
      "[6,   600] loss: 1.699\n",
      "Accuracy of the network on the 10000 test images: 69 %\n",
      "[7,   200] loss: 1.687\n",
      "[7,   400] loss: 1.684\n",
      "[7,   600] loss: 1.683\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[8,   200] loss: 1.673\n",
      "[8,   400] loss: 1.674\n",
      "[8,   600] loss: 1.674\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[9,   200] loss: 1.655\n",
      "[9,   400] loss: 1.655\n",
      "[9,   600] loss: 1.656\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[10,   200] loss: 1.648\n",
      "[10,   400] loss: 1.648\n",
      "[10,   600] loss: 1.647\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[11,   200] loss: 1.638\n",
      "[11,   400] loss: 1.641\n",
      "[11,   600] loss: 1.642\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[12,   200] loss: 1.632\n",
      "[12,   400] loss: 1.633\n",
      "[12,   600] loss: 1.632\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[13,   200] loss: 1.626\n",
      "[13,   400] loss: 1.627\n",
      "[13,   600] loss: 1.629\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[14,   200] loss: 1.627\n",
      "[14,   400] loss: 1.625\n",
      "[14,   600] loss: 1.624\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[15,   200] loss: 1.621\n",
      "[15,   400] loss: 1.622\n",
      "[15,   600] loss: 1.622\n",
      "Accuracy of the network on the 10000 test images: 71 %\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.1, 0.1, 0.05, 0.05, 0.05, 0.02, 0.02, \n",
    "           0.02, 0.01, 0.01, 0.01, 0.005,\n",
    "           0.005, 0.002, 0.001]\n",
    "print('******************normal case****************')\n",
    "# lr_list = [0.05] * NUM_EPOCH\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(neta.parameters(), lr=0.001)\n",
    "normal_loss = []\n",
    "normal_accuracy = []\n",
    "for epoch in range(NUM_EPOCH) :    \n",
    "    running_loss = 0.0\n",
    "    learning_rate = lr_list[epoch]\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = net(inputs.to(device), conw1, conw2, conw3, conw4, conw5)\n",
    "#         print(outputs.shape)\n",
    "#         print(labels.shape)\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "#         print(loss)\n",
    "        loss.backward()   \n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Update weights using gradient descent\n",
    "            conw1 -= learning_rate * conw1.grad\n",
    "            conw2 -= learning_rate * conw2.grad\n",
    "            conw3 -= learning_rate * conw3.grad\n",
    "            conw4 -= learning_rate * conw4.grad\n",
    "            conw5 -= learning_rate * conw5.grad\n",
    "\n",
    "            # Manually zero the gradients after running the backward pass\n",
    "            conw1.grad.zero_()\n",
    "            conw2.grad.zero_()   \n",
    "            conw3.grad.zero_()\n",
    "            conw4.grad.zero_()       \n",
    "            conw5.grad.zero_()                   \n",
    "            \n",
    "    test_acc = test(net, conw1, conw2, conw3, conw4, conw5)\n",
    "    normal_loss.append(running_loss/len(trainloader))\n",
    "    normal_accuracy.append(test_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "874e72e3-b916-49a3-bbd4-9c0cdd2c0c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "bn1.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "bn1.running_mean\n",
      "tensor([0.1537, 0.1423, 0.3052, 0.3083, 0.1378, 0.1930, 0.2093, 0.2043],\n",
      "       device='cuda:0')\n",
      "bn1.running_var\n",
      "tensor([0.0799, 0.0708, 0.2034, 0.2183, 0.0804, 0.0960, 0.1399, 0.1199],\n",
      "       device='cuda:0')\n",
      "bn1.num_batches_tracked\n",
      "tensor(14086, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for k in net.state_dict() :\n",
    "    if 'bn1' in k :\n",
    "        print(k)\n",
    "        print(net.state_dict()[k])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dc86290-8dcf-4ba5-b081-a68e0f0b5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_loss\n",
    "# normal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13d25a3b-a193-4654-9754-c1d9ebb73575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gated_loss\n",
    "# gated_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718b9f1d-1159-47e7-a3be-1a5afd747d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam_loss\n",
    "# adam_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d2eb9d7-947b-4bda-9cbf-a41913ad6f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.arange(0,15,1)\n",
    "plt.plot(X, adam_loss,  color='red')\n",
    "plt.plot(X, gated_loss, color='blue')\n",
    "plt.plot(X, normal_loss, color='green')\n",
    "plt.legend(['adam', 'gated', 'normal'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "740b0e00-0d6b-45e7-b5ed-acb133063d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.arange(0,15,1)\n",
    "plt.plot(X, adam_accuracy,  color='red')\n",
    "plt.plot(X, gated_accuracy, color='blue')\n",
    "plt.plot(X, normal_accuracy, color='green')\n",
    "plt.legend(['adam', 'gated', 'normal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710eb41-7640-4ae6-86b4-bb68aba4907e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
