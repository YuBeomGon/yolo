{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e953aaff-5e25-46ee-a200-7043b49bf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/call-backward-on-function-inside-a-backpropagation-step/3793\n",
    "# https://discuss.pytorch.org/t/implementing-a-custom-convolution-using-conv2d-input-and-conv2d-weight/18556\n",
    "# https://discuss.pytorch.org/t/implementing-a-custom-convolution-using-conv2d-input-and-conv2d-weight/18556/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d81d1b7-de30-4c36-a039-14389f064908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3e9003-9102-4e71-98f6-bab909d4376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv2dFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None, stride=1, padding=1, dilation=1, groups=1):\n",
    "        # Save arguments to context to use on backward\n",
    "        # WARNING : if stride, padding, dilation etc is array, this will not work properly!!!!\n",
    "#         print('stride', stride)\n",
    "        if weight.shape[2] == 1 :\n",
    "            padding = 0\n",
    "        elif weight.shape[2] == 5 :\n",
    "            padding = 2\n",
    "        elif weight.shape[2] == 7 :\n",
    "            padding = 3\n",
    "        confs = torch.from_numpy(np.array([stride, padding, dilation, groups]))\n",
    "        ctx.save_for_backward(input, weight, bias, confs)\n",
    "\n",
    "        # Compute Convolution\n",
    "        return F.conv2d(input, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Load saved tensors\n",
    "        input, weight, bias, confs = ctx.saved_variables\n",
    "        confs = confs.numpy()\n",
    "        stride, padding, dilation, groups= confs[0], confs[1], confs[2], confs[3]\n",
    "\n",
    "        # Calculate Gradient\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.nn.grad.conv2d_input(input.shape, weight, grad_output, stride, padding, dilation, groups)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.nn.grad.conv2d_weight(input, weight.shape, grad_output, stride, padding, dilation, groups)\n",
    "                \n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "\n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None:\n",
    "            return grad_input, grad_weight, grad_bias, None, None, None, None\n",
    "        else:\n",
    "            return grad_input, grad_weight, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd706d30-a744-47e1-b4e7-b000f8dd4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck\n",
    "conv = Conv2dFunction.apply\n",
    "# gradcheck takes a tuple of tensors as input, check if your gradient\n",
    "# evaluated with these tensors are close enough to numerical\n",
    "# approximations and returns True if they all verify this condition.\n",
    "# input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))\n",
    "# test = gradcheck(linear, input, eps=1e-6, atol=1e-4)\n",
    "# print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbec456-07f5-48e8-ac80-64201f5d4e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0714c16b-d4d3-4993-9880-6ac5862e56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, C_in, C_out, K_size = batch_size, 3, 12, 3\n",
    "# Create random Tensors for weights.\n",
    "conw1 = torch.randn(8,3,5,5, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2 = torch.randn(32,8,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3 = torch.randn(128,32,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4 = torch.randn(128,128,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5 = torch.randn(10,128,1,1, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "conw1 = torch.nn.init.xavier_uniform_(conw1, gain=1.0)\n",
    "conw2 = torch.nn.init.xavier_uniform_(conw2, gain=1.0)\n",
    "conw3 = torch.nn.init.xavier_uniform_(conw3, gain=1.0)\n",
    "conw4 = torch.nn.init.xavier_uniform_(conw4, gain=1.0)\n",
    "conw5 = torch.nn.init.xavier_uniform_(conw5, gain=1.0)\n",
    "# print(conw1)\n",
    "# print(conw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d83544-adbf-49f9-bf2e-de7891fa75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = Conv2dFunction.apply\n",
    "        self.conv2 = Conv2dFunction.apply\n",
    "        self.conv3 = Conv2dFunction.apply\n",
    "        self.conv4 = Conv2dFunction.apply\n",
    "        self.conv5 = Conv2dFunction.apply\n",
    "        self.avgpool = torch.nn.AvgPool2d((16,16) ,stride=(16,16))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, w1, w2, w3, w4, w5):\n",
    "#         x = self.conv1(x, w1)\n",
    "#         x = self.act(x)\n",
    "#         x = self.conv2(x, w2)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.conv3(x, w3)\n",
    "#         x = self.act(x)\n",
    "#         x = self.conv4(x, w4)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "#         x = torch.nn.Softmax(dim=1)(x)\n",
    "\n",
    "        x = self.conv1(x, w1)\n",
    "        x = self.act(x)\n",
    "        x = torch.nn.BatchNorm2d(8).to(device)(x)\n",
    "        x = self.act(self.conv2(x, w2))\n",
    "        x = self.maxpool(x)\n",
    "        x = torch.nn.BatchNorm2d(32).to(device)(x)\n",
    "        x = self.conv3(x, w3)\n",
    "        x = self.act(x)\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.act(self.conv4(x, w4))\n",
    "        x = torch.nn.BatchNorm2d(128).to(device)(x)\n",
    "        x = self.conv5(x, w5)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "#         x = torch.nn.Softmax(dim=1)(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f00a2e-56f8-400a-8f67-c2566254a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb5f59f-6c53-4939-904a-c0bc8dcbec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "image, label = iter(trainloader).next()\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2c4fbe-b6f4-412b-bfcd-30d6182cb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.3852, 5.1312, 5.1291, 4.5985, 4.7257, 5.4525, 5.1078, 5.1414, 5.0053,\n",
      "        4.8059, 4.5361, 4.6694, 4.8804, 4.9882, 4.7773, 5.2820, 4.5821, 5.1986,\n",
      "        4.8851, 5.3089, 5.4936, 4.9226, 4.5855, 5.3331, 5.0343, 5.0437, 4.5800,\n",
      "        5.3194, 4.8920, 4.6095, 5.4020, 4.3477, 6.2052, 4.7943, 4.4879, 5.3667,\n",
      "        4.6738, 5.4539, 4.6145, 5.2922, 5.0118, 4.7892, 5.3580, 6.3817, 5.0193,\n",
      "        5.0355, 5.0187, 4.7582, 5.2573, 4.7536, 4.4561, 5.3869, 4.9071, 4.0278,\n",
      "        4.8598, 5.0734, 4.7922, 4.8079, 5.0655, 5.4134, 5.0137, 5.1085, 5.3020,\n",
      "        4.6449], device='cuda:0', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    }
   ],
   "source": [
    "image, labels = iter(trainloader).next()\n",
    "outputs = net(image.to(device), conw1, conw2, conw3, conw4, conw5).to(device)\n",
    "print(outputs.sum(dim=1))\n",
    "# print(outputs)\n",
    "loss = criterion(outputs, labels.to(device))\n",
    "loss.backward()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf08457c-bdf5-454d-b152-91959d5d4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conw5.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a08cb68-a7a9-4163-b096-420b0da1e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (model, w1, w2, w3, w4, w5) :\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            outputs = model(inputs.to(device), w1, w2, w3, w4, w5)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2309ec7d-2cba-4900-ab93-c2515453ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.012\n",
      "tensor([-0.0739], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[1,   201] loss: 2.097\n",
      "tensor([-0.0830], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[1,   401] loss: 2.030\n",
      "tensor([-0.0886], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[1,   601] loss: 2.012\n",
      "tensor([-0.0941], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 37 %\n",
      "[2,     1] loss: 0.010\n",
      "tensor([-0.0980], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[2,   201] loss: 1.988\n",
      "tensor([-0.1035], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[2,   401] loss: 1.977\n",
      "tensor([-0.1084], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[2,   601] loss: 1.972\n",
      "tensor([-0.1103], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 40 %\n",
      "[3,     1] loss: 0.010\n",
      "tensor([-0.1122], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[3,   201] loss: 1.960\n",
      "tensor([-0.1159], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[3,   401] loss: 1.951\n",
      "tensor([-0.1176], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[3,   601] loss: 1.945\n",
      "tensor([-0.1197], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 42 %\n",
      "[4,     1] loss: 0.010\n",
      "tensor([-0.1210], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[4,   201] loss: 1.937\n",
      "tensor([-0.1236], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[4,   401] loss: 1.932\n",
      "tensor([-0.1251], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[4,   601] loss: 1.930\n",
      "tensor([-0.1271], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 45 %\n",
      "[5,     1] loss: 0.010\n",
      "tensor([-0.1299], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[5,   201] loss: 1.921\n",
      "tensor([-0.1314], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[5,   401] loss: 1.920\n",
      "tensor([-0.1322], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[5,   601] loss: 1.912\n",
      "tensor([-0.1342], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 46 %\n",
      "[6,     1] loss: 0.010\n",
      "tensor([-0.1354], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[6,   201] loss: 1.910\n",
      "tensor([-0.1370], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[6,   401] loss: 1.910\n",
      "tensor([-0.1393], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[6,   601] loss: 1.904\n",
      "tensor([-0.1415], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "[7,     1] loss: 0.010\n",
      "tensor([-0.1424], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[7,   201] loss: 1.900\n",
      "tensor([-0.1443], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[7,   401] loss: 1.897\n",
      "tensor([-0.1458], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[7,   601] loss: 1.898\n",
      "tensor([-0.1474], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "[8,     1] loss: 0.010\n",
      "tensor([-0.1479], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[8,   201] loss: 1.896\n",
      "tensor([-0.1498], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[8,   401] loss: 1.891\n",
      "tensor([-0.1507], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[8,   601] loss: 1.889\n",
      "tensor([-0.1529], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 48 %\n",
      "[9,     1] loss: 0.009\n",
      "tensor([-0.1550], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[9,   201] loss: 1.886\n",
      "tensor([-0.1550], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[9,   401] loss: 1.888\n",
      "tensor([-0.1572], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[9,   601] loss: 1.885\n",
      "tensor([-0.1588], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 48 %\n",
      "[10,     1] loss: 0.009\n",
      "tensor([-0.1601], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[10,   201] loss: 1.882\n",
      "tensor([-0.1624], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[10,   401] loss: 1.878\n",
      "tensor([-0.1633], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[10,   601] loss: 1.878\n",
      "tensor([-0.1637], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "Accuracy of the network on the 10000 test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "# lr_list = [0.05, 0.01, 0.01, 0.002, 0.001, 0.001, 0.0002, 0.0001, 0.00002, 0.00001]\n",
    "lr_list = [0.05] * 10\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "for epoch in range(10) :    \n",
    "    running_loss = 0.0\n",
    "    learning_rate = lr_list[epoch]\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = net(inputs.to(device), conw1, conw2, conw3, conw4, conw5)\n",
    "#         print(outputs.shape)\n",
    "#         print(labels.shape)\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "#         print(loss)\n",
    "        loss.backward()    \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0 \n",
    "#             print(conw1[0][0][0])\n",
    "#             print(conw5[0][0][0])\n",
    "#             print(conw4.grad)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Update weights using gradient descent\n",
    "            conw1 -= learning_rate * conw1.grad\n",
    "            conw2 -= learning_rate * conw2.grad\n",
    "            conw3 -= learning_rate * conw3.grad\n",
    "            conw4 -= learning_rate * conw4.grad\n",
    "            conw5 -= learning_rate * conw5.grad\n",
    "\n",
    "            # Manually zero the gradients after running the backward pass\n",
    "            conw1.grad.zero_()\n",
    "            conw2.grad.zero_()   \n",
    "            conw3.grad.zero_()\n",
    "            conw4.grad.zero_()       \n",
    "            conw5.grad.zero_()                   \n",
    "            \n",
    "    test(net, conw1, conw2, conw3, conw4, conw5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebaf905-d82c-45f4-8cf5-7dbf57746d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be209fc-1dc9-4503-8cac-cb289ca17d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters = torch.randn(12, 3, 3, 3)\n",
    "# inputs = torch.randn(2, 3, 32, 32)\n",
    "# F.conv2d(inputs, filters, padding=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc86290-8dcf-4ba5-b081-a68e0f0b5633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7078, 0.2922],\n",
       "        [0.7366, 0.2634],\n",
       "        [0.7476, 0.2524],\n",
       "        [0.6517, 0.3483]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(4,2)\n",
    "print(x.shape)\n",
    "torch.nn.Softmax(dim=1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d25a3b-a193-4654-9754-c1d9ebb73575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b9f1d-1159-47e7-a3be-1a5afd747d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
