{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b2fdb-768c-4054-bc22-764c81689571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbef703c-f522-468c-8457-5bd93c1aa5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,3)*1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9801c7-913f-4f03-9171-83f32359afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dFunctionN(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None, stride=1, padding=1, dilation=1, groups=1):\n",
    "        # Save arguments to context to use on backward\n",
    "        # WARNING : if stride, padding, dilation etc is array, this will not work properly!!!!\n",
    "#         print('stride', stride)\n",
    "        if weight.shape[2] == 1 :\n",
    "            padding = 0\n",
    "        elif weight.shape[2] == 5 :\n",
    "            padding = 2\n",
    "        elif weight.shape[2] == 7 :\n",
    "            padding = 3\n",
    "        confs = torch.from_numpy(np.array([stride, padding, dilation, groups]))\n",
    "        dinput = torch.ones(input.shape) * 1e-5\n",
    "        dinput = dinput.cuda() \n",
    "        input += dinput\n",
    "        out = F.conv2d(input, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
    "        dout = F.conv2d(dinput, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
    "        dout = dout.cuda()\n",
    "        ctx.save_for_backward(input, out, dout, weight, bias, confs)\n",
    "\n",
    "        # Compute Convolution\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Load saved tensors\n",
    "        input, out, dout, weight, bias, confs = ctx.saved_variables\n",
    "        confs = confs.numpy()\n",
    "        stride, padding, dilation, groups= confs[0], confs[1], confs[2], confs[3]\n",
    "\n",
    "        # Calculate Gradient\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        dinput = torch.ones(input.shape) * 1e-5\n",
    "        dinput = dinput.cuda()\n",
    "        \n",
    "        \n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.nn.grad.conv2d_input(input.shape, weight, grad_output, stride, padding, dilation, groups)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_output = grad_output*(dout)\n",
    "            grad_weight = torch.nn.grad.conv2d_weight(dinput, weight.shape, grad_output, stride, padding, dilation, groups)\n",
    "                \n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0).squeeze(0)\n",
    "\n",
    "\n",
    "        # WARNING : Bias maybe buggy, remove if it is buggy\n",
    "        if bias is not None:\n",
    "            return grad_input, grad_weight, grad_bias, None, None, None, None\n",
    "        else:\n",
    "            return grad_input, grad_weight, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdefc726-4e82-40d6-8a1b-13b70b97816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7532153-f389-491d-9ed1-7365298e29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# N, C_in, C_out, K_size = batch_size, 3, 12, 3\n",
    "# Create random Tensors for weights.\n",
    "conw1 = torch.randn(8,3,5,5, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2 = torch.randn(32,8,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3 = torch.randn(128,32,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4 = torch.randn(128,128,3,3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5 = torch.randn(10,128,1,1, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "conw1 = torch.nn.init.xavier_uniform_(conw1, gain=1.0)\n",
    "conw2 = torch.nn.init.xavier_uniform_(conw2, gain=1.0)\n",
    "conw3 = torch.nn.init.xavier_uniform_(conw3, gain=1.0)\n",
    "conw4 = torch.nn.init.xavier_uniform_(conw4, gain=1.0)\n",
    "conw5 = torch.nn.init.xavier_uniform_(conw5, gain=1.0)\n",
    "\n",
    "# conw1g = conw1.clone().detatch(requires_grad=True)\n",
    "conw1n = torch.tensor(conw1, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2n = torch.tensor(conw2, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3n = torch.tensor(conw3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4n = torch.tensor(conw4, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5n = torch.tensor(conw5, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# for adam \n",
    "conw1a = torch.tensor(conw1, device=device, dtype=dtype, requires_grad=True)\n",
    "conw2a = torch.tensor(conw2, device=device, dtype=dtype, requires_grad=True)\n",
    "conw3a = torch.tensor(conw3, device=device, dtype=dtype, requires_grad=True)\n",
    "conw4a = torch.tensor(conw4, device=device, dtype=dtype, requires_grad=True)\n",
    "conw5a = torch.tensor(conw5, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "conw1a_list = [conw1a, conw2a, conw3a, conw4a, conw5a]\n",
    "conw1n_list = [conw1n, conw2n, conw3n, conw4n, conw5n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0570627-2ed2-46cd-b82f-33338b2c4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, conv_list, conv):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = conv.apply\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = conv.apply\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = conv.apply\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = conv.apply\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = conv.apply\n",
    "        self.avgpool = torch.nn.AvgPool2d((2,2) ,stride=(2,2))\n",
    "        self.maxpool = torch.nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.dtype = torch.float\n",
    "        self.c1 = None\n",
    "        self.c2 = None\n",
    "        self.c3 = None\n",
    "        self.c4 = None\n",
    "        self.c5 = None\n",
    "        \n",
    "        # weights of batch norm for custom backward, normal case \n",
    "        self.conw1, self.conw2, self.conw3, self.conw4, self.conw5 = conv_list \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.c1 = self.conv1(x, self.conw1)\n",
    "        x = self.bn1(self.act(self.c1))\n",
    "        x = self.maxpool(x)\n",
    "        self.c2 = self.conv2(x, self.conw2)\n",
    "        x = self.bn2(self.act(self.c2))\n",
    "        x = self.maxpool(x)\n",
    "        self.c3 = self.conv3(x, self.conw3)\n",
    "        x = self.bn3(self.act(self.c3))\n",
    "        x = self.maxpool(x)\n",
    "        self.c4 = self.conv4(x, self.conw4)\n",
    "        x = self.bn4(self.act(self.c4))\n",
    "        x = self.maxpool(x)\n",
    "        self.c5 = self.conv5(x, self.conw5)\n",
    "        x = self.avgpool(self.c5)\n",
    "        x = torch.squeeze(x)\n",
    "#         x = self.linear(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "\n",
    "#         self.c1 = self.act(self.conv1(x, self.conw1))\n",
    "#         x = self.maxpool(self.c1)\n",
    "#         self.c2 = self.act(self.conv2(x, self.conw2))\n",
    "#         x = self.maxpool(self.c2)\n",
    "#         self.c3 = self.act(self.conv3(x, self.conw3))\n",
    "#         x = self.maxpool(self.c3)\n",
    "#         self.c4 = self.act(self.conv4(x, self.conw4))\n",
    "#         x = self.maxpool(self.c4)\n",
    "#         self.c5 = self.conv5(x, self.conw5)\n",
    "#         x = self.avgpool(self.c5)\n",
    "#         x = torch.squeeze(x)\n",
    "# #         x = self.linear(x)\n",
    "#         x = torch.nn.Softmax(dim=1)(x)\n",
    "# #         x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def conv_return (self) :\n",
    "        return self.c1, self.c2, self.c3, self.c4, self.c5        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31e4a9b-9805-45fc-8129-640c5bbcfb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(conw1n_list, Conv2dFunctionN).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ab6d40-20a9-4abe-9f32-bd29986d677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    }
   ],
   "source": [
    "image, labels = iter(trainloader).next()\n",
    "outputs = net(image.to(device)).to(device)\n",
    "print(outputs.shape)\n",
    "loss = criterion(outputs, labels.to(device))\n",
    "loss.backward()\n",
    "print(torch.nn.Softmax(dim=1)(outputs).sum(dim=1))\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c969ea45-925b-41bd-a547-727eed505445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (model) :\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs.to(device))\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    return (100 * correct / total)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c02022-86c9-4951-af27-533c197709a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 10\n",
    "lr_list = [ 0.01, 0.01, 0.01, 0.01, 0.005,\n",
    "           0.005, 0.005, 0.005, 0.001, 0.001, 0.001, 0.0005, 0.0005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e257ef-875c-4f55-aed0-578e5d3ccde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** Numerical Gardient update ****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 2.338\n",
      "tensor(1.7980e-11, device='cuda:0')\n",
      "tensor(3.7285e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[2,   400] loss: 2.337\n",
      "tensor(2.5748e-11, device='cuda:0')\n",
      "tensor(4.8592e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[3,   400] loss: 2.336\n",
      "tensor(1.7991e-11, device='cuda:0')\n",
      "tensor(4.2521e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[4,   400] loss: 2.337\n",
      "tensor(2.5702e-11, device='cuda:0')\n",
      "tensor(1.0588e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[5,   400] loss: 2.336\n",
      "tensor(2.5002e-11, device='cuda:0')\n",
      "tensor(3.9654e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[6,   400] loss: 2.336\n",
      "tensor(2.7104e-11, device='cuda:0')\n",
      "tensor(9.1962e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[7,   400] loss: 2.337\n",
      "tensor(2.1904e-11, device='cuda:0')\n",
      "tensor(5.0520e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[8,   400] loss: 2.337\n",
      "tensor(1.5458e-11, device='cuda:0')\n",
      "tensor(5.2258e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[9,   400] loss: 2.338\n",
      "tensor(2.1419e-11, device='cuda:0')\n",
      "tensor(6.4563e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n",
      "[10,   400] loss: 2.337\n",
      "tensor(2.2417e-11, device='cuda:0')\n",
      "tensor(6.2122e-11, device='cuda:0')\n",
      "Accuracy of the network on the 10000 test images: 7 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('****************** Numerical Gardient update ****************')\n",
    "# lr_list = [0.05] * NUM_EPOCH\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "gated1_loss = []\n",
    "gated1_accuracy = []\n",
    "# optimizer = optim.Adam([conw1g, conw2g, conw3g, conw4g, conw5g], lr=0.001)\n",
    "# optimizerbn = optim.Adam(netg.parameters(), lr=0.001)\n",
    "for epoch in range(NUM_EPOCH) :    \n",
    "    running_loss = 0.0\n",
    "    learning_rate = lr_list[epoch]\n",
    "#     learning_rate = 0.05\n",
    "    optimizer = optim.SGD(conw1n_list, lr=0.0001)\n",
    "#     optimizerbn = optim.SGD(net.parameters(), lr=learning_rate)    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = net(inputs.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "#         optimizerbn.zero_grad()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 400 == 399:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "            print(conw1n_list[0].grad.norm())\n",
    "            print(conw1n_list[4].grad.norm())\n",
    "            \n",
    "        optimizer.step()\n",
    "#         optimizerbn.step()\n",
    "        \n",
    "        optimizer.zero_grad()            \n",
    "            \n",
    "    test_acc = test(net)\n",
    "    gated1_loss.append(running_loss/len(trainloader))\n",
    "    gated1_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915c9771-723a-4e4f-a395-95ab78292b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conw1n_list[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b191c7-ac40-46ff-9b12-8f4ca96d4812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
