{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08d91b9-2360-491b-8fba-57b538e9b60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05, 0.04351133533380851, 0.03763019350290237, 0.03233860639039575, 0.027610188407766852, 0.023412708106044778, 0.019710173577058045, 0.01646450246756338, 0.013636839516207507, 0.011188577139226377, 0.00908212776868068, 0.0072814904000044894, 0.005752648131336976, 0.004463828361377955, 0.003385652732557608, 0.0024911998332304472, 0.0017560000734507363, 0.001157978988356383, 0.0006773624649329806, 0.00029655499559261365]\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# import joblib\n",
    "import cv2\n",
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "#import pretrainedmodels\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gated import *\n",
    "from resnet_gated import *\n",
    "from train import train_gated, test\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d01384-e820-485f-9257-8a266a0ad82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffabfdd5-37bb-46a9-8bf6-8e93e50c34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0f42e8-c6e8-4565-9ad8-08044a133b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "image_paths = list(paths.list_images('../data/101_ObjectCategories'))\n",
    "data = []\n",
    "labels = []\n",
    "for image_path in image_paths:\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "    if label == 'BACKGROUND_Google':\n",
    "        continue\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292073f9-9ff6-4f66-b830-fb964b7aa3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745cdd14-feb6-446f-9e24-dff1e3710002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes: 101\n"
     ]
    }
   ],
   "source": [
    "# one hot encode\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(f\"Total number of classes: {len(lb.classes_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1eefcfe-51cf-49d5-9e33-a016f3fa7cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (6073,)\n",
      "x_test examples: (1693,)\n",
      "x_val examples: (911,)\n"
     ]
    }
   ],
   "source": [
    "# divide the data into train, validation, and test set\n",
    "(x_train, x_val , y_train, y_val) = train_test_split(data, labels, \n",
    "                                                    test_size=0.3,  \n",
    "                                                    stratify=labels,\n",
    "                                                    random_state=42)\n",
    "\n",
    "(x_val, x_test, y_val, y_test) = train_test_split(x_val, y_val, \n",
    "                                                    test_size=0.65, \n",
    "                                                    random_state=42)\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3e83d1-5285-4337-b35f-b687f3ba98e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98,  3, 65, 52,  0,  1, 71, 72,  3,  3, 23,  3,  1, 55,  1, 11, 17,\n",
       "       40, 90, 53])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_val[:20], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ab7404-c1f6-4018-8dd3-10d24ec1317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDataset(x_train, y_train, train_transform)\n",
    "val_data = ImageDataset(x_val, y_val, val_transform)\n",
    "test_data = ImageDataset(x_test, y_test, val_transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992af6ab-586f-42f6-8fe9-95b2193c708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilation [False, False, False]\n",
      "stride 1\n",
      "downsample\n",
      "stride 2\n",
      "downsample\n",
      "stride 2\n",
      "downsample\n",
      "stride 2\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f1417-4ca1-48e4-8bb7-849f26bba09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 6073 examples, validating on 911 examples...\n",
      "Epoch 1 of 20\n",
      "Train Loss: 0.0558, Train Acc: 25.41\n",
      "Val Loss: 0.0528, Val Acc: 33.70\n",
      "Epoch 2 of 20\n",
      "Train Loss: 0.0417, Train Acc: 40.51\n",
      "Val Loss: 0.0422, Val Acc: 43.25\n",
      "Epoch 3 of 20\n",
      "Train Loss: 0.0336, Train Acc: 50.26\n",
      "Val Loss: 0.0355, Val Acc: 50.05\n",
      "Epoch 4 of 20\n",
      "Train Loss: 0.0278, Train Acc: 57.80\n",
      "Val Loss: 0.0312, Val Acc: 55.10\n",
      "Epoch 5 of 20\n",
      "Train Loss: 0.0227, Train Acc: 65.06\n",
      "Val Loss: 0.0284, Val Acc: 59.50\n",
      "Epoch 6 of 20\n",
      "Train Loss: 0.0178, Train Acc: 72.63\n",
      "Val Loss: 0.0249, Val Acc: 62.13\n",
      "Epoch 7 of 20\n",
      "Train Loss: 0.0135, Train Acc: 79.17\n",
      "Val Loss: 0.0220, Val Acc: 65.09\n",
      "Epoch 8 of 20\n",
      "Train Loss: 0.0092, Train Acc: 86.81\n",
      "Val Loss: 0.0214, Val Acc: 65.97\n",
      "Epoch 9 of 20\n",
      "Train Loss: 0.0052, Train Acc: 94.15\n",
      "Val Loss: 0.0200, Val Acc: 69.26\n",
      "Epoch 10 of 20\n",
      "Train Loss: 0.0024, Train Acc: 98.25\n",
      "Val Loss: 0.0174, Val Acc: 72.34\n",
      "Epoch 11 of 20\n",
      "Train Loss: 0.0009, Train Acc: 99.84\n",
      "Val Loss: 0.0175, Val Acc: 72.56\n",
      "Epoch 12 of 20\n",
      "Train Loss: 0.0004, Train Acc: 99.98\n",
      "Val Loss: 0.0168, Val Acc: 72.78\n",
      "Epoch 13 of 20\n",
      "Train Loss: 0.0002, Train Acc: 99.97\n",
      "Val Loss: 0.0169, Val Acc: 73.22\n",
      "Epoch 14 of 20\n",
      "Train Loss: 0.0002, Train Acc: 99.98\n",
      "Val Loss: 0.0171, Val Acc: 73.66\n",
      "Epoch 15 of 20\n",
      "Train Loss: 0.0001, Train Acc: 99.98\n",
      "Val Loss: 0.0167, Val Acc: 73.44\n",
      "Epoch 16 of 20\n",
      "Train Loss: 0.0001, Train Acc: 99.98\n",
      "Val Loss: 0.0173, Val Acc: 73.22\n",
      "Epoch 17 of 20\n",
      "Train Loss: 0.0001, Train Acc: 99.98\n",
      "Val Loss: 0.0170, Val Acc: 73.33\n",
      "Epoch 18 of 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training on {len(train_data)} examples, validating on {len(val_data)} examples...\")\n",
    "train_gated(model, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac1da97-fa8d-4255-8890-bfd0b1f0ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test images: 75.605 %\n",
      "train.py finished running\n"
     ]
    }
   ],
   "source": [
    "correct, total = test(model, testloader)\n",
    "print('Accuracy of the network on test images: %0.3f %%' % (100 * correct / total))\n",
    "print('train.py finished running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826df50-cbe3-422a-9ac4-f228949aaf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = model.state_dict()\n",
    "# for i in state_dict :\n",
    "# #     print(i)\n",
    "#     if 'conv_w' in i :\n",
    "#         print(state_dict[i][0,0])\n",
    "#     if 'layer1.0.conv1_w' in i :\n",
    "#         print(state_dict[i][0,0])\n",
    "#     if 'layer1.0.conv2_w' in i :\n",
    "#         print(state_dict[i][0,0])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a8876-c65c-4185-80b3-fb89ec77bd21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
